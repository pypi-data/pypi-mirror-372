{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8KRSmRhckQL"
   },
   "source": [
    "# Training a new model\n",
    "This Jupyter Notebook will teach you how to train a new model. The only requirements is that you already sampled your Ground Truth masks using the \"format_dataset\" notebook tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1crk0-b7c3IQ"
   },
   "source": [
    "## Downloading the package\n",
    "\n",
    "Make sure that the notebook is running with Python>=3.10 and with a version of PyTorch >=1.13 installed with CUDA available (necessary for training).\n",
    "\n",
    "To verify if PyTorch and Cuda are installed, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4802,
     "status": "ok",
     "timestamp": 1741166333845,
     "user": {
      "displayName": "Quentin RAPILLY",
      "userId": "13440189952482936627"
     },
     "user_tz": -60
    },
    "id": "-rUueKG1d6Lk",
    "outputId": "fa3e660f-50eb-4bcd-d418-76631f82cfc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version of Pytorch: 2.5.1+cu124\n",
      "Cuda working properly: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Current version of Pytorch: {torch.__version__}\")\n",
    "print(f\"Cuda working properly: {torch.cuda.is_available()}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuUh9XPzeoDC"
   },
   "source": [
    "If you have the good version of Torch and Cuda is working, you can run the following cell to install our package. Otherwise, fix your Python environment before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5656,
     "status": "ok",
     "timestamp": 1741166339503,
     "user": {
      "displayName": "Quentin RAPILLY",
      "userId": "13440189952482936627"
     },
     "user_tz": -60
    },
    "id": "qh3iaG2nahrp",
    "outputId": "5a38ccc0-77bf-4bee-9943-1e165d18f507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nagini3D in /usr/local/lib/python3.11/dist-packages (0.0.1)\n",
      "Requirement already satisfied: csbdeep==0.7.4 in /usr/local/lib/python3.11/dist-packages (from nagini3D) (0.7.4)\n",
      "Requirement already satisfied: einops==0.7.0 in /usr/local/lib/python3.11/dist-packages (from nagini3D) (0.7.0)\n",
      "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (from nagini3D) (2.3.0)\n",
      "Requirement already satisfied: scikit-image==0.21.0 in /usr/local/lib/python3.11/dist-packages (from nagini3D) (0.21.0)\n",
      "Requirement already satisfied: scipy==1.11.3 in /usr/local/lib/python3.11/dist-packages (from nagini3D) (1.11.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from csbdeep==0.7.4->nagini3D) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from csbdeep==0.7.4->nagini3D) (3.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from csbdeep==0.7.4->nagini3D) (1.17.0)\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from csbdeep==0.7.4->nagini3D) (2025.2.18)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from csbdeep==0.7.4->nagini3D) (4.67.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from csbdeep==0.7.4->nagini3D) (24.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0->nagini3D) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.3.0->nagini3D) (6.0.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->nagini3D) (3.4.2)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->nagini3D) (11.1.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->nagini3D) (2.37.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->nagini3D) (1.8.0)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.21.0->nagini3D) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->csbdeep==0.7.4->nagini3D) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->csbdeep==0.7.4->nagini3D) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->csbdeep==0.7.4->nagini3D) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->csbdeep==0.7.4->nagini3D) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->csbdeep==0.7.4->nagini3D) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->csbdeep==0.7.4->nagini3D) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nagini3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKIBFmX6QUb-"
   },
   "outputs": [],
   "source": [
    "from nagini3D.data.training_set import TrainingSet, custom_collate\n",
    "from nagini3D.data.th_optim_set import OptimSet\n",
    "from nagini3D.models.model import Nagini3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUV3Ir4sQXl2"
   },
   "source": [
    "## Configuration setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ukmvV5-RN1Z"
   },
   "source": [
    "Your train and validation datasets should be organized as follow:\n",
    "\n",
    "\n",
    "```\n",
    "-set name\n",
    " |-images (dir storing the images)\n",
    " |-masks  (dir storing the corresponding masks)\n",
    " |-samplings (dir storing the output of the format_dataset code: samplings and spots maps)\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKbKRz45QXKN"
   },
   "outputs": [],
   "source": [
    "P = 101                   # number of points on the predicted surfaces (should be an odd number to match Fibonacci lattice requirements, should be <= at the number of points sampled on the GT masks)\n",
    "M1 = 4                    # complexity parameter (see article for details)\n",
    "M2 = 2                    # complexity parameter (see article for details)\n",
    "batch_size = 1           # The algorithm is really memory consuming, try to keep the batch small to avoid CUDA out of memory, especially with high values of P (>>100)\n",
    "nb_epochs = 1000\n",
    "\n",
    "patch_size = 64          # Size of the patches cropped in your images to provide to the network\n",
    "train_set_dir = \"\"       # Directory storing your training dataset (organized as mentionned below)\n",
    "val_set_dir =   \"\"       # Directory storing your validation dataset (organized as mentionned below)\n",
    "data_aug = True          # If True, random flip along x,y,z axis\n",
    "cell_ratio_th = 0.02     # If >0.0, the patch with a proportion of object voxels smaller than the choosen value will be discarded\n",
    "anisotropy = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiOirEoi60Sz"
   },
   "outputs": [],
   "source": [
    "settings_cfg = {\n",
    "    \"experiment_name\": \"jupyter-nagini\",\n",
    "    \"M1\": M1,\n",
    "    \"M2\": M2,\n",
    "    \"nb_points_on_surface\": P,\n",
    "    \"nb_epochs\": nb_epochs\n",
    "}\n",
    "\n",
    "data_cfg = {\n",
    "    \"patch_size\": patch_size,\n",
    "    \"data_aug\": data_aug,\n",
    "    \"train\": train_set_dir,\n",
    "    \"val\": val_set_dir\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Cs4ijtk4sbL"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEfsXDkft4w0"
   },
   "outputs": [],
   "source": [
    "train_set = TrainingSet(nb_points=P, patch_size=patch_size, dataset_dir=train_set_dir, data_aug=data_aug, cell_ratio_th=cell_ratio_th, anisotropy_ratio=anisotropy)\n",
    "val_set = TrainingSet(nb_points=P, r_mean=train_set.r_mean,  patch_size=patch_size, data_aug=data_aug, dataset_dir=val_set_dir, cell_ratio_th=cell_ratio_th, anisotropy_ratio=anisotropy)\n",
    "\n",
    "train_loader = DataLoader(train_set, collate_fn=custom_collate, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, collate_fn=custom_collate, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPbNUXCY1-0Y"
   },
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    \"input_channels\": 1,                      # number of input channels of your image\n",
    "    \"features_start\": 32,                     # number of feature at the first layer of the U-Net\n",
    "    \"num_layers\": 3,                          # number of layers\n",
    "    \"inner_normalisation\": \"BatchNorm\",\n",
    "    \"train_bn\": True,\n",
    "    \"padding_mode\": \"zeros\",\n",
    "    \"bilinear\": False\n",
    "}\n",
    "\n",
    "save_path = \"\"        # directory where you want to store the model weigths, the configuration file and the optimal thresholds file at the end of the training\n",
    "\n",
    "model = Nagini3D(unet_cfg=model_cfg, P=P, M1=M1, M2=M2, device=device, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0XPifHi19L4"
   },
   "outputs": [],
   "source": [
    "optim_cfg = {\n",
    "    \"name\": \"adam\",\n",
    "    \"parameters\": {\n",
    "        \"lr\": 0.0001,\n",
    "        \"weight_decay\": 0.0001\n",
    "    }\n",
    "}\n",
    "\n",
    "# you can also use SGD optimizer by switching \"adam\" for \"sgd\" and precising the corresponding parameters\n",
    "\n",
    "model.init_optimizer(optimizer_cfg=optim_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqsh0-DJ3UzS"
   },
   "outputs": [],
   "source": [
    "loss_cfg = {\n",
    "  \"epoch_reg_max\": 200,  # int: number of epochs during which the regularization preventing surface twists is applied\n",
    "  \"reg_part\": 0.0,       # float in [0,1]: weight the regularisation preventing surface twists, keep it zero for small values of M1 and M2 (typically 4,2), increase if you augment them.\n",
    "  \"lambdas\":  {\n",
    "      \"snakes\": 1.0,             # float: weight the surface loss\n",
    "      \"spots\": 1.0,              # float: weight the probability loss used for center detection\n",
    "      \"regularization\" : 0.001\n",
    "  }\n",
    "}\n",
    "\n",
    "model.init_loss(loss_lambdas=loss_cfg[\"lambdas\"], reg_part=loss_cfg[\"reg_part\"], epoch_reg_max=loss_cfg[\"epoch_reg_max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-QqCq_16tgT"
   },
   "outputs": [],
   "source": [
    "save_cfg = {\"path\": save_path}\n",
    "settings_cfg[\"r_mean\"] = train_set.r_mean\n",
    "cfg = {\"settings\": settings_cfg, \"optimizer\": optim_cfg, \"model\": model_cfg, \"data\": data_cfg, \"settings\": settings_cfg, \"loss\": loss_cfg}\n",
    "\n",
    "model.save_config(cfg_dict=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCDg0V1f8_3J"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nUOlGgN8_Oi"
   },
   "outputs": [],
   "source": [
    "best_val_score = float(\"inf\")\n",
    "epoch_best_val = -1\n",
    "\n",
    "for epoch_idx in range(nb_epochs):\n",
    "  print(f\"Epoch {epoch_idx+1} / {nb_epochs}\\nTraining ...\")\n",
    "\n",
    "  snake_ratio = model.update_snake_loss(epoch_idx) # if you added a regularization loss, i.e. \"reg_part\">0, this will slowly decrease the regularization part to be zero at \"epoch_reg_max\"\n",
    "\n",
    "  loss = model.epoch(data_loader = train_loader)\n",
    "\n",
    "  print(f\"\\nLoss : {loss['loss']}\\nTesting ...\")\n",
    "\n",
    "  validation, _ = model.val(data_loader = val_loader, nb_cells_to_plot=4)\n",
    "\n",
    "  print(f\"\\nAccuracy on validation set : {validation['loss']}\")\n",
    "\n",
    "  if validation[\"loss\"] < best_val_score:\n",
    "      model.save_model(f\"best\")\n",
    "      best_val_score = validation[\"loss\"]\n",
    "      epoch_best_val = epoch_idx\n",
    "\n",
    "cfg[\"save\"] = {**cfg[\"save\"], \"best_epoch\" : epoch_best_val}\n",
    "model.save_config(cfg_dict=cfg)\n",
    "model.save_model(\"final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pF4Yoik8-t6h"
   },
   "source": [
    "## Processing of optimal thresholds for inference computed on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YXN-1Tb-_fI"
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "model.load_weights(join(model.save_dir, \"best.pkl\"))\n",
    "optim_set = OptimSet(cfg[\"data\"][\"val\"])\n",
    "opti_th = model.optimize_thresholds(optim_set, r_mean=train_set.r_mean, nb_tiles=(1,1,1))\n",
    "model.save_th(th_dict=opti_th)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOoxE0LM6AkiXtK2jK+dW2u",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
