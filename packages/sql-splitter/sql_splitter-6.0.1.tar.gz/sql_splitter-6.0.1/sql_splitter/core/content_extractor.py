"""
Content Extractor - SQL Parser AST v6.0

ðŸ“¦ Final content extraction from AST for expect.md compliance

Author: AI Assistant
Version: 6.0 AST Modular
Date: 2025-08-26
Status: âœ… Final JSON output generation for 100% expect.md compliance
"""

import re
from typing import List, Dict, Any, Optional, Set
from .ast_nodes import *
from .sql_tokenizer import SQLTokenizer, TokenStream

class ContentExtractor:
    """Extract final content from SQL for expect.md compliance"""

    def __init__(self):
        self.table_aliases = {}
        self.database_name = ""
        self.detected_databases = set()

    def extract_fields(self, sql: str, group_by_fields: List[str] = None) -> List[Dict[str, Any]]:
        """ðŸŽ¯ Extract field information with enhanced parsing"""
        fields = []
        if not group_by_fields:
            group_by_fields = []

        # Extract SELECT clause
        select_match = re.search(r'\bSELECT\s+(.*?)\s+FROM\b', sql, re.IGNORECASE | re.DOTALL)
        if not select_match:
            return fields

        select_clause = select_match.group(1)
        field_parts = self._smart_split_fields(select_clause)

        for field_part in field_parts:
            field_info = self._parse_single_field(field_part.strip(), group_by_fields)
            if field_info:
                fields.append(field_info)

        return fields

    def _smart_split_fields(self, select_clause: str) -> List[str]:
        """ðŸŽ¯ Intelligent field splitting with function/parentheses awareness"""
        fields = []
        current_field = ""
        paren_level = 0
        quote_level = 0
        in_backticks = False

        for char in select_clause:
            if char == '`':
                in_backticks = not in_backticks
            elif char == '(' and not in_backticks:
                paren_level += 1
            elif char == ')' and not in_backticks:
                paren_level -= 1
            elif char == "'" and not in_backticks:
                quote_level = 1 - quote_level
            elif char == ',' and paren_level == 0 and quote_level == 0 and not in_backticks:
                if current_field.strip():
                    fields.append(current_field.strip())
                current_field = ""
                continue

            current_field += char

        if current_field.strip():
            fields.append(current_field.strip())

        return fields

    def _parse_single_field(self, field_str: str, group_by_fields: List[str]) -> Optional[Dict[str, Any]]:
        """ðŸŽ¯ Parse individual field with comprehensive analysis"""
        if not field_str:
            return None

        # Extract alias
        alias = self._extract_field_alias(field_str)
        
        # Get original expression (without AS clause)
        original_expr = self._get_original_expression(field_str)
        
        # Determine table
        table_name = self._determine_field_table(original_expr)
        
        # Format field expression
        formatted_field = self._format_field_expression(original_expr, table_name, alias)
        
        # Check if field is in GROUP BY
        is_group_by = alias in group_by_fields

        return {
            "table": table_name,
            "field": formatted_field,  # âœ… CORRECTED: use "field" as per expect.md requirements
            "alias": alias,
            "groupBy": is_group_by
        }

    def _extract_field_alias(self, field_str: str) -> str:
        """ðŸŽ¯ Extract field alias with backtick-free and backtick support"""
        
        # Pattern 1: AS alias (without backticks) - MOST COMMON after normalization
        as_match = re.search(r'\s+AS\s+([a-zA-Z_][a-zA-Z0-9_]*)', field_str, re.IGNORECASE)
        if as_match:
            return as_match.group(1)
        
        # Pattern 2: AS `alias` (with backticks) - legacy support
        as_backtick_match = re.search(r'\s+AS\s+`([^`]+)`', field_str, re.IGNORECASE)
        if as_backtick_match:
            return as_backtick_match.group(1)

        # Pattern 3: table.field format (without backticks)
        dot_match = re.search(r'([a-zA-Z_][a-zA-Z0-9_]*)\\.([a-zA-Z_][a-zA-Z0-9_]*)$', field_str)
        if dot_match:
            return dot_match.group(2)  # Use field name as alias

        # Pattern 4: `table`.`field` format (with backticks) - legacy support
        dot_backtick_match = re.search(r'`([a-zA-Z_][a-zA-Z0-9_]*)`\\.`([a-zA-Z_][a-zA-Z0-9_]*)`$', field_str)
        if dot_backtick_match:
            return dot_backtick_match.group(2)  # Use field name as alias

        # Pattern 5: Direct field name (no dots)
        field_match = re.search(r'([a-zA-Z_][a-zA-Z0-9_]*)$', field_str)
        if field_match:
            return field_match.group(1)

        # Pattern 6: Function name extraction
        func_match = re.search(r'([a-zA-Z_][a-zA-Z0-9_]*)\s*\(', field_str)
        if func_match:
            return func_match.group(1).upper()  # Use function name as alias

        # Pattern 7: Complex expression - use simplified version
        if len(field_str) > 20:
            return "complex_expr"

        return field_str[:20] if field_str else ""

    def _get_original_expression(self, field_str: str) -> str:
        """Get original expression without AS clause"""
        as_match = re.search(r'(.*?)\s+AS\s+', field_str, re.IGNORECASE)
        if as_match:
            return as_match.group(1).strip()
        return field_str.strip()

    def _determine_field_table(self, expr: str) -> str:
        """ðŸš€ ULTIMATE: mo-sql-parsing inspired field-table association for all SQL expression types"""
        
        # ðŸš€ STEP 1: Handle simple table.field patterns (mo-sql-parsing quality)
        simple_table = self._handle_simple_table_field_patterns(expr)
        if simple_table:
            return simple_table
        
        # ðŸš€ STEP 2: Handle complex expressions (functions, subqueries, etc.)
        if self._is_complex_expression(expr):
            primary_table = self._extract_primary_table_from_complex_expr(expr)
            if primary_table:
                return primary_table
        
        return ""
    
    def _handle_simple_table_field_patterns(self, expr: str) -> str:
        """ðŸš€ NEW: Handle simple table.field patterns with mo-sql-parsing precision"""
        
        # Skip complex expressions - let specialized handler deal with them
        if '(' in expr or any(func in expr.upper() for func in ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN', 'OVER', 'CASE', 'SELECT']):
            return ""
        
        if '.' not in expr:
            return ""
        
        parts = expr.split('.')
        
        # Three-part format: DB.Table.field (handle database prefixes)
        if len(parts) >= 3:
            db_name = parts[0].strip()
            table_name = parts[1].strip()
            # Skip database prefix, use actual table name
            if (table_name not in self.detected_databases and 
                table_name != 'momo' and 
                self._is_valid_table_name(table_name)):
                return table_name
        
        # Two-part format: Table.field or Alias.field (most common)
        elif len(parts) == 2:
            table_or_alias = parts[0].strip()
            field_name = parts[1].strip()
            
            # ðŸŽ¯ mo-sql-parsing insight: Validate both parts
            if (self._is_valid_identifier(table_or_alias) and 
                self._is_valid_identifier(field_name) and
                table_or_alias not in self.detected_databases and 
                table_or_alias != 'momo'):
                
                # Resolve alias to actual table name
                resolved_table = self._resolve_table_alias(table_or_alias)
                if resolved_table:
                    return resolved_table
        
        return ""
    
    def _is_complex_expression(self, expr: str) -> bool:
        """ðŸš€ NEW: Determine if expression is complex (mo-sql-parsing categorization)"""
        complex_indicators = ['(', 'COUNT', 'SUM', 'AVG', 'MAX', 'MIN', 'OVER', 'CASE', 'SELECT', 'WHEN', 'THEN']
        return any(indicator in expr.upper() for indicator in complex_indicators)
    
    def _is_valid_identifier(self, identifier: str) -> bool:
        """ðŸš€ NEW: Validate SQL identifier (mo-sql-parsing standards)"""
        if not identifier or len(identifier) < 1:  # âœ… Allow single-char aliases like 'c', 'o', 'u'
            return False
        
        # Must start with letter or underscore
        if not (identifier[0].isalpha() or identifier[0] == '_'):
            return False
        
        # Must contain only alphanumeric and underscore
        if not all(c.isalnum() or c == '_' for c in identifier):
            return False
        
        # Must not contain operators or special characters
        invalid_chars = ['+', '-', '*', '/', '(', ')', '=', '<', '>', ' ', '!', '@', '#', '$', '%', '^', '&']
        if any(char in identifier for char in invalid_chars):
            return False
        
        return True
    
    def _extract_primary_table_from_complex_expr(self, expr: str) -> str:
        """ðŸš€ ENHANCED: mo-sql-parsing inspired table extraction from complex expressions"""
        
        # ðŸŽ¯ STEP 1: Extract ALL table.field references (mo-sql-parsing approach)
        table_refs = self._extract_all_table_field_references(expr)
        
        if table_refs:
            # ðŸŽ¯ STEP 2: Prioritized table selection (inspired by mo-sql-parsing logic)
            return self._select_primary_table_from_references(table_refs, expr)
        
        return ""
    
    def _extract_all_table_field_references(self, expr: str) -> List[tuple[str, str]]:
        """ðŸš€ ENHANCED: Extract all table.field references from expression (mo-sql-parsing inspired)"""
        
        # ðŸ” Enhanced pattern: Capture all valid table.field patterns including inside functions
        # Matches: table.field, alias.field, even inside parentheses like COUNT(table.field)
        # Using the working pattern from debug: (\w+)\.(\w+)
        pattern = r'(\w+)\.(\w+)'
        matches = re.findall(pattern, expr)
        
        # ðŸŽ¯ Filter and validate matches (mo-sql-parsing quality standards)
        valid_refs = []
        for table_or_alias, field_name in matches:
            # Skip database names and invalid patterns
            if (table_or_alias not in self.detected_databases and 
                table_or_alias != 'momo' and
                len(table_or_alias) >= 1 and len(field_name) >= 2 and  # âœ… Allow single-char aliases like 'o', 'c', 'u'
                not any(char in table_or_alias for char in ['+', '-', '*', '/', '(', ')', '=', '<', '>']) and
                not any(char in field_name for char in ['+', '-', '*', '/', '(', ')', '=', '<', '>'])):
                valid_refs.append((table_or_alias, field_name))
        
        return valid_refs
    
    def _select_primary_table_from_references(self, table_refs: List[tuple[str, str]], expr: str) -> str:
        """ðŸš€ NEW: Select primary table from multiple references (mo-sql-parsing prioritization logic)"""
        
        if not table_refs:
            return ""
        
        # ðŸŽ¯ Priority 1: Table reference in function arguments (highest priority)
        # mo-sql-parsing insight: Function arguments contain the most relevant table
        func_pattern = r'\b(?:COUNT|SUM|AVG|MAX|MIN|STDDEV)\s*\(\s*(?:DISTINCT\s+)?([a-zA-Z_][a-zA-Z0-9_]*)\.[a-zA-Z_][a-zA-Z0-9_]*'
        func_match = re.search(func_pattern, expr, re.IGNORECASE)
        if func_match:
            func_table = func_match.group(1)
            for table_or_alias, _ in table_refs:
                if table_or_alias == func_table:
                    return self._resolve_table_alias(table_or_alias)
        
        # ðŸŽ¯ Priority 2: Window function PARTITION BY table (high priority)
        window_pattern = r'OVER\s*\(\s*PARTITION\s+BY\s+([a-zA-Z_][a-zA-Z0-9_]*)\.[a-zA-Z_][a-zA-Z0-9_]*'
        window_match = re.search(window_pattern, expr, re.IGNORECASE)
        if window_match:
            window_table = window_match.group(1)
            for table_or_alias, _ in table_refs:
                if table_or_alias == window_table:
                    return self._resolve_table_alias(table_or_alias)
        
        # ðŸŽ¯ Priority 3: First table reference (mo-sql-parsing default)
        first_table_or_alias = table_refs[0][0]
        return self._resolve_table_alias(first_table_or_alias)
    
    def _resolve_table_alias(self, table_or_alias: str) -> str:
        """ðŸš€ NEW: Resolve table alias to actual table name"""
        if table_or_alias in self.table_aliases:
            return self.table_aliases[table_or_alias]
        if self._is_valid_table_name(table_or_alias):
            return table_or_alias
        return ""

    def _format_field_expression(self, expr: str, table_name: str, alias: str) -> str:
        """ðŸŽ¯ Format field expression for expect.md compliance with backtick-free support"""
        
        # Uppercase SQL functions
        formatted = re.sub(
            r'\b(sum|count|avg|max|min|date_format|if|concat|case|when|then|else|end|coalesce|ifnull|length|substring|upper|lower|trim|now|curdate|year|month|day)\s*\(',
            lambda m: m.group().upper(), 
            expr, 
            flags=re.IGNORECASE
        )

        # Apply dot-split approach to field names too!
        formatted = re.sub(r'\b([a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z_][a-zA-Z0-9_]*)\b', 
                          lambda m: '.'.join(m.group(1).split('.')[1:]), formatted)
        
        return formatted

    def extract_where_conditions(self, sql: str) -> List[str]:
        """ðŸš€ ENHANCED: Extract only actual WHERE conditions, not SQL fragments"""
        conditions = []
        
        # ðŸŽ¯ Step 1: Find WHERE clause with robust boundary detection
        where_pattern = r'\bWHERE\s+(.*?)(?=\s+(?:GROUP\s+BY|ORDER\s+BY|HAVING|LIMIT|UNION|INTERSECT|EXCEPT|\)|\s*$))'
        where_match = re.search(where_pattern, sql, re.IGNORECASE | re.DOTALL)
        
        if not where_match:
            return conditions
        
        where_clause = where_match.group(1).strip()
        
        # ðŸŽ¯ Step 2: Filter out complex SQL constructs that aren't conditions
        if self._is_valid_where_condition(where_clause):
            # ðŸŽ¯ Step 3: Split into individual conditions
            individual_conditions = self._split_where_conditions(where_clause)
            conditions.extend(individual_conditions)
        
        return conditions
    
    def _is_valid_where_condition(self, clause: str) -> bool:
        """ðŸš€ NEW: Validate that clause is actually a WHERE condition, not SQL fragments"""
        
        # ðŸš¨ Red flags: These indicate SQL fragments, not conditions
        red_flags = [
            'UNION ALL SELECT',
            'INNER JOIN',
            'LEFT JOIN', 
            'RIGHT JOIN',
            'FROM (',
            ') SELECT',
            'WITH ',
            'CREATE ',
            'INSERT ',
            'UPDATE ',
            'DELETE '
        ]
        
        clause_upper = clause.upper()
        for flag in red_flags:
            if flag in clause_upper:
                return False
        
        # ðŸŽ¯ Valid condition indicators
        valid_indicators = [
            '=', '!=', '<>', '<', '>', '<=', '>=',
            'IS NULL', 'IS NOT NULL',
            'IN (', 'NOT IN (',
            'EXISTS (', 'NOT EXISTS (',
            'LIKE ', 'NOT LIKE ',
            'BETWEEN ', 'NOT BETWEEN '
        ]
        
        # Check if contains at least one valid condition operator
        for indicator in valid_indicators:
            if indicator in clause_upper:
                return True
        
        # ðŸš¨ If no valid operators found, likely not a real condition  
        return len(clause) < 200  # Allow short clauses that might be simple conditions
    
    def _split_where_conditions(self, where_clause: str) -> List[str]:
        """ðŸš€ NEW: Split WHERE clause into individual conditions"""
        
        # For complex WHERE clauses, return as single condition for now
        # Future enhancement: Smart AND/OR splitting with proper parentheses handling
        if len(where_clause.strip()) > 0:
            return [where_clause.strip()]
        
        return []

    def extract_group_by_fields(self, sql: str) -> List[str]:
        """ðŸŽ¯ Extract GROUP BY fields"""
        group_by_fields = []
        
        # Extract GROUP BY clause
        group_by_match = re.search(r'\bGROUP\s+BY\s+(.*?)(?:\s+(?:ORDER\s+BY|HAVING|LIMIT|$))', sql, re.IGNORECASE | re.DOTALL)
        if not group_by_match:
            return group_by_fields
        
        group_by_clause = group_by_match.group(1).strip()
        
        # Split by comma and clean
        for field in group_by_clause.split(','):
            field = field.strip()
            if field:
                # Remove backticks and database prefixes
                field = re.sub(r'`([^`]+)`', r'\1', field)
                if '.' in field:
                    parts = field.split('.')
                    if len(parts) >= 2:
                        field = parts[-1]  # Use the last part (field name)
                
                if field and field not in ['GROUP', 'BY', 'ORDER', 'HAVING', 'LIMIT']:
                    group_by_fields.append(field)
        
        return group_by_fields

    def set_context(self, table_aliases: Dict[str, str], database_name: str = "", detected_databases: Set[str] = None):
        """Set extraction context from other components"""
        self.table_aliases = table_aliases.copy()
        self.database_name = database_name
        if detected_databases:
            self.detected_databases = detected_databases.copy()

    def _is_valid_table_name(self, name: str) -> bool:
        """Validate table name"""
        if not name or len(name) < 2:
            return False

        # SQL keywords
        sql_keywords = {
            'SELECT', 'FROM', 'WHERE', 'JOIN', 'INNER', 'LEFT', 'RIGHT', 'FULL', 'OUTER',
            'ON', 'AS', 'AND', 'OR', 'NOT', 'IN', 'BETWEEN', 'LIKE', 'IS', 'NULL'
        }
        if name.upper() in sql_keywords:
            return False

        # Database schemas
        if name in self.detected_databases:
            return False

        # Obvious database names
        if re.match(r'^(main_db|analytics_db|test_db|prod_db|dev_db|momo)$', name):
            return False

        return True

    def create_expect_md_output(self, tables: List[str], joins: List[Dict[str, Any]], 
                           fields: List[Dict[str, Any]], where_conditions: List[str]) -> Dict[str, Any]:
        """ðŸŽ¯ Create final expect.md compliant output"""
        
        return {
            "success": True,
            "fields": fields,
            "tables": tables,
            "joins": joins,
            "whereConditions": where_conditions,
            "parser": "sqlsplit"  # âœ… CORRECTED: string format as per expect.md requirements
        }

# Helper functions for easy integration
def extract_content_from_sql(sql: str, table_aliases: Dict[str, str] = None, 
                           joins: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Extract all content from SQL for expect.md compliance"""
    
    extractor = ContentExtractor()
    
    if table_aliases:
        extractor.set_context(table_aliases)
    
    # Extract components
    group_by_fields = extractor.extract_group_by_fields(sql)
    fields = extractor.extract_fields(sql, group_by_fields)
    where_conditions = extractor.extract_where_conditions(sql)
    
    # Get tables from table_aliases keys and values
    tables = []
    if table_aliases:
        # Add actual table names (values)
        tables.extend(table_aliases.values())
        # Add any table names that appear in fields but not in aliases
        for field in fields:
            if field.get('table') and field['table'] not in tables:
                tables.append(field['table'])
    
    tables = sorted(list(set(tables))) if tables else []
    joins = joins if joins else []
    
    return extractor.create_expect_md_output(tables, joins, fields, where_conditions)

if __name__ == "__main__":
    print("ðŸ“¦ Content Extractor - SQL Parser AST v6.0")
    print("=" * 60)
    
    # Test content extraction
    test_sql = """
    SELECT `mt_item`.`DetailsID`, COUNT(*) AS `item_count`, 
           DATE_FORMAT(`mt_item`.`iCreateT`, '%Y-%m') AS `month`
    FROM `mt_item` 
    LEFT JOIN `mv_order` o ON `mt_item`.`Details_OrderID` = o.`OrderID`
    WHERE `mt_item`.`iDeleted` < 1
    GROUP BY `month`
    """
    
    extractor = ContentExtractor()
    extractor.set_context({'o': 'mv_order'})
    
    fields = extractor.extract_fields(test_sql, ['month'])
    where_conditions = extractor.extract_where_conditions(test_sql)
    group_by = extractor.extract_group_by_fields(test_sql)
    
    print(f"âœ… Extracted {len(fields)} fields")
    print(f"âœ… WHERE conditions: {where_conditions}")
    print(f"âœ… GROUP BY fields: {group_by}")
    print("\nðŸŽ¯ Ready for final AST integration!")
