Metadata-Version: 2.3
Name: echo-app
Version: 1.0.2
Summary: Echo AI - Multi-agent AI orchestration system with plugin management
License: MIT
Keywords: ai,agents,echo-ai,orchestration,coordination,langchain,langgraph,multi-agent,cli
Author: Jonas Kahn
Author-email: me@ifelse.one
Requires-Python: >=3.13,<3.14
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Framework :: FastAPI
Classifier: Environment :: Console
Classifier: Intended Audience :: System Administrators
Provides-Extra: dev
Requires-Dist: alembic (>=1.16.4,<2.0.0)
Requires-Dist: asyncpg (>=0.30.0,<0.31.0)
Requires-Dist: black (>=25.1.0,<26.0.0) ; extra == "dev"
Requires-Dist: echo-sdk (>=1.0.1,<2.0.0)
Requires-Dist: fastapi (>=0.116.1,<0.117.0)
Requires-Dist: greenlet (>=3.2.4,<4.0.0)
Requires-Dist: httpx (>=0.28.1,<0.29.0)
Requires-Dist: isort (>=6.0.1,<7.0.0) ; extra == "dev"
Requires-Dist: langchain (>=0.3.27,<0.4.0)
Requires-Dist: langchain-anthropic (>=0.3.18,<0.4.0)
Requires-Dist: langchain-community (>=0.3.27,<0.4.0)
Requires-Dist: langchain-core (>=0.3.74,<0.4.0)
Requires-Dist: langchain-google-genai (>=2.1.9,<3.0.0)
Requires-Dist: langchain-openai (>=0.3.30,<0.4.0)
Requires-Dist: langgraph-checkpoint-redis (>=0.1.0,<0.2.0)
Requires-Dist: langgraph[add] (>=0.6.5,<0.7.0)
Requires-Dist: mypy (>=1.17.1,<2.0.0) ; extra == "dev"
Requires-Dist: pre-commit (>=4.3.0,<5.0.0) ; extra == "dev"
Requires-Dist: psycopg2-binary (>=2.9.10,<3.0.0)
Requires-Dist: pydantic (>=2.11.7,<3.0.0)
Requires-Dist: pydantic-settings (>=2.10.1,<3.0.0)
Requires-Dist: pytest (>=8.4.1,<9.0.0) ; extra == "dev"
Requires-Dist: pytest-asyncio (>=1.1.0,<2.0.0) ; extra == "dev"
Requires-Dist: pytest-cov (>=6.2.1,<7.0.0) ; extra == "dev"
Requires-Dist: pytest-mock (>=3.14.1,<4.0.0) ; extra == "dev"
Requires-Dist: python-dotenv (>=1.1.1,<2.0.0)
Requires-Dist: redis (>=6.4.0,<7.0.0)
Requires-Dist: ruff (>=0.12.9,<0.13.0) ; extra == "dev"
Requires-Dist: sqlalchemy (>=2.0.43,<3.0.0)
Requires-Dist: streamlit (>=1.48.1,<2.0.0)
Requires-Dist: uvicorn[standard] (>=0.35.0,<0.36.0)
Project-URL: Documentation, https://echo.readthedocs.io/
Project-URL: Homepage, https://github.com/jonaskahn/echo
Project-URL: Repository, https://github.com/jonaskahn/echo.git
Project-URL: issues, https://github.com/jonaskahn/echo/issues
Description-Content-Type: text/markdown

# Echo AI ğŸ¤– Multi-Agent AI Framework

A powerful, plugin-based multi-agent conversational AI framework built on FastAPI and LangGraph, featuring intelligent
agent orchestration, efficient conversation storage, and comprehensive multi-provider LLM support.

## ğŸš€ Quick Start

### For End Users

```bash
# Install and start everything
pip install echo-app
python -m echo start all
```

### For Developers

```bash
# Clone and setup
git clone <your-repo-url>
cd echo
poetry install
python -m echo start all --debug
```

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Plugin Development](#-plugin-development)
- [Configuration](#-configuration)
- [Development](#-development)
- [Deployment](#-deployment)
- [Architecture](#-architecture)

## ğŸŒŸ Features

### ğŸ¤– Multi-Agent Orchestration

- **LangGraph-Based Coordination**: Intelligent conversation routing between specialized agents
- **Plugin System**: SDK-based agent discovery with hot reload capabilities
- **Safety Mechanisms**: Configurable limits for agent hops and tool calls
- **State Management**: Comprehensive conversation state tracking with checkpoint persistence

### ğŸ’¾ Storage Architecture

- **Conversation Turns**: Stores user input and AI responses with context
- **Multi-Backend Support**: PostgreSQL, Redis, and in-memory options
- **Token Tracking**: Precise cost attribution and optimization

### ğŸ§  Multi-Provider LLM Support

- **OpenAI**: GPT models with function calling
- **Anthropic**: Claude models with large context windows
- **Google**: Gemini models with multimodal capabilities
- **Azure OpenAI**: Enterprise-grade hosted models

### ğŸ–¥ï¸ Command Line Interface

- **Simple & Reliable**: Built with argparse for maximum compatibility
- **Service Orchestration**: Start multiple services with a single command
- **Development Tools**: Debug mode, custom ports, dependency checking

## ğŸ“¦ Installation

### Prerequisites

- **Python 3.13+**
- **Poetry** (for development)
- **PostgreSQL** (optional, for persistent storage)
- **Redis** (optional, for session storage)

### From PyPI (End Users)

```bash
pip install echo-app
```

### From Source (Developers)

```bash
git clone <your-repo-url>
cd echo
poetry install
```

## ğŸ¯ Usage

### Starting Services

```bash
# Start both API and UI servers
python -m echo start all

# Start only the API server
python -m echo start api

# Start only the UI server
python -m echo start ui

# Start with custom configuration
python -m echo start all --api-port 8080 --ui-port 8502

# Start with debug mode
python -m echo start all --debug
```

### CLI Commands

```bash
# Show version information
python -m echo version

# Show system information
python -m echo info

# List available plugins
python -m echo plugins

# Show help
python -m echo --help
python -m echo start --help
```

## ğŸ“– API Documentation

### Interactive Docs

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

### Core Endpoints

#### Chat Processing

```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Help me solve 2x + 5 = 15",
    "thread_id": "user-123-session",
    "user_id": "user-123"
  }'
```

#### Plugin Management

```bash
# List available plugins
curl "http://localhost:8000/api/v1/plugins"

# Get plugin details
curl "http://localhost:8000/api/v1/plugins/math_agent"

# Reload plugins (development)
curl -X POST "http://localhost:8000/api/v1/plugins/reload"
```

#### System Health

```bash
# Simple health check
curl "http://localhost:8000/api/v1/health"

# Detailed system status
curl "http://localhost:8000/api/v1/status"
```

## ğŸ”Œ Plugin Development

### Quick Plugin Example

Create a minimal plugin:

```python
# plugins/hello_agent/plugin.py
from echo_sdk.base.plugin import BasePlugin
from echo_sdk.base.metadata import PluginMetadata


class HelloPlugin(BasePlugin):
    @staticmethod
    def get_metadata() -> PluginMetadata:
        return PluginMetadata(
            name="hello_agent",
            version="0.1.0",
            description="Replies with a friendly greeting",
            capabilities=["greeting"],
        )

    @staticmethod
    def create_agent() -> BasePluginAgent:
        from .agent import HelloAgent
        return HelloAgent(HelloPlugin.get_metadata())
```

```python
# plugins/hello_agent/agent.py
from echo_sdk.base.agent import BasePluginAgent


class HelloAgent(BasePluginAgent):
    async def ainvoke(self, message: str) -> str:
        return f"Hello from {self.metadata.name}! You said: {message}"
```

### Plugin Structure

```
plugins/
â””â”€â”€ your_plugin/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ plugin.py      # Plugin contract and metadata
    â”œâ”€â”€ agent.py       # Agent implementation
    â””â”€â”€ tools.py       # Tool implementations
```

### Docker Compose Setup

```yaml
services:
  echo:
    build: ..
    ports:
      - "8000:8000"
      - "8501:8501"
    environment:
      - ECHO_DEFAULT_LLM_PROVIDER=openai
      - ECHO_PLUGINS_DIR=["/usr/src/echo/plugins"]
    volumes:
      - ../plugins:/usr/src/echo/plugins:ro
```

**Note**: The Docker setup uses the new CLI commands via supervisord to manage both API and UI services.

## âš™ï¸ Configuration

### Environment Variables

```bash
# LLM Provider
ECHO_DEFAULT_LLM_PROVIDER=openai
ECHO_OPENAI_API_KEY=your-openai-key
ECHO_ANTHROPIC_API_KEY=your-claude-key
ECHO_GOOGLE_API_KEY=your-gemini-key

# Database (optional - defaults to in-memory)
ECHO_CONVERSATION_STORAGE_BACKEND=memory  # or postgresql

# Plugin Configuration
ECHO_PLUGINS_DIR=["./plugins/src/echo_plugins"]

# API Server
ECHO_API_HOST=0.0.0.0
ECHO_API_PORT=8000
ECHO_DEBUG=true
```

### CLI Override

Most settings can be overridden via CLI arguments:

```bash
python -m echo start api --api-host 127.0.0.1 --api-port 8080 --debug
```

### Safety and Performance

```bash
# Agent Routing Limits
ECHO_MAX_AGENT_HOPS=25
ECHO_MAX_TOOL_HOPS=50
ECHO_GRAPH_RECURSION_LIMIT=50

# Session Management
ECHO_SESSION_TIMEOUT=3600
ECHO_MAX_SESSION_HISTORY=100
```

## ğŸ”§ Development

### Setup

```bash
# Install development dependencies
poetry install

# Run with auto-reload using CLI (recommended)
python -m echo start all --debug
```

### Development Commands

```bash
# Run tests
poetry run pytest

# Code formatting
poetry run black src/
poetry run isort src/

# Show detailed system information
echo info

# List and manage plugins
echo plugins
```

### Project Structure

```
echo/
â”œâ”€â”€ src/echo/                    # Main application code
â”‚   â”œâ”€â”€ api/                     # FastAPI routes and schemas
â”‚   â”œâ”€â”€ cli.py                   # Command-line interface (argparse)
â”‚   â”œâ”€â”€ core/                    # Multi-agent orchestration
â”‚   â”œâ”€â”€ domain/                  # Business models and DTOs
â”‚   â”œâ”€â”€ infrastructure/          # External service integrations
â”‚   â”œâ”€â”€ config/                  # Configuration management
â”‚   â””â”€â”€ ui/                      # Streamlit chat interface
â”œâ”€â”€ plugins/                     # Plugin ecosystem
â”œâ”€â”€ sdk/                         # Echo SDK for plugin development
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ migrations/                  # Database migrations
â”œâ”€â”€ deploy.sh                    # PyPI deployment script
â””â”€â”€ tests/                       # Test suite
```

## ğŸš€ Deployment

### Health Checks

```bash
# Load balancer health check
GET /api/v1/health
â†’ {"status": "healthy"}

# Detailed system status
GET /api/v1/status
â†’ {
  "status": "operational",
  "available_plugins": ["math_agent", "search_agent"],
  "healthy_plugins": ["math_agent", "search_agent"], 
  "failed_plugins": [],
  "total_sessions": 42
}
```

### Docker Deployment

```dockerfile
FROM python:3.13-slim

WORKDIR /app
COPY . .

RUN pip install poetry && poetry install
EXPOSE 8000 8501

# Use the CLI for better control
CMD ["poetry", "run", "echo", "start", "all"]
```

### PyPI Deployment (Maintainers)

```bash
# Deploy with patch version bump
./deploy.sh --patch

# Deploy with minor version bump
./deploy.sh --minor

# Deploy to TestPyPI first
./deploy.sh --test

# Deploy without version bump
./deploy.sh --no-bump
```

## ğŸ—ï¸ Architecture

### Framework Architecture

```
Echo AI Framework Architecture
â”œâ”€â”€ CLI Layer (argparse)
â”‚   â”œâ”€â”€ Service Management (start/stop api, ui, or both)
â”‚   â”œâ”€â”€ System Information (version, info, plugins)
â”‚   â””â”€â”€ Development Tools (debug mode, custom config)
â”œâ”€â”€ API Layer (FastAPI)
â”‚   â”œâ”€â”€ Chat Endpoints (/api/v1/chat)
â”‚   â”œâ”€â”€ Plugin Management (/api/v1/plugins)  
â”‚   â””â”€â”€ System Monitoring (/api/v1/status, /api/v1/health)
â”œâ”€â”€ Application Services
â”‚   â”œâ”€â”€ ConversationService (Complete conversation lifecycle)
â”‚   â”œâ”€â”€ OrchestratorService (LangGraph coordination wrapper)
â”‚   â””â”€â”€ ServiceContainer (Dependency injection and lifecycle)
â”œâ”€â”€ Core Orchestration
â”‚   â”œâ”€â”€ MultiAgentOrchestrator (LangGraph-based routing)
â”‚   â”œâ”€â”€ AgentState (Conversation state management)
â”‚   â””â”€â”€ Coordinator (Tool-routed graph execution)
â”œâ”€â”€ Domain Models
â”‚   â”œâ”€â”€ Thread (Conversation containers with cost tracking)
â”‚   â”œâ”€â”€ Conversation (User-assistant exchanges)
â”‚   â”œâ”€â”€ User & Organization (Multi-tenant support)
â”‚   â””â”€â”€ DTOs (Data transfer objects for API)
â””â”€â”€ Infrastructure
    â”œâ”€â”€ Database (Multi-backend: PostgreSQL/Redis/Memory)
    â”œâ”€â”€ LLM Factory (Multi-provider with caching)
    â””â”€â”€ Plugin Manager (SDK-based agent discovery)
```

### Storage Architecture

```
ğŸ“ Stores: User Input â†’ AI Response
ğŸ’¾ Storage: Conversation turns with context
ğŸ”„ Context: Full reconstruction capability for LangGraph
```

### Benefits

- **Efficient Storage**: Optimized conversation history management
- **Fast Loading**: Streamlined conversation history retrieval
- **Context Preservation**: Full LangGraph context reconstruction
- **Token Tracking**: Precise cost attribution and optimization

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes with proper documentation
4. Add tests for new functionality
5. Ensure all tests pass (`poetry run pytest`)
6. Run code formatting (`poetry run black src/ && poetry run isort src/`)
7. Commit your changes (`git commit -m 'Add amazing feature'`)
8. Push to the branch (`git push origin feature/amazing-feature`)
9. Open a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **LangGraph**: For powerful multi-agent orchestration capabilities
- **FastAPI**: For high-performance async API framework
- **Echo SDK**: For comprehensive plugin development support
- **Pydantic**: For robust data validation and serialization
- **Streamlit**: For interactive development interface

---

**Echo AI Framework** - Empowering intelligent multi-agent conversations with production-ready performance and
developer-friendly architecture.

