{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac3674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95df9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/585887642129215339', creation_time=1756220346330, experiment_id='585887642129215339', last_update_time=1756220346330, lifecycle_stage='active', name='Testing', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e7eb5",
   "metadata": {},
   "source": [
    "### Generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdec61d",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383941ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = generate(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ce22e",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = await generate.acall(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa17c80",
   "metadata": {},
   "source": [
    "### Tool Loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bc936",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import random\n",
    "from tinyloop.features.function_calling import Tool\n",
    "from tinyloop.modules.tool_loop import ToolLoop\n",
    "\n",
    "\n",
    "def roll_dice():\n",
    "    \"\"\"Roll a dice and return the result\"\"\"\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    last_roll: int\n",
    "    reached_goal: bool\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a dice rolling assistant.\n",
    "You should rool a dice until you get the number indicated in the prompt.\n",
    "You should use the function roll_dice to roll the dice.\n",
    "Before you roll the dice make sure to check if you have reached the goal.\n",
    "\n",
    "In the end, you should return the last roll.\n",
    "You should also return a boolean indicating if you reached the number indicated in the prompt or not.\n",
    "\"\"\"\n",
    "\n",
    "loop = ToolLoop(\n",
    "    model=\"openai/gpt-4.1\",\n",
    "    system_prompt=system_prompt,\n",
    "    temperature=0.1,\n",
    "    output_format=FinalAnswer,\n",
    "    tools=[\n",
    "        Tool(\n",
    "            roll_dice,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = loop(\n",
    "    prompt=\"Roll a dice until you get a 6\",\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7748497",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b840855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from tinyloop.features.function_calling import Tool\n",
    "from tinyloop.modules.tool_loop import ToolLoop\n",
    "import asyncio\n",
    "\n",
    "mlflow.config.enable_async_logging(True)\n",
    "\n",
    "\n",
    "async def roll_dice():\n",
    "    \"\"\"Roll a dice and return the result\"\"\"\n",
    "    await asyncio.sleep(3)\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    last_roll: int\n",
    "    reached_goal: bool\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a dice rolling assistant.\n",
    "You should rool a dice until you get the number indicated in the prompt.\n",
    "You should use the function roll_dice to roll the dice.\n",
    "Before you roll the dice make sure to check if you have reached the goal.\n",
    "\n",
    "In the end, you should return the last roll.\n",
    "You should also return a boolean indicating if you reached the number indicated in the prompt or not.\n",
    "\"\"\"\n",
    "\n",
    "loop = ToolLoop(\n",
    "    model=\"openai/gpt-4.1\",\n",
    "    system_prompt=system_prompt,\n",
    "    temperature=0.1,\n",
    "    output_format=FinalAnswer,\n",
    "    tools=[\n",
    "        Tool(\n",
    "            roll_dice,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = await loop.acall(\n",
    "    prompt=\"Roll a dice until you get a 6\",\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d561ded6",
   "metadata": {},
   "source": [
    "### Generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758dfec1",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = generate.call(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5cb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "Generate.run(\n",
    "    model=\"openai/gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    "    output_format=Characters,\n",
    "    prompt=\"Give me 3 harry potter characters\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e806da2",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4db005a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione Granger\\n3. Ron </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Weasley'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">raw_response</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModelResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-C8vSytURVuG9su18JOe8mq5tXVt5c'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1756243560</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4.1-nano-2025-04-14'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_c4c155951e'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choices</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Message</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Granger\\n3. Ron Weasley'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">provider_specific_fields</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "                <span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">provider_specific_fields</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Usage</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetailsWrapper</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">text_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetailsWrapper</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">text_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">image_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">message_history</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Give me 3 harry potter characters'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione Granger\\n3. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Ron Weasley'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">cost</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1599999999999999e-05</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">hidden_fields</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'custom_llm_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'region_name'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'headers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tue, 26 Aug 2025 21:26:00 GMT'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content-type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/json'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'transfer-encoding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chunked'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'connection'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'keep-alive'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'access-control-expose-headers'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'X-Request-ID'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'openai-organization'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lfm-l6lfkw'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'openai-processing-ms'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'364'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'openai-project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'proj_7yoQfLIduKm5aSVPH3fNz0C9'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'openai-version'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2020-10-01'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-envoy-upstream-service-time'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'455'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-limit-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'10000'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-limit-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'10000000'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-remaining-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9999'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-remaining-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9999989'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-reset-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6ms'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-reset-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0s'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-request-id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'req_a65b9f4c226941ccafbc9ad252f0c542'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'cf-cache-status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'DYNAMIC'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'strict-transport-security'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'max-age=31536000; includeSubDomains; preload'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-content-type-options'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'nosniff'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'server'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cloudflare'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'cf-ray'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'975667a93e0fbee0-YYC'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content-encoding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gzip'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'alt-svc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'h3=\":443\"; ma=86400'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'additional_headers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-limit-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'10000'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-remaining-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9999'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-limit-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'10000000'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'x-ratelimit-remaining-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9999989'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Tue, 26 Aug 2025 21:26:00 GMT'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-content-type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/json'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-transfer-encoding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chunked'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-connection'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'keep-alive'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-access-control-expose-headers'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'X-Request-ID'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-openai-organization'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lfm-l6lfkw'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-openai-processing-ms'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'364'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-openai-project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'proj_7yoQfLIduKm5aSVPH3fNz0C9'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-openai-version'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2020-10-01'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-envoy-upstream-service-time'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'455'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-ratelimit-limit-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'10000'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-ratelimit-limit-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'10000000'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-ratelimit-remaining-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9999'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-ratelimit-remaining-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9999989'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-ratelimit-reset-requests'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6ms'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-ratelimit-reset-tokens'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0s'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-request-id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'req_a65b9f4c226941ccafbc9ad252f0c542'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-cf-cache-status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'DYNAMIC'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-strict-transport-security'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'max-age=31536000; includeSubDomains; preload'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-x-content-type-options'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'nosniff'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-server'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cloudflare'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-cf-ray'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'975667a93e0fbee0-YYC'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-content-encoding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gzip'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider-alt-svc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'h3=\":443\"; ma=86400'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'optional_params'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'stream'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'extra_body'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_call_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'c63ad252-3313-4297-9689-04869a809cba'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'api_base'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://api.openai.com'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_id'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'response_cost'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1599999999999999e-05</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai/gpt-4.1-nano'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_overhead_time_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.777</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'_response_ms'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">714.947</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m'Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione Granger\\n3. Ron \u001b[0m\n",
       "\u001b[32mWeasley'\u001b[0m,\n",
       "    \u001b[33mraw_response\u001b[0m=\u001b[1;35mModelResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-C8vSytURVuG9su18JOe8mq5tXVt5c'\u001b[0m,\n",
       "        \u001b[33mcreated\u001b[0m=\u001b[1;36m1756243560\u001b[0m,\n",
       "        \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4.1-nano-2025-04-14'\u001b[0m,\n",
       "        \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "        \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_c4c155951e'\u001b[0m,\n",
       "        \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mChoices\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "                \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mmessage\u001b[0m=\u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mcontent\u001b[0m=\u001b[32m'Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione \u001b[0m\n",
       "\u001b[32mGranger\\n3. Ron Weasley'\u001b[0m,\n",
       "                    \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                    \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[33mprovider_specific_fields\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "                \u001b[1m)\u001b[0m,\n",
       "                \u001b[33mprovider_specific_fields\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33musage\u001b[0m=\u001b[1;35mUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m25\u001b[0m,\n",
       "            \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m16\u001b[0m,\n",
       "            \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m41\u001b[0m,\n",
       "            \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetailsWrapper\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mtext_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetailsWrapper\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "                \u001b[33mtext_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mimage_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmessage_history\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Give me 3 harry potter characters'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione Granger\\n3. \u001b[0m\n",
       "\u001b[32mRon Weasley'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcost\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.1599999999999999e-05\u001b[0m,\n",
       "    \u001b[33mhidden_fields\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'custom_llm_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
       "        \u001b[32m'region_name'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'headers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'date'\u001b[0m: \u001b[32m'Tue, 26 Aug 2025 21:26:00 GMT'\u001b[0m,\n",
       "            \u001b[32m'content-type'\u001b[0m: \u001b[32m'application/json'\u001b[0m,\n",
       "            \u001b[32m'transfer-encoding'\u001b[0m: \u001b[32m'chunked'\u001b[0m,\n",
       "            \u001b[32m'connection'\u001b[0m: \u001b[32m'keep-alive'\u001b[0m,\n",
       "            \u001b[32m'access-control-expose-headers'\u001b[0m: \u001b[32m'X-Request-ID'\u001b[0m,\n",
       "            \u001b[32m'openai-organization'\u001b[0m: \u001b[32m'lfm-l6lfkw'\u001b[0m,\n",
       "            \u001b[32m'openai-processing-ms'\u001b[0m: \u001b[32m'364'\u001b[0m,\n",
       "            \u001b[32m'openai-project'\u001b[0m: \u001b[32m'proj_7yoQfLIduKm5aSVPH3fNz0C9'\u001b[0m,\n",
       "            \u001b[32m'openai-version'\u001b[0m: \u001b[32m'2020-10-01'\u001b[0m,\n",
       "            \u001b[32m'x-envoy-upstream-service-time'\u001b[0m: \u001b[32m'455'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-limit-requests'\u001b[0m: \u001b[32m'10000'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-limit-tokens'\u001b[0m: \u001b[32m'10000000'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-remaining-requests'\u001b[0m: \u001b[32m'9999'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-remaining-tokens'\u001b[0m: \u001b[32m'9999989'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-reset-requests'\u001b[0m: \u001b[32m'6ms'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-reset-tokens'\u001b[0m: \u001b[32m'0s'\u001b[0m,\n",
       "            \u001b[32m'x-request-id'\u001b[0m: \u001b[32m'req_a65b9f4c226941ccafbc9ad252f0c542'\u001b[0m,\n",
       "            \u001b[32m'cf-cache-status'\u001b[0m: \u001b[32m'DYNAMIC'\u001b[0m,\n",
       "            \u001b[32m'strict-transport-security'\u001b[0m: \u001b[32m'max-\u001b[0m\u001b[32mage\u001b[0m\u001b[32m=\u001b[0m\u001b[32m31536000\u001b[0m\u001b[32m; includeSubDomains; preload'\u001b[0m,\n",
       "            \u001b[32m'x-content-type-options'\u001b[0m: \u001b[32m'nosniff'\u001b[0m,\n",
       "            \u001b[32m'server'\u001b[0m: \u001b[32m'cloudflare'\u001b[0m,\n",
       "            \u001b[32m'cf-ray'\u001b[0m: \u001b[32m'975667a93e0fbee0-YYC'\u001b[0m,\n",
       "            \u001b[32m'content-encoding'\u001b[0m: \u001b[32m'gzip'\u001b[0m,\n",
       "            \u001b[32m'alt-svc'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32mh3\u001b[0m\u001b[32m=\":443\"; \u001b[0m\u001b[32mma\u001b[0m\u001b[32m=\u001b[0m\u001b[32m86400\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'additional_headers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'x-ratelimit-limit-requests'\u001b[0m: \u001b[32m'10000'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-remaining-requests'\u001b[0m: \u001b[32m'9999'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-limit-tokens'\u001b[0m: \u001b[32m'10000000'\u001b[0m,\n",
       "            \u001b[32m'x-ratelimit-remaining-tokens'\u001b[0m: \u001b[32m'9999989'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-date'\u001b[0m: \u001b[32m'Tue, 26 Aug 2025 21:26:00 GMT'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-content-type'\u001b[0m: \u001b[32m'application/json'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-transfer-encoding'\u001b[0m: \u001b[32m'chunked'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-connection'\u001b[0m: \u001b[32m'keep-alive'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-access-control-expose-headers'\u001b[0m: \u001b[32m'X-Request-ID'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-openai-organization'\u001b[0m: \u001b[32m'lfm-l6lfkw'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-openai-processing-ms'\u001b[0m: \u001b[32m'364'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-openai-project'\u001b[0m: \u001b[32m'proj_7yoQfLIduKm5aSVPH3fNz0C9'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-openai-version'\u001b[0m: \u001b[32m'2020-10-01'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-envoy-upstream-service-time'\u001b[0m: \u001b[32m'455'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-ratelimit-limit-requests'\u001b[0m: \u001b[32m'10000'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-ratelimit-limit-tokens'\u001b[0m: \u001b[32m'10000000'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-ratelimit-remaining-requests'\u001b[0m: \u001b[32m'9999'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-ratelimit-remaining-tokens'\u001b[0m: \u001b[32m'9999989'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-ratelimit-reset-requests'\u001b[0m: \u001b[32m'6ms'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-ratelimit-reset-tokens'\u001b[0m: \u001b[32m'0s'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-request-id'\u001b[0m: \u001b[32m'req_a65b9f4c226941ccafbc9ad252f0c542'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-cf-cache-status'\u001b[0m: \u001b[32m'DYNAMIC'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-strict-transport-security'\u001b[0m: \u001b[32m'max-\u001b[0m\u001b[32mage\u001b[0m\u001b[32m=\u001b[0m\u001b[32m31536000\u001b[0m\u001b[32m; includeSubDomains; preload'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-x-content-type-options'\u001b[0m: \u001b[32m'nosniff'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-server'\u001b[0m: \u001b[32m'cloudflare'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-cf-ray'\u001b[0m: \u001b[32m'975667a93e0fbee0-YYC'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-content-encoding'\u001b[0m: \u001b[32m'gzip'\u001b[0m,\n",
       "            \u001b[32m'llm_provider-alt-svc'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32mh3\u001b[0m\u001b[32m=\":443\"; \u001b[0m\u001b[32mma\u001b[0m\u001b[32m=\u001b[0m\u001b[32m86400\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'optional_params'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'stream'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'extra_body'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'litellm_call_id'\u001b[0m: \u001b[32m'c63ad252-3313-4297-9689-04869a809cba'\u001b[0m,\n",
       "        \u001b[32m'api_base'\u001b[0m: \u001b[32m'https://api.openai.com'\u001b[0m,\n",
       "        \u001b[32m'model_id'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'response_cost'\u001b[0m: \u001b[1;36m1.1599999999999999e-05\u001b[0m,\n",
       "        \u001b[32m'litellm_model_name'\u001b[0m: \u001b[32m'openai/gpt-4.1-nano'\u001b[0m,\n",
       "        \u001b[32m'litellm_overhead_time_ms'\u001b[0m: \u001b[1;36m1.777\u001b[0m,\n",
       "        \u001b[32m'_response_ms'\u001b[0m: \u001b[1;36m714.947\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-958aab2cfa23c0dbf168dad8ec5bfd16&amp;experiment_id=585887642129215339&amp;version=3.3.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-958aab2cfa23c0dbf168dad8ec5bfd16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 15:26:00 WARNING mlflow.tracing.fluent: Failed to start span litellm-acompletion: None. For full traceback, set logging level to debug.\n"
     ]
    }
   ],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = await generate.acall(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5d7480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResponse(response='Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione Granger\\n3. Ron Weasley', raw_response=ModelResponse(id='chatcmpl-C8vSsBPBpqU7nZHQOFJwJao7RDeJR', created=1756243554, model='gpt-4.1-nano-2025-04-14', object='chat.completion', system_fingerprint='fp_c4c155951e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione Granger\\n3. Ron Weasley', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=25, prompt_tokens=16, total_tokens=41, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default'), tool_calls=None, message_history=[{'role': 'user', 'content': 'Give me 3 harry potter characters'}, {'role': 'assistant', 'content': 'Sure! Here are three Harry Potter characters:\\n\\n1. Harry Potter\\n2. Hermione Granger\\n3. Ron Weasley'}], cost=1.1599999999999999e-05, hidden_fields={'custom_llm_provider': 'openai', 'region_name': None, 'headers': {'date': 'Tue, 26 Aug 2025 21:25:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'lfm-l6lfkw', 'openai-processing-ms': '318', 'openai-project': 'proj_7yoQfLIduKm5aSVPH3fNz0C9', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '331', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999989', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_9f6e43f4e4e148e1a1054ad703cd0ebf', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=MKvb_iy_Sz5xWU2pLGd08jdhJeazfLWyH7AR8gnKZxU-1756243554-1.0.1.1-r6SP8b8cgES20JyXeV3puNnEDpGQM.mR1fhB7TaLIgycjoVnpIk8sHVoRBz6zrEYnq3RXMNu1QsLqK0_kA8GwUaEKigbiCN46REMkeOom4s; path=/; expires=Tue, 26-Aug-25 21:55:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=TevMNtBuEVkj3n5AzWHpQCpgaKg_iHXk.6LwqY9W6AM-1756243554755-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97566785ea22bee0-YYC', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'}, 'additional_headers': {'x-ratelimit-limit-requests': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-tokens': '9999989', 'llm_provider-date': 'Tue, 26 Aug 2025 21:25:54 GMT', 'llm_provider-content-type': 'application/json', 'llm_provider-transfer-encoding': 'chunked', 'llm_provider-connection': 'keep-alive', 'llm_provider-access-control-expose-headers': 'X-Request-ID', 'llm_provider-openai-organization': 'lfm-l6lfkw', 'llm_provider-openai-processing-ms': '318', 'llm_provider-openai-project': 'proj_7yoQfLIduKm5aSVPH3fNz0C9', 'llm_provider-openai-version': '2020-10-01', 'llm_provider-x-envoy-upstream-service-time': '331', 'llm_provider-x-ratelimit-limit-requests': '10000', 'llm_provider-x-ratelimit-limit-tokens': '10000000', 'llm_provider-x-ratelimit-remaining-requests': '9999', 'llm_provider-x-ratelimit-remaining-tokens': '9999989', 'llm_provider-x-ratelimit-reset-requests': '6ms', 'llm_provider-x-ratelimit-reset-tokens': '0s', 'llm_provider-x-request-id': 'req_9f6e43f4e4e148e1a1054ad703cd0ebf', 'llm_provider-cf-cache-status': 'DYNAMIC', 'llm_provider-set-cookie': '__cf_bm=MKvb_iy_Sz5xWU2pLGd08jdhJeazfLWyH7AR8gnKZxU-1756243554-1.0.1.1-r6SP8b8cgES20JyXeV3puNnEDpGQM.mR1fhB7TaLIgycjoVnpIk8sHVoRBz6zrEYnq3RXMNu1QsLqK0_kA8GwUaEKigbiCN46REMkeOom4s; path=/; expires=Tue, 26-Aug-25 21:55:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=TevMNtBuEVkj3n5AzWHpQCpgaKg_iHXk.6LwqY9W6AM-1756243554755-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'llm_provider-strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'llm_provider-x-content-type-options': 'nosniff', 'llm_provider-server': 'cloudflare', 'llm_provider-cf-ray': '97566785ea22bee0-YYC', 'llm_provider-content-encoding': 'gzip', 'llm_provider-alt-svc': 'h3=\":443\"; ma=86400'}, 'optional_params': {'temperature': 0.1, 'stream': False, 'extra_body': {}}, 'litellm_call_id': '13f865e5-8caa-4f38-9022-55c1dc783cca', 'api_base': 'https://api.openai.com', 'model_id': None, 'response_cost': 1.1599999999999999e-05, 'litellm_model_name': 'openai/gpt-4.1-nano', 'litellm_overhead_time_ms': 20.406, '_response_ms': 693.4})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-7a350dfb77eec3d308dfcc1e3deaba32&amp;experiment_id=585887642129215339&amp;version=3.3.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-7a350dfb77eec3d308dfcc1e3deaba32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 15:25:54 WARNING mlflow.tracing.fluent: Failed to start span litellm-acompletion: None. For full traceback, set logging level to debug.\n"
     ]
    }
   ],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "await Generate.arun(\n",
    "    model=\"openai/gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    "    output_format=Characters,\n",
    "    prompt=\"Give me 3 harry potter characters\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
