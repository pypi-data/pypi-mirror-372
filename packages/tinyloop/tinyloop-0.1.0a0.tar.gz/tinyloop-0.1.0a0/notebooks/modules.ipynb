{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e7eb5",
   "metadata": {},
   "source": [
    "### Generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdec61d",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383941ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = generate(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ce22e",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = await generate.acall(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa17c80",
   "metadata": {},
   "source": [
    "### Tool Loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bc936",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import random\n",
    "from tinyloop.features.function_calling import Tool\n",
    "from tinyloop.modules.tool_loop import ToolLoop\n",
    "\n",
    "\n",
    "def roll_dice():\n",
    "    \"\"\"Roll a dice and return the result\"\"\"\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    last_roll: int\n",
    "    reached_goal: bool\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a dice rolling assistant.\n",
    "You should rool a dice until you get the number indicated in the prompt.\n",
    "You should use the function roll_dice to roll the dice.\n",
    "Before you roll the dice make sure to check if you have reached the goal.\n",
    "\n",
    "In the end, you should return the last roll.\n",
    "You should also return a boolean indicating if you reached the number indicated in the prompt or not.\n",
    "\"\"\"\n",
    "\n",
    "loop = ToolLoop(\n",
    "    model=\"openai/gpt-4.1\",\n",
    "    system_prompt=system_prompt,\n",
    "    temperature=0.1,\n",
    "    output_format=FinalAnswer,\n",
    "    tools=[\n",
    "        Tool(\n",
    "            roll_dice,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = loop(\n",
    "    prompt=\"Roll a dice until you get a 6\",\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7748497",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b840855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from tinyloop.features.function_calling import Tool\n",
    "from tinyloop.modules.tool_loop import ToolLoop\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def roll_dice():\n",
    "    \"\"\"Roll a dice and return the result\"\"\"\n",
    "    await asyncio.sleep(1)\n",
    "    return random.randint(1, 6)\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    last_roll: int\n",
    "    reached_goal: bool\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a dice rolling assistant.\n",
    "You should rool a dice until you get the number indicated in the prompt.\n",
    "You should use the function roll_dice to roll the dice.\n",
    "Before you roll the dice make sure to check if you have reached the goal.\n",
    "\n",
    "In the end, you should return the last roll.\n",
    "You should also return a boolean indicating if you reached the number indicated in the prompt or not.\n",
    "\"\"\"\n",
    "\n",
    "loop = ToolLoop(\n",
    "    model=\"openai/gpt-4.1\",\n",
    "    system_prompt=system_prompt,\n",
    "    temperature=0.1,\n",
    "    output_format=FinalAnswer,\n",
    "    tools=[\n",
    "        Tool(\n",
    "            roll_dice,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "response = await loop.acall(\n",
    "    prompt=\"Roll a dice until you get a 6\",\n",
    "    parallel_tool_calls=False,\n",
    ")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d561ded6",
   "metadata": {},
   "source": [
    "### Generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758dfec1",
   "metadata": {},
   "source": [
    "#### Sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = generate(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e806da2",
   "metadata": {},
   "source": [
    "#### Async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyloop.modules.generate import Generate\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    image: str\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "\n",
    "generate = Generate(\n",
    "    model=\"openai/gpt-4.1-nano\", temperature=0.1, output_format=Characters\n",
    ")\n",
    "\n",
    "response = await generate.acall(prompt=\"Give me 3 harry potter characters\")\n",
    "rprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d7480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
