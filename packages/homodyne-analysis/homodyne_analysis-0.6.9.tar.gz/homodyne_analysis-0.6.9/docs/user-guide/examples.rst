Examples
========

Real-world examples demonstrating common use cases and workflows.

Example 1: Basic Isotropic Analysis
------------------------------------

**Scenario**: Quick analysis of an isotropic sample for preliminary results.

**Configuration** (``isotropic_example.json``):

.. code-block:: javascript

   {
     "metadata": {
       "sample_name": "polymer_solution",
       "analysis_mode": "static_isotropic"
     },
     "analysis_settings": {
       "static_mode": true,
       "static_submode": "isotropic"
     },
     "file_paths": {
       "c2_data_file": "data/polymer_c2_data.h5"
     },
     "initial_parameters": {
       "values": [1500, -0.8, 50]
     }
   }

**Command**:

.. code-block:: bash

   # Run classical analysis (results saved to ./homodyne_results/)
   python run_homodyne.py --config isotropic_example.json --method classical
   
   # Generate data validation plots only (saved to ./homodyne_results/exp_data/)
   python run_homodyne.py --config isotropic_example.json --plot-experimental-data
   
   # Run in quiet mode for batch processing
   python run_homodyne.py --config isotropic_example.json --method classical --quiet

**Expected Output**:

.. code-block:: text

   âœ… Analysis completed successfully
   ğŸ“Š Results summary:
   - Dâ‚€: 1423.5 Â± 45.2
   - Î±: -0.76 Â± 0.03  
   - D_offset: 62.1 Â± 8.9
   - Chi-squared: 1.23
   - Analysis time: 12.3s

Example 2: Flow Analysis with MCMC
-----------------------------------

**Scenario**: Complete analysis of a system under flow conditions with uncertainty quantification.

**Configuration** (``flow_mcmc_example.json``):

.. code-block:: javascript

   {
     "metadata": {
       "sample_name": "flowing_suspension",
       "analysis_mode": "laminar_flow"
     },
     "analysis_settings": {
       "static_mode": false,
       "enable_angle_filtering": true,
       "angle_filter_ranges": [[-5, 5], [175, 185]]
     },
     "file_paths": {
       "c2_data_file": "data/suspension_flow.h5",
       "phi_angles_file": "data/phi_angles_flow.txt"
     },
     "initial_parameters": {
       "parameter_names": ["D0", "alpha", "D_offset", "gamma_dot_t0", "beta", "gamma_dot_t_offset", "phi0"],
       "values": [2000, -1.0, 100, 15, 0.3, 2, 0],
       "active_parameters": ["D0", "alpha", "D_offset", "gamma_dot_t0"]
     },
     "optimization_config": {
       "mcmc_sampling": {
         "enabled": true,
         "draws": 3000,
         "tune": 1500,
         "chains": 4,
         "target_accept": 0.95
       },
       "scaling_parameters": {
         "fitted_range": {"min": 1.0, "max": 2.0},
         "theory_range": {"min": 0.0, "max": 1.0},
         "contrast": {"min": 0.05, "max": 0.5, "prior_mu": 0.3, "prior_sigma": 0.1, "type": "TruncatedNormal"},
         "offset": {"min": 0.05, "max": 1.95, "prior_mu": 1.0, "prior_sigma": 0.2, "type": "TruncatedNormal"}
       }
     }
   }

**Workflow**:

.. code-block:: bash

   # Step 1: Data validation (optional, saves to ./homodyne_results/exp_data/)
   python run_homodyne.py --config flow_mcmc_example.json --plot-experimental-data
   
   # Step 2: Classical optimization for initial estimates (saves to ./homodyne_results/classical/)
   python run_homodyne.py --config flow_mcmc_example.json --method classical
   
   # Step 3: MCMC sampling for uncertainty quantification (saves to ./homodyne_results/mcmc/)
   python run_homodyne.py --config flow_mcmc_example.json --method mcmc
   
   # Step 4: Complete analysis with both methods (recommended)
   python run_homodyne.py --config flow_mcmc_example.json --method all

**Expected Output**:

.. code-block:: text

   Classical Results:
   - Dâ‚€: 1876.3, Î±: -0.94, D_offset: 112.5, Î³Ì‡â‚€: 12.8
   - Chi-squared: 1.45
   
   MCMC Results:
   - Convergence: âœ… Excellent (RÌ‚ < 1.01)
   - Dâ‚€: 1876 Â± 89, Î±: -0.94 Â± 0.08
   - D_offset: 113 Â± 24, Î³Ì‡â‚€: 12.8 Â± 1.2
   - Posterior samples: 12,000

Example 3: Performance-Optimized Analysis
------------------------------------------

**Scenario**: Large dataset requiring optimized performance settings.

**Configuration** (``performance_example.json``):

.. code-block:: javascript

   {
     "analysis_settings": {
       "static_mode": true,
       "static_submode": "anisotropic", 
       "enable_angle_filtering": true,
       "angle_filter_ranges": [[-3, 3], [177, 183]]
     },
     "file_paths": {
       "c2_data_file": "data/large_dataset.h5",
       "phi_angles_file": "data/angles_high_res.txt"
     },
     "performance_settings": {
       "num_threads": 8,
       "data_type": "float32",
       "memory_limit_gb": 16,
       "enable_jit": true,
       "chunked_processing": true
     },
     "initial_parameters": {
       "values": [3000, -0.6, 200]
     }
   }

**Results**:

- **Memory usage**: Reduced by ~50% with float32
- **Speed improvement**: 3-4x faster with angle filtering
- **Accuracy**: Maintained with optimized angle ranges

Example 4: Batch Processing Multiple Samples
---------------------------------------------

**Scenario**: Process multiple samples with consistent parameters.

**Batch Script** (``batch_analysis.py``):

.. code-block:: python

   import os
   import json
   from homodyne import HomodyneAnalysisCore, ConfigManager
   
   # Sample list
   samples = [
       {"name": "sample_01", "file": "data/sample_01.h5"},
       {"name": "sample_02", "file": "data/sample_02.h5"},
       {"name": "sample_03", "file": "data/sample_03.h5"}
   ]
   
   # Base configuration
   base_config = {
       "analysis_settings": {
           "static_mode": True,
           "static_submode": "isotropic"
       },
       "initial_parameters": {
           "values": [1000, -0.5, 100]
       }
   }
   
   results = {}
   
   for sample in samples:
       print(f"Processing {sample['name']}...")
       
       # Create sample-specific config
       config = base_config.copy()
       config["file_paths"] = {"c2_data_file": sample["file"]}
       config["metadata"] = {"sample_name": sample["name"]}
       
       # Save temporary config
       config_file = f"temp_{sample['name']}.json"
       with open(config_file, 'w') as f:
           json.dump(config, f, indent=2)
       
       # Run analysis
       try:
           config_manager = ConfigManager(config_file)
           analysis = HomodyneAnalysisCore(config_manager)
           result = analysis.optimize_classical()
           
           results[sample['name']] = {
               "parameters": result.x,
               "chi_squared": result.fun,
               "success": result.success
           }
           
           print(f"âœ… {sample['name']}: Ï‡Â² = {result.fun:.3f}")
           
       except Exception as e:
           print(f"âŒ {sample['name']}: {str(e)}")
           results[sample['name']] = {"error": str(e)}
       
       # Cleanup
       os.remove(config_file)
   
   # Save batch results
   with open("batch_results.json", 'w') as f:
       json.dump(results, f, indent=2)
   
   print(f"Batch processing complete. Results saved to batch_results.json")

Example 5: Progressive Analysis Workflow
-----------------------------------------

**Scenario**: Systematic approach from simple to complex analysis.

**Workflow Script** (``progressive_analysis.py``):

.. code-block:: python

   from homodyne import HomodyneAnalysisCore, ConfigManager
   import json
   
   def progressive_analysis(data_file, angles_file):
       """
       Perform progressive analysis: isotropic â†’ anisotropic â†’ flow
       """
       
       results = {}
       
       # Step 1: Isotropic analysis (fastest)
       print("Step 1: Isotropic analysis...")
       iso_config = {
           "analysis_settings": {"static_mode": True, "static_submode": "isotropic"},
           "file_paths": {"c2_data_file": data_file},
           "initial_parameters": {"values": [1000, -0.5, 100]}
       }
       
       iso_result = run_analysis(iso_config, "isotropic")
       results["isotropic"] = iso_result
       
       # Step 2: Anisotropic analysis  
       print("Step 2: Anisotropic analysis...")
       aniso_config = iso_config.copy()
       aniso_config["analysis_settings"]["static_submode"] = "anisotropic"
       aniso_config["analysis_settings"]["enable_angle_filtering"] = True
       aniso_config["file_paths"]["phi_angles_file"] = angles_file
       
       aniso_result = run_analysis(aniso_config, "anisotropic")
       results["anisotropic"] = aniso_result
       
       # Compare isotropic vs anisotropic
       iso_chi2 = results["isotropic"]["chi_squared"]
       aniso_chi2 = results["anisotropic"]["chi_squared"]
       improvement = (iso_chi2 - aniso_chi2) / iso_chi2 * 100
       
       print(f"Chi-squared improvement: {improvement:.1f}%")
       
       # Step 3: Flow analysis (if significant improvement)
       if improvement > 5:  # 5% improvement threshold
           print("Step 3: Flow analysis...")
           flow_config = aniso_config.copy()
           flow_config["analysis_settings"]["static_mode"] = False
           flow_config["initial_parameters"] = {
               "parameter_names": ["D0", "alpha", "D_offset", "gamma_dot_t0", "beta", "gamma_dot_t_offset", "phi0"],
               "values": list(aniso_result["parameters"]) + [10, 0.5, 1, 0],
               "active_parameters": ["D0", "alpha", "D_offset", "gamma_dot_t0"]
           }
           
           flow_result = run_analysis(flow_config, "flow")
           results["flow"] = flow_result
       else:
           print("Skipping flow analysis - anisotropic improvement < 5%")
       
       return results
   
   def run_analysis(config_dict, mode_name):
       """Run analysis with given configuration"""
       config_file = f"temp_{mode_name}.json"
       
       with open(config_file, 'w') as f:
           json.dump(config_dict, f, indent=2)
       
       try:
           config = ConfigManager(config_file)
           analysis = HomodyneAnalysisCore(config)
           result = analysis.optimize_classical()
           
           return {
               "parameters": result.x.tolist(),
               "chi_squared": float(result.fun),
               "success": bool(result.success)
           }
       finally:
           import os
           if os.path.exists(config_file):
               os.remove(config_file)
   
   # Run progressive analysis
   if __name__ == "__main__":
       results = progressive_analysis(
           "data/my_sample.h5", 
           "data/my_angles.txt"
       )
       
       with open("progressive_results.json", 'w') as f:
           json.dump(results, f, indent=2)

Common Patterns
---------------

**Error Handling**:

.. code-block:: python

   try:
       analysis = HomodyneAnalysisCore(config)
       result = analysis.optimize_classical()
       
       if result.success:
           print(f"âœ… Optimization successful: Ï‡Â² = {result.fun:.3f}")
       else:
           print(f"âš ï¸ Optimization failed: {result.message}")
           
   except FileNotFoundError as e:
       print(f"âŒ File not found: {e}")
   except ValueError as e:
       print(f"âŒ Configuration error: {e}")

**Parameter Validation**:

.. code-block:: python

   def validate_parameters(params, mode="isotropic"):
       """Validate parameter values are physically reasonable"""
       
       if mode == "isotropic":
           D0, alpha, D_offset = params[:3]
           
           if not (100 <= D0 <= 10000):
               print(f"âš ï¸ D0 = {D0} may be outside typical range [100, 10000]")
           
           if not (-2.0 <= alpha <= 0.0):
               print(f"âš ï¸ Î± = {alpha} may be outside typical range [-2.0, 0.0]")
               
           if abs(D_offset) > 100:
               print(f"âš ï¸ D_offset = {D_offset} is outside typical range [-100, 100]")

**Result Comparison**:

.. code-block:: python

   def compare_results(result1, result2, labels=["Method 1", "Method 2"]):
       """Compare two analysis results"""
       
       chi2_1, chi2_2 = result1.fun, result2.fun
       improvement = (chi2_1 - chi2_2) / chi2_1 * 100
       
       print(f"{labels[0]} Ï‡Â²: {chi2_1:.4f}")
       print(f"{labels[1]} Ï‡Â²: {chi2_2:.4f}")
       print(f"Improvement: {improvement:+.1f}%")
       
       if improvement > 5:
           print("âœ… Significant improvement")
       elif improvement > 1:
           print("âš ï¸ Modest improvement") 
       else:
           print("âŒ No significant improvement")

Output Directory Structure
---------------------------

Starting from version 6.0, the analysis results are organized into method-specific subdirectories:

.. code-block:: text

   ./homodyne_results/
   â”œâ”€â”€ homodyne_analysis_results.json    # Main results file
   â”œâ”€â”€ run.log                           # Analysis log file
   â”œâ”€â”€ exp_data/                         # Experimental data plots (--plot-experimental-data)
   â”‚   â”œâ”€â”€ data_validation_phi_*.png
   â”‚   â””â”€â”€ summary_statistics.txt
   â”œâ”€â”€ classical/                       # Classical method outputs (--method classical)
   â”‚   â”œâ”€â”€ all_classical_methods_summary.json  # Summary of all classical methods
   â”‚   â”œâ”€â”€ nelder_mead/                  # Nelder-Mead method results
   â”‚   â”‚   â”œâ”€â”€ analysis_results_nelder_mead.json
   â”‚   â”‚   â”œâ”€â”€ parameters.json           # Parameters with uncertainties
   â”‚   â”‚   â”œâ”€â”€ fitted_data.npz          # Complete data (experimental, fitted, residuals)
   â”‚   â”‚   â””â”€â”€ c2_heatmaps_nelder_mead.png
   â”‚   â””â”€â”€ gurobi/                      # Gurobi method results
   â”‚       â”œâ”€â”€ analysis_results_gurobi.json
   â”‚       â”œâ”€â”€ parameters.json
   â”‚       â”œâ”€â”€ fitted_data.npz
   â”‚       â””â”€â”€ c2_heatmaps_gurobi.png
   â”œâ”€â”€ robust/                          # Robust method outputs (--method robust)
   â”‚   â”œâ”€â”€ all_robust_methods_summary.json  # Summary of all robust methods
   â”‚   â”œâ”€â”€ wasserstein/                 # Wasserstein robust method
   â”‚   â”‚   â”œâ”€â”€ analysis_results_wasserstein.json
   â”‚   â”‚   â”œâ”€â”€ parameters.json
   â”‚   â”‚   â”œâ”€â”€ fitted_data.npz
   â”‚   â”‚   â””â”€â”€ c2_heatmaps_wasserstein.png
   â”‚   â”œâ”€â”€ scenario/                    # Scenario-based robust method
   â”‚   â”‚   â””â”€â”€ [similar structure]
   â”‚   â””â”€â”€ ellipsoidal/                 # Ellipsoidal robust method
   â”‚       â””â”€â”€ [similar structure]
   â””â”€â”€ mcmc/                            # MCMC method outputs (--method mcmc)
       â”œâ”€â”€ fitted_data.npz              # Consolidated data (experimental, fitted, residuals, parameters)
       â”œâ”€â”€ mcmc_summary.json            # MCMC convergence diagnostics and posterior statistics
       â”œâ”€â”€ mcmc_trace.nc                # NetCDF trace data (ArviZ format)
       â”œâ”€â”€ c2_heatmaps_phi_*.png        # C2 correlation heatmaps using posterior means
       â”œâ”€â”€ 3d_surface_phi_*.png         # 3D surface plots with 95% confidence intervals
       â”œâ”€â”€ 3d_surface_residuals_phi_*.png # 3D residuals plots for quality assessment
       â”œâ”€â”€ trace_plot.png               # MCMC trace plots
       â””â”€â”€ corner_plot.png              # Parameter posterior distributions

**Key Changes**:

- **Main results file**: Now saved in output directory instead of current directory
- **Classical method**: Results organized in dedicated ``./homodyne_results/classical/`` subdirectory
- **MCMC method**: Results organized in dedicated ``./homodyne_results/mcmc/`` subdirectory  
- **Experimental data plots**: Saved to ``./homodyne_results/exp_data/`` when using ``--plot-experimental-data``
- **Data files**: Both classical and MCMC methods save experimental, fitted, and residuals data as ``.npz`` files
- **Method-specific outputs**:
  - **Classical**: Point estimates with C2 heatmaps (diagnostic plots skipped)
  - **MCMC**: Posterior distributions with trace data, convergence diagnostics, specialized plots, and 3D surface visualizations
- **3D visualization**: MCMC method automatically generates publication-quality 3D surface plots with confidence intervals
- **Fitted data calculation**: Both methods use least squares scaling optimization (``fitted = contrast * theory + offset``)
- **Plotting behavior**: The ``--plot-experimental-data`` flag now skips all fitting and exits immediately after plotting

Diagnostic Summary Visualizations
----------------------------------

The package automatically generates comprehensive diagnostic summary plots that combine multiple analysis components into a single visualization. These provide researchers with immediate feedback on analysis quality and method performance.

Main Diagnostic Summary Plot
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each analysis generates a main ``diagnostic_summary.png`` file in the root results directory (``./homodyne_results/diagnostic_summary.png``) with a **2Ã—3 grid layout** containing:

**Subplot 1: Method Comparison (Top Left)**
  - Bar chart comparing Ï‡Â² values across optimization methods
  - Log-scale Y-axis with scientific notation value labels
  - Color-coded methods (Nelder-Mead, Gurobi, Robust-Wasserstein, etc.)

**Subplot 2: Parameter Uncertainties (Top Middle)**
  - Horizontal bar chart of parameter uncertainties (Ïƒ)
  - Parameter names on Y-axis (amplitude, frequency, phase, etc.)
  - Grid lines for enhanced readability
  - Shows placeholder if uncertainties unavailable

**Subplot 3: MCMC Convergence Diagnostics (Top Right)**
  - RÌ‚ (R-hat) convergence assessment for MCMC methods
  - Color coding: Green (RÌ‚ < 1.1), Orange (1.1 â‰¤ RÌ‚ < 1.2), Red (RÌ‚ â‰¥ 1.2)
  - Dashed red line at RÌ‚ = 1.1 convergence threshold
  - Shows placeholder for classical-only methods

**Subplot 4: Residuals Distribution Analysis (Bottom, Full Width)**
  - Histogram of residuals (experimental - theoretical)
  - Overlaid normal distribution curve for comparison
  - Statistical summary with mean (Î¼) and standard deviation (Ïƒ)
  - Shows placeholder if residuals data unavailable

Method-Specific Diagnostic Summaries (Removed)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Note:** Method-specific diagnostic summary plots have been removed to reduce redundant output. Only the main ``diagnostic_summary.png`` is generated for ``--method all`` to provide meaningful cross-method comparisons.

Additional Visualization Outputs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**C2 Correlation Heatmaps** (``c2_heatmaps_*.png``)
  - 2D heatmaps of experimental vs theoretical correlation functions
  - Individual plots for each scattering angle (Ï† = 0Â°, 45Â°, 90Â°, 135Â°)
  - Method-specific versions for each optimization approach
  - Time axes (tâ‚, tâ‚‚) showing correlation delay times
  - Viridis colormap for correlation intensity visualization

**MCMC-Specific Plots** (when applicable)
  - ``trace_plot.png``: MCMC chain traces for convergence assessment
  - ``corner_plot.png``: Parameter posterior distributions and correlations

**Data Validation Plots** (``data_validation_*.png``)
  - Experimental data quality assessment plots
  - Individual plots for each scattering angle
  - 2D heatmaps and cross-sections of raw experimental data
  - Statistical summaries and data quality metrics

Key Features
~~~~~~~~~~~~

1. **Adaptive Content**: Appropriate placeholders shown when data unavailable
2. **Cross-Method Comparison**: Easy comparison of different optimization approaches  
3. **Quality Assessment**: Convergence and fitting quality metrics at a glance
4. **Statistical Analysis**: Residuals analysis and uncertainty quantification
5. **Professional Formatting**: Consistent styling with grid lines, proper labels, and legends

These diagnostic summaries provide immediate visual feedback on analysis quality, method performance, and parameter reliability, enabling researchers to quickly assess their results and identify potential issues.

Common Output Structure for All 5 Classical Methods
----------------------------------------------------

Each of the 5 optimization methods (``Nelder-Mead``, ``Gurobi``, ``Robust-Wasserstein``, ``Robust-Scenario``, ``Robust-Ellipsoidal``) generates standardized outputs for consistent analysis and comparison.

Individual Method Directory Structure
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: text

   ./homodyne_results/classical/
   â”œâ”€â”€ nelder_mead/
   â”œâ”€â”€ gurobi/
   â”œâ”€â”€ robust_wasserstein/
   â”œâ”€â”€ robust_scenario/
   â””â”€â”€ robust_ellipsoidal/

Per-Method Files
~~~~~~~~~~~~~~~~

Each method directory contains two primary files:

**parameters.json** - Human-readable parameter results
  Contains fitted parameter values with uncertainties, goodness-of-fit metrics (chi-squared, degrees of freedom), convergence information (iterations, function evaluations, termination status), and data statistics.

**fitted_data.npz** - Consolidated Numerical Data Archive

Complete data structure for each method:

.. code-block:: python

   import numpy as np
   
   # Load method-specific data
   data = np.load("fitted_data.npz")
   
   # Primary correlation function data
   c2_fitted = data["c2_fitted"]           # Method-specific fitted data (n_angles, n_t2, n_t1)
   c2_experimental = data["c2_experimental"] # Original experimental data (n_angles, n_t2, n_t1)
   residuals = data["residuals"]           # Method-specific residuals (n_angles, n_t2, n_t1)
   
   # Parameter and fit results
   parameters = data["parameters"]         # Fitted parameter values (n_params,)
   uncertainties = data["uncertainties"]   # Parameter uncertainties (n_params,)
   chi_squared = data["chi_squared"]       # Chi-squared goodness-of-fit (scalar)
   
   # Coordinate arrays
   phi_angles = data["phi_angles"]         # Angular coordinates (n_angles,) [degrees]
   t1 = data["t1"]                        # First correlation time array (n_t1,) [seconds]
   t2 = data["t2"]                        # Second correlation time array (n_t2,) [seconds]

**Key Features:**
  - **Consolidated structure**: All method-specific data in a single NPZ file per method
  - **Complete data access**: Experimental, fitted, and residual data together
  - **Coordinate information**: Full time and angular coordinate arrays included
  - **Statistical metadata**: Parameter uncertainties and goodness-of-fit metrics
  - **Consistent format**: Same structure across all optimization methods (classical, robust, MCMC)

**Array Dimensions:**
  - **Correlation functions**: ``(n_angles, n_t2, n_t1)`` - typically ``(4, 60-100, 60-100)``
  - **Parameters**: ``(n_params,)`` - 3 for static modes, 7 for laminar flow
  - **Time arrays**: ``(n_t1,)``, ``(n_t2,)`` - discretized with ``dt`` spacing
  - **Angles**: ``(n_angles,)`` - typically ``[0Â°, 45Â°, 90Â°, 135Â°]``

Method-Specific Characteristics
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Classical Methods (Nelder-Mead, Gurobi)**
  - Point estimates only with deterministic convergence metrics
  - Faster execution with iterations and function evaluations tracking  
  - Termination reasons and solver-specific status information
  - No built-in uncertainty quantification from optimization method

**Robust Methods (Wasserstein, Scenario, Ellipsoidal)**
  - Robust optimization against data uncertainty with worst-case guarantees
  - Additional robust-specific parameters (uncertainty radius, scenarios, confidence levels)
  - Convex optimization solver status codes and solve times
  - Enhanced reliability under data perturbations

Cross-Method Comparison
~~~~~~~~~~~~~~~~~~~~~~~

The ``all_classical_methods_summary.json`` and ``all_robust_methods_summary.json`` files provide easy comparison across all methods with:
  - Analysis timestamp and methods analyzed
  - Best method selection based on chi-squared values
  - Consolidated results showing parameters and goodness-of-fit for each method
  - Success status for each optimization approach

Data Array Structure
~~~~~~~~~~~~~~~~~~~~

All methods use consistent data array dimensions:
  - **Correlation data**: ``(n_angles, n_t2, n_t1)`` format
  - **Time arrays**: ``t1 = np.arange(n_t1) * dt`` and ``t2 = np.arange(n_t2) * dt``
  - **Individual angles**: ``(n_t2, n_t1)`` where rows=tâ‚‚, columns=tâ‚

This standardized structure enables direct comparison of optimization performance and facilitates automated analysis workflows across different methods.

MCMC Prior Distributions
------------------------

All parameters use **Normal distributions** in the MCMC implementation:

.. code-block:: python

   import pymc as pm
   
   # Standard prior distributions used in homodyne MCMC
   with pm.Model() as model:
       # All parameters use Normal distributions
       D0 = pm.Normal("D0", mu=1e4, sigma=1000.0)                      # Diffusion coefficient [Ã…Â²/s]
       alpha = pm.Normal("alpha", mu=-1.5, sigma=0.1)                 # Time exponent [dimensionless]
       D_offset = pm.Normal("D_offset", mu=0.0, sigma=10.0)            # Baseline diffusion [Ã…Â²/s]
       gamma_dot_t0 = pm.Normal("gamma_dot_t0", mu=1e-3, sigma=1e-2)   # Reference shear rate [sâ»Â¹]
       beta = pm.Normal("beta", mu=0.0, sigma=0.1)                     # Shear exponent [dimensionless]
       gamma_dot_t_offset = pm.Normal("gamma_dot_t_offset", mu=0.0, sigma=1e-3)  # Baseline shear [sâ»Â¹]
       phi0 = pm.Normal("phi0", mu=0.0, sigma=5.0)                     # Angular offset [degrees]

**Configuration Example:**

.. code-block:: json

   {
     "parameter_space": {
       "bounds": [
         {"name": "D0", "min": 1.0, "max": 1000000, "type": "Normal"},
         {"name": "alpha", "min": -2.0, "max": 2.0, "type": "Normal"},
         {"name": "D_offset", "min": -100, "max": 100, "type": "Normal"},
         {"name": "gamma_dot_t0", "min": 1e-6, "max": 1.0, "type": "Normal"},
         {"name": "beta", "min": -2.0, "max": 2.0, "type": "Normal"},
         {"name": "gamma_dot_t_offset", "min": -1e-2, "max": 1e-2, "type": "Normal"},
         {"name": "phi0", "min": -10, "max": 10, "type": "Normal"}
       ]
     }
   }

Example 6: Logging Control for Different Scenarios
----------------------------------------------------

**Scenario**: Using different logging modes for various use cases.

**Interactive Analysis** (default logging):

.. code-block:: bash

   # Normal interactive analysis with console and file logging
   homodyne --config my_config.json --method classical
   
   # With detailed debugging information
   homodyne --config my_config.json --method all --verbose

**Batch Processing** (quiet mode):

.. code-block:: bash

   # Process multiple samples quietly (logs only to files)
   for sample in sample_01 sample_02 sample_03; do
       homodyne --config configs/${sample}_config.json \
               --output-dir results/${sample} \
               --method classical \
               --quiet
   done

**Automated Scripts** (``batch_quiet_analysis.sh``):

.. code-block:: bash

   #!/bin/bash
   # Batch processing script with quiet logging
   
   SAMPLES_DIR="./data/samples"
   RESULTS_DIR="./results"
   
   for config_file in configs/*.json; do
       sample_name=$(basename "$config_file" .json)
       
       echo "Processing ${sample_name}..."
       
       # Run analysis in quiet mode
       homodyne --config "$config_file" \
               --output-dir "${RESULTS_DIR}/${sample_name}" \
               --method classical \
               --quiet
       
       # Check if analysis succeeded (logs are in file)
       if [ -f "${RESULTS_DIR}/${sample_name}/run.log" ]; then
           echo "âœ… ${sample_name}: Check ${RESULTS_DIR}/${sample_name}/run.log"
       else
           echo "âŒ ${sample_name}: Analysis failed"
       fi
   done
   
   echo "Batch processing complete. Check individual run.log files for details."

**Debugging Mode** (verbose logging):

.. code-block:: bash

   # Troubleshoot analysis with detailed logging
   homodyne --config problem_sample.json --method all --verbose
   
   # Debug MCMC convergence issues
   homodyne --config mcmc_issue.json --method mcmc --verbose

**Key Benefits**:

- **Default mode**: Best for interactive use, shows progress and errors
- **Verbose mode** (``--verbose``): Essential for troubleshooting and development
- **Quiet mode** (``--quiet``): Perfect for batch processing and automation
- **File logging**: Always enabled, provides complete analysis record

**Log File Locations**:

.. code-block:: text

   ./output_directory/
   â”œâ”€â”€ run.log                    # Complete analysis log
   â”œâ”€â”€ classical/                 # Classical method results
   â”œâ”€â”€ mcmc/                      # MCMC method results  
   â””â”€â”€ homodyne_analysis_results.json  # Main results

**Error Handling Note**: In quiet mode, errors are only logged to files, so check ``run.log`` files for troubleshooting.

Example 7: Performance Monitoring and Optimization
----------------------------------------------------

**Scenario**: Monitor and optimize performance with production-ready stability. The homodyne package has been rebalanced for excellent performance consistency with 97% reduction in chi-squared calculation variability.

**Advanced Performance Monitoring** (``performance_monitoring.py``):

.. code-block:: python

   from homodyne.core.config import performance_monitor
   from homodyne.tests.conftest_performance import (
       stable_benchmark,
       assert_performance_within_bounds
   )
   import time
   import numpy as np
   
   # Performance-monitored analysis function
   def analyze_sample_with_monitoring(config_file, output_dir):
       """Analyze sample with comprehensive performance monitoring."""
       from homodyne import HomodyneAnalysisCore, ConfigManager
       
       with performance_monitor.time_function("full_analysis"):
           config = ConfigManager(config_file)
           analyzer = HomodyneAnalysisCore(config)
           
           # Perform analysis with monitoring
           results = analyzer.optimize_classical()
           
       # Log performance summary
       performance_monitor.log_performance_summary()
       return results
   
   # Setup and warmup
   def setup_optimized_environment():
       """Setup optimized numerical environment."""
       # Initialize performance monitoring
       print("Setting up performance monitoring...")
       performance_monitor.reset_timings()
       
       print("âœ“ Performance monitoring initialized")
       print("âœ“ Numba available: True (JIT compilation enabled)")
       print("âœ“ Multi-threading enabled")
       
       return True
   
   # Performance benchmarking example
   def benchmark_analysis_performance():
       """Benchmark analysis performance with different strategies."""
       
       def sample_computation():
           """Sample computation for benchmarking."""
           # Simulate typical analysis computation
           data = np.random.rand(1000, 1000)
           result = np.sum(data @ data.T)
           time.sleep(0.001)  # Simulate I/O overhead
           return result
       
       print("=== Performance Benchmarking ===")
       
       # Standard stable benchmarking
       print("Running stable benchmark...")
       stable_results = stable_benchmark(
           sample_computation, 
           warmup_runs=5, 
           measurement_runs=15,
           outlier_threshold=2.0
       )
       
       cv_stable = stable_results['std'] / stable_results['mean']
       print(f"Stable benchmark: {stable_results['mean']:.4f}s Â± {cv_stable:.3f} CV")
       print(f"Outliers removed: {stable_results['outlier_count']}/{len(stable_results['times'])}")
       
       # Adaptive benchmarking
       print("Running adaptive benchmark...")
       adaptive_results = adaptive_stable_benchmark(
           sample_computation,
           target_cv=0.10,  # Target 10% coefficient of variation
           max_runs=30,
           min_runs=10
       )
       
       print(f"Adaptive benchmark: {adaptive_results['cv']:.3f} CV in {adaptive_results['total_runs']} runs")
       print(f"Target achieved: {adaptive_results['achieved_target']}")
       
       return stable_results, adaptive_results
   
   # Memory and cache monitoring
   def monitor_cache_performance():
       """Monitor smart cache performance."""
       cache = get_performance_cache()
       
       # Simulate some cached operations
       for i in range(10):
           key = f"test_data_{i}"
           data = np.random.rand(100, 100)
           cache.put(key, data)
       
       # Get cache statistics
       stats = cache.stats()
       print("=== Cache Performance ===")
       print(f"Cached items: {stats['items']}")
       print(f"Memory usage: {stats['memory_mb']:.1f} MB")
       print(f"Utilization: {stats['utilization']:.1%}")
       print(f"Memory utilization: {stats['memory_utilization']:.1%}")
       
       return stats
   
   # Complete performance analysis workflow
   def run_performance_analysis_example():
       """Complete example of performance-optimized analysis."""
       print("=== Homodyne Performance Analysis Example ===")
       
       # Step 1: Environment setup and warmup
       warmup_results, kernel_config = setup_optimized_environment()
       
       # Step 2: Performance benchmarking
       stable_results, adaptive_results = benchmark_analysis_performance()
       
       # Step 3: Cache monitoring
       cache_stats = monitor_cache_performance()
       
       # Step 4: Run sample analysis with monitoring
       # Note: This would need actual data files
       print("=== Sample Analysis (simulated) ===")
       
       def simulated_analysis():
           # Simulate analysis computation with performance monitoring
           with performance_monitor.time_function("simulated_analysis"):
               time.sleep(0.1)
           return {"chi_squared": 1.23, "parameters": [1.0, 0.1, 0.05]}
       
       result = simulated_analysis()
       print(f"Analysis result: {result}")
       
       # Step 5: Get comprehensive performance summary
       summary = get_performance_summary()
       print("=== Performance Summary ===")
       
       if summary:
           for func_name, stats in summary.items():
               if isinstance(stats, dict) and "calls" in stats:
                   print(f"{func_name}:")
                   print(f"  Calls: {stats['calls']}")
                   print(f"  Avg time: {stats['avg_time']:.4f}s")
                   print(f"  Total time: {stats['total_time']:.4f}s")
       
       # Performance achievements and recommendations  
       print("=== Performance Stability Achievements ===")
       print("âœ“ Chi-squared calculations: CV < 0.31 across all array sizes")
       print("âœ“ 97% reduction in performance variability achieved")
       print("âœ“ Conservative threading (max 4 cores) for optimal stability")
       print("âœ“ Balanced JIT optimization for numerical precision")
       
       print("=== Performance Recommendations ===")
       
       if warmup_results.get('total_warmup_time', 0) > 2.0:
           print("âš  Consider caching warmup results for faster startup")
       
       if cv_stable > 0.31:  # Updated threshold reflecting rebalanced performance
           print("âš  Performance variability above rebalanced threshold - check system load")
       elif cv_stable < 0.10:
           print("âœ“ Excellent stability achieved (CV < 0.10)")
       
       if cache_stats['memory_utilization'] > 0.80:
           print("âš  Cache memory usage high - consider increasing max_memory_mb")
       
       print("âœ“ Performance analysis complete")
       
       return {
           'warmup': warmup_results,
           'kernel_config': kernel_config,
           'benchmarks': {'stable': stable_results, 'adaptive': adaptive_results},
           'cache_stats': cache_stats,
           'performance_summary': summary
       }
   
   # Run the complete example
   if __name__ == "__main__":
       results = run_performance_analysis_example()

**Configuration for Performance Monitoring** (``performance_config.json``):

.. code-block:: json

   {
     "performance_settings": {
       "numba_optimization": {
         "enable_numba": true,
         "warmup_numba": true,
         "stability_enhancements": {
           "enable_kernel_warmup": true,
           "warmup_iterations": 5,
           "optimize_memory_layout": true,
           "environment_optimization": {
             "auto_configure": true,
             "max_threads": 8,
             "gc_optimization": true
           }
         },
         "performance_monitoring": {
           "enable_profiling": true,
           "adaptive_benchmarking": true,
           "target_cv": 0.10,
           "memory_monitoring": true,
           "smart_caching": {
             "enabled": true,
             "max_items": 200,
             "max_memory_mb": 1000.0
           }
         }
       }
     }
   }

**Key Performance Features Demonstrated**:

- **JIT Warmup**: Pre-compile kernels for stable performance
- **Adaptive Benchmarking**: Automatically find optimal measurement counts  
- **Memory Monitoring**: Track and optimize memory usage
- **Smart Caching**: Memory-aware LRU caching with cleanup
- **Performance Profiling**: Comprehensive monitoring and statistics
- **Environment Optimization**: Automatic BLAS/threading configuration

Next Steps
----------

- Explore the :doc:`../api-reference/core` for advanced programmatic usage
- Review :doc:`../developer-guide/performance` for optimization strategies
- Check :doc:`../developer-guide/troubleshooting` if you encounter issues