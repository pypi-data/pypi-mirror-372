8.20

### now 

### admin
[ ] update readme: cool examples + how-tos (see scratch/readme/README-working.md + notes#8.26)
[x] register the pypi package
    [x] build the package 
        [x] name = innocuous
        [x] dependencies: remove numpy (?)
    [x] upload with twine
    -> it installs, yay!
[ ] finalize 0.2.1
    [x] readme in progress as best as can
        [x] add some uv workflow commands to notes (make separate file)
    [x] add license
    [x] dev-summary v0.2.0
    [ ] finalize
        [ ] merge
        [ ] tag
        [ ] push
        [ ] build
        [ ] add to release writeups

### core functionality
[ ] pattern to pass param to the accept functions
[ ] re-insert punctuation at decode time
[ ] headers for length (this opens up many feats)
[ ] nonce (see notes for ideas on this)
[ ] error correction encoding
[ ] need to allow a natural ending to poems
[ ] how to deal with arbitrarily close (e.g. choices 5-8 are all < 1e-6)

### misc / other
[ ] uv workflow, how to uninstall publish group from pip?
[ ] --version for pkg
[ ] optional dep-groups: dev, test, extras
[ ] cli encode: print(repr(generated_text))
[ ] add bash scripts for cli in examples
[ ] stdout vs stderr logging
[ ] script to ruff format + rebase (also how to select which dirs)
[ ] add types to main_encode, main_decode args + return type and better docstring
[ ] add default values for params in main_enc / main_dec
[ ] add mem debug lines for llm-check
[ ] run it on coder-1, do batch examples
[ ] unicode code coloring for each token (accepted, and or encoded)
[ ] could deal with conflicts at the encoding step too
[ ] structured log (enables test mocking)
[ ] pass arbitrary kwargs to create_llm_client, e.g. make context larger
[x] ruff format
[ ] add more tests: mark.slow 

### examples
[x] create wizards example -> innoucuous/external-repo/wiz1.py + prompt1.txt
[ ] code generation, e.g. create an example of class instantiation
[ ] encrypting message ahead of time

### misc
[ ] just generate at a temperature (so we can compare against our encoded poems)

### niceties
[ ] build unit tests w/ mocks based off generated data
[ ] logging module which saves all the top tokens
[ ] analysis of wordcount by parameters
[ ] llm.utils.llama_log_set: import as a callback ()

### done
[x] create a jupyter notebook in examples
[x] gitignore scripts/ dir
[x] allow text for message
[x] subcommand check-llm
[x] how to load model_path (env var)
    [~] also load from .env
    [x] add a cli arg
    [x] add status check (llm.interaface:demo)
    [x] update examples
[x] finalize v0.2
    - note: we can bump things to v0.2.0
    [x] version bump + uv sync
    [x] tag 0.2
    [x] push code on master + tags to gh
[~] p2pkh.v2.chunk3 has an err, but succeeds, why?
    [x] dry-run rebase -> works, but we might have conflict on .public-agdocs
    [x] task-a
    [x] manual updates
    [x] task-b
        [x] push both good branches
    [x] reabse to v2
[x] package refactor
    -> tmp/a -> tmp/b -> tmp/c
    uv pip install -e .  (install stego_llm)
    [x] review package modules
        x rm llm/core.py
        x rm llm/utils.py
        x stego/filters:_acceptance_criteria
    [x] remove main.py's in src/
    [x] move books to gitignored        -> tmp/c
    [x] ruff format                     -> tmp/d

[x] add a tests directory
[x] cli for control
    [x] create outside repo to test ../external-repo
    [x] build spec
    [x] add pytest config to run on tests/ dir
    -> fix on tmp/e

[x] able to turn on/off debug logging from another script
[x] generate v3: 2/3/4
    [x] double space rendering
    [x] check line breaks are preserved on gh
[x] test without re-init llm -> yup still breaks
[x] chunk_size=4 example -> it is almost limerick size but seems like its translated
[x] docs: examples + readme update
[x] filter punctuation pre and post accept
    [x] encode
    - ready to go on a agro task with example_decode_test()
    [x] decode 
[x] prove that examples work (not just silently fail)
    -> tmp/verify
    [x] simple example
    [x] reproduce the branch for all + above (looks good)
    - note this was likely an OOM exit
[x] allow selecting needed tokens / punctuations above a threshold
    [x] collect examples:
    [x] allow "\n" to be selected in filter_tok()
    [x] main_decode: for -> while 
    [x] top_punctuation
    [x] high_thresh


### core
[x] encoding example
[x] decoding example
[x] refactor enc + dec
[x] n_vocab for mistral
[x] pre-select / post-select hooks
[~] deploy to web




8.19

### llm proof-of-concept
[x] src/ runs
[x] src/ runs w/o logging

### docs + assets
[x] readme for documentation
    - how to setup jupyter nb + uv
[x] organize folder:

### prototype
[x] simple.py with weights