"""
RFS Framework í…ŒìŠ¤íŠ¸ ì„¤ì • ë° ê³µí†µ fixture

ì´ ëª¨ë“ˆì€ ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” fixtureì™€ ì„¤ì •ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import asyncio
import logging
import os
import tempfile
from typing import Any, AsyncGenerator, Dict, Generator
from unittest.mock import AsyncMock, MagicMock

import pytest

# Test environment setup
os.environ["RFS_ENV"] = "test"
os.environ["LOG_LEVEL"] = "DEBUG"

# Disable logging during tests unless explicitly needed
logging.getLogger("rfs").setLevel(logging.CRITICAL)


# ì„¸ì…˜ ë ˆë²¨ ì´ë²¤íŠ¸ ë£¨í”„ ì œê±° - pytest-asyncioê°€ ìë™ìœ¼ë¡œ í•¨ìˆ˜ ë ˆë²¨ì—ì„œ ê´€ë¦¬
# @pytest.fixture(scope="session")
# def event_loop():
#     """ì´ë²¤íŠ¸ ë£¨í”„ fixture - ì „ì²´ í…ŒìŠ¤íŠ¸ ì„¸ì…˜ìš©"""
#     loop = asyncio.new_event_loop()
#     yield loop
#     loop.close()


@pytest.fixture
def temp_dir() -> Generator[str, None, None]:
    """ì„ì‹œ ë””ë ‰í† ë¦¬ fixture"""
    with tempfile.TemporaryDirectory() as tmp_dir:
        yield tmp_dir


@pytest.fixture
def sample_config() -> Dict[str, Any]:
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì„¤ì •"""
    return {
        "database": {"url": "sqlite:///test.db", "pool_size": 5, "echo": False},
        "cache": {"type": "memory", "ttl": 300, "max_size": 1000},
        "messaging": {"broker": "memory", "queue_size": 100},
        "logging": {
            "level": "INFO",
            "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        },
    }


@pytest.fixture
def mock_redis() -> MagicMock:
    """Mock Redis í´ë¼ì´ì–¸íŠ¸"""
    mock = MagicMock()
    mock.get.return_value = None
    mock.set.return_value = True
    mock.delete.return_value = 1
    mock.exists.return_value = False
    mock.ttl.return_value = -1
    mock.ping.return_value = True
    mock.pipeline.return_value = mock
    mock.execute.return_value = []
    mock.watch.return_value = None
    mock.multi.return_value = None
    return mock


@pytest.fixture
def mock_database_connection() -> MagicMock:
    """Mock ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    mock = MagicMock()
    mock.begin.return_value = mock
    mock.commit.return_value = None
    mock.rollback.return_value = None
    mock.close.return_value = None
    mock.execute.return_value = MagicMock()
    mock.fetchone.return_value = None
    mock.fetchall.return_value = []
    mock.__enter__ = MagicMock(return_value=mock)
    mock.__exit__ = MagicMock(return_value=None)
    return mock


@pytest.fixture
def mock_transaction_manager() -> MagicMock:
    """Mock íŠ¸ëœì­ì…˜ ë§¤ë‹ˆì €"""
    mock = MagicMock()
    mock.begin.return_value = MagicMock()
    mock.commit.return_value = None
    mock.rollback.return_value = None
    mock.get_current.return_value = None
    mock.is_active.return_value = False
    return mock


@pytest.fixture
def in_memory_db_engine():
    """ì¸ë©”ëª¨ë¦¬ SQLite ì—”ì§„ fixture (mock)"""
    mock = MagicMock()
    mock.dispose.return_value = None
    return mock


@pytest.fixture
async def async_in_memory_db():
    """ë¹„ë™ê¸° ì¸ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ fixture (mock)"""
    mock_engine = MagicMock()
    mock_session = MagicMock()

    yield {"engine": mock_engine, "session": mock_session}


@pytest.fixture
def mock_message_broker():
    """Mock ë©”ì‹œì§€ ë¸Œë¡œì»¤"""

    class MockBroker:
        def __init__(self):
            self.messages = []
            self.subscribers = {}
            self.is_connected = True

        async def publish(self, topic: str, message: Any):
            self.messages.append({"topic": topic, "message": message})

        async def subscribe(self, topic: str, handler):
            if topic not in self.subscribers:
                self.subscribers[topic] = []
            self.subscribers[topic].append(handler)

        async def connect(self):
            self.is_connected = True

        async def disconnect(self):
            self.is_connected = False

    return MockBroker()


@pytest.fixture
def sample_data():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°"""
    return {
        "users": [
            {"id": 1, "name": "ê¹€ì² ìˆ˜", "email": "kim@example.com", "age": 30},
            {"id": 2, "name": "ì´ì˜í¬", "email": "lee@example.com", "age": 25},
            {"id": 3, "name": "ë°•ë¯¼ìˆ˜", "email": "park@example.com", "age": 35},
        ],
        "products": [
            {"id": 1, "name": "ë…¸íŠ¸ë¶", "price": 1500000, "category": "ì „ìì œí’ˆ"},
            {"id": 2, "name": "ë§ˆìš°ìŠ¤", "price": 50000, "category": "ì „ìì œí’ˆ"},
            {"id": 3, "name": "ì±…ìƒ", "price": 200000, "category": "ê°€êµ¬"},
        ],
        "orders": [
            {"id": 1, "user_id": 1, "product_id": 1, "quantity": 1, "total": 1500000},
            {"id": 2, "user_id": 2, "product_id": 2, "quantity": 2, "total": 100000},
        ],
    }


@pytest.fixture
def mock_async_function():
    """ë¹„ë™ê¸° í•¨ìˆ˜ mock"""
    return AsyncMock()


@pytest.fixture
def performance_timer():
    """ì„±ëŠ¥ ì¸¡ì •ìš© íƒ€ì´ë¨¸"""
    import time

    class Timer:
        def __init__(self):
            self.start_time = None
            self.end_time = None

        def start(self):
            self.start_time = time.perf_counter()

        def stop(self):
            self.end_time = time.perf_counter()

        @property
        def elapsed(self):
            if self.start_time and self.end_time:
                return self.end_time - self.start_time
            return None

    return Timer()


@pytest.fixture
def edge_case_data():
    """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ë°ì´í„°"""
    return {
        "empty_values": ["", None, [], {}, set()],
        "large_values": {
            "string": "a" * 10000,
            "number": 2**63 - 1,
            "list": list(range(10000)),
            "dict": {f"key_{i}": f"value_{i}" for i in range(1000)},
        },
        "unicode_values": ["ğŸš€", "í•œê¸€", "ğŸ”¥ğŸ’¯", "Ã‰mojis", "ä¸­æ–‡"],
        "special_characters": ["\n", "\t", "\r", "\\", "'", '"', "&", "<", ">"],
    }


@pytest.fixture
def error_scenarios():
    """ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°"""
    return {
        "network_errors": [ConnectionError, TimeoutError, OSError],
        "data_errors": [ValueError, TypeError, KeyError],
        "business_errors": ["INSUFFICIENT_BALANCE", "INVALID_USER", "EXPIRED_TOKEN"],
        "system_errors": [MemoryError, PermissionError, FileNotFoundError],
    }


@pytest.fixture(autouse=True)
def setup_test_environment():
    """ê° í…ŒìŠ¤íŠ¸ ì „í›„ í™˜ê²½ ì„¤ì •"""
    # í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ ì„¤ì •
    original_env = os.environ.copy()

    yield

    # í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬
    os.environ.clear()
    os.environ.update(original_env)


# Cloud Run ì „ìš© í”½ìŠ¤ì²˜ë“¤ ì¶”ê°€
@pytest.fixture(autouse=True)
def reset_cloud_run_singletons():
    """ê° í…ŒìŠ¤íŠ¸ í›„ Cloud Run ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë“¤ ì´ˆê¸°í™”"""
    yield

    # ì‹±ê¸€í†¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì •ë¦¬
    try:
        from rfs.core.singleton import SingletonMeta

        SingletonMeta._instances = {}
    except ImportError:
        pass


@pytest.fixture
def clean_environment():
    """í™˜ê²½ ë³€ìˆ˜ ì •ë¦¬ëœ ìƒíƒœ ì œê³µ"""
    cloud_run_vars = [
        "K_SERVICE",
        "K_REVISION",
        "K_CONFIGURATION",
        "GOOGLE_CLOUD_PROJECT",
        "GOOGLE_CLOUD_REGION",
        "CLOUD_RUN_REGION",
        "PORT",
        "CLOUD_RUN_JOB",
    ]

    # ê¸°ì¡´ ê°’ë“¤ ë°±ì—…
    backup = {}
    for var in cloud_run_vars:
        if var in os.environ:
            backup[var] = os.environ[var]
            del os.environ[var]

    yield

    # í™˜ê²½ ë³€ìˆ˜ ë³µì›
    for var, value in backup.items():
        os.environ[var] = value


@pytest.fixture
def mock_cloud_run_environment():
    """Mock Cloud Run í™˜ê²½ ì œê³µ"""
    env_vars = {
        "K_SERVICE": "test-service",
        "K_REVISION": "test-service-00001-abc",
        "K_CONFIGURATION": "test-service",
        "GOOGLE_CLOUD_PROJECT": "test-project-123",
        "GOOGLE_CLOUD_REGION": "asia-northeast3",
        "PORT": "8080",
    }

    from unittest.mock import patch

    with patch.dict(os.environ, env_vars):
        yield env_vars


@pytest.fixture
def isolated_monitoring_client():
    """ê²©ë¦¬ëœ ëª¨ë‹ˆí„°ë§ í´ë¼ì´ì–¸íŠ¸ ì œê³µ"""
    from rfs.cloud_run.helpers import CloudMonitoringClient

    # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ê°•ì œ ìƒì„±
    if hasattr(CloudMonitoringClient, "_instances"):
        CloudMonitoringClient._instances.clear()

    client = CloudMonitoringClient()
    client._metrics = []
    client._logs = []

    yield client

    # ì •ë¦¬
    if hasattr(CloudMonitoringClient, "_instances"):
        CloudMonitoringClient._instances.clear()


@pytest.fixture
def isolated_task_queue():
    """ê²©ë¦¬ëœ ì‘ì—… í ì œê³µ"""
    from rfs.cloud_run.helpers import CloudTaskQueue

    # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ê°•ì œ ìƒì„±
    if hasattr(CloudTaskQueue, "_instances"):
        CloudTaskQueue._instances.clear()

    queue = CloudTaskQueue()
    queue._queue = []
    queue._processing = False

    yield queue

    # ì •ë¦¬
    if hasattr(CloudTaskQueue, "_instances"):
        CloudTaskQueue._instances.clear()


@pytest.fixture
def isolated_service_discovery():
    """ê²©ë¦¬ëœ ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ì œê³µ"""
    from rfs.cloud_run.helpers import CloudRunServiceDiscovery

    # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ê°•ì œ ìƒì„±
    if hasattr(CloudRunServiceDiscovery, "_instances"):
        CloudRunServiceDiscovery._instances.clear()

    discovery = CloudRunServiceDiscovery()
    discovery._services = {}
    discovery._initialized = False

    yield discovery

    # ì •ë¦¬
    if hasattr(CloudRunServiceDiscovery, "_instances"):
        CloudRunServiceDiscovery._instances.clear()


# ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë§ˆì»¤ë“¤
def pytest_configure(config):
    """ì»¤ìŠ¤í…€ ë§ˆì»¤ ë“±ë¡"""
    config.addinivalue_line(
        "markers", "slow: marks tests as slow (deselect with '-m \"not slow\"')"
    )
    config.addinivalue_line("markers", "integration: marks tests as integration tests")
    config.addinivalue_line("markers", "unit: marks tests as unit tests")
    config.addinivalue_line("markers", "cloud_run: marks tests as cloud run specific")


# Parametrize helpers - ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”
# def pytest_generate_tests(metafunc):
#     """ë™ì  ë§¤ê°œë³€ìˆ˜ ìƒì„±"""
#     if "concurrency_level" in metafunc.fixturenames:
#         metafunc.parametrize("concurrency_level", [1, 5, 10, 50, 100])
#
#     if "cache_size" in metafunc.fixturenames:
#         metafunc.parametrize("cache_size", [10, 100, 1000, 10000])
#
#     if "data_size" in metafunc.fixturenames:
#         metafunc.parametrize("data_size", ["small", "medium", "large"])
