import os
import threading
import json
import traceback
import pandas as pd
from datetime import datetime
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Callable, Optional

from libentry.mcp import api
from libentry import logger

from evaluation_service_base.charts.dtypes import BaseChart
from evaluation_service_base.core.common import BaseEvaluationServiceConfig, EvaluationContext, \
    EvaluationServiceInputParams, EvaluationData, EvaluationResults, BaseEvaluationRaw
from evaluation_service_base.core.constants import ProgressConstants
from evaluation_service_base.core.enum import EvaluationStep, TaskStatus
from evaluation_service_base.core.exceptions import TaskCancelledException
from evaluation_service_base.core.managers import StepProgressManager
from evaluation_service_base.core.reporters import StepProgressReporter
from evaluation_service_base.utils.minio_client import MinioClient, MinioConfig
from evaluation_service_base.utils.s3_handler import S3DataHandler


class BaseEvaluationService(ABC, S3DataHandler):
    """è¯„ä¼°æœåŠ¡åŸºç±»"""

    def __init__(self, config: BaseEvaluationServiceConfig, minio_config: MinioConfig):
        self.config = config
        self.minio_client = MinioClient(minio_config)
        super().__init__(self.minio_client)
        self.progress_manager = StepProgressManager(config)
        self._ensure_directories()

    def _ensure_directories(self) -> None:
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [self.config.result_dir, self.config.progress_log_dir]
        for directory in directories:
            os.makedirs(directory, exist_ok=True)

    def _setup_evaluation_context(self, task_id: str, input_params: EvaluationServiceInputParams) -> EvaluationContext:
        """è®¾ç½®è¯„ä¼°ä¸Šä¸‹æ–‡"""
        context = EvaluationContext(task_id=task_id, input_params=input_params)
        self._setup_local_detail_path(context)
        return context

    def _setup_local_detail_path(self, context: EvaluationContext):
        """è®¾ç½®æœ¬åœ°è¯¦ç»†ç»“æœè·¯å¾„"""
        os.makedirs(self.config.result_dir, exist_ok=True)

        base_filename = f"{context.task_id}_detail"
        json_path = f"{self.config.result_dir}/{base_filename}.json"
        h5_path = f"{self.config.result_dir}/{base_filename}.h5"

        context.set_local_detail_path(json_path)
        context.set_local_h5_detail_path(h5_path)

        logger.info(f"è®¾ç½®æœ¬åœ°è¯¦ç»†ç»“æœè·¯å¾„: {json_path}")
        return

    @api.post()
    def evaluate(self, input_param: EvaluationServiceInputParams) -> Dict[str, Any]:
        """å¯åŠ¨è¯„ä¼°ä»»åŠ¡"""
        task_id = input_param.task_id

        if not self.progress_manager.create_task(task_id):
            return self._create_response("already_running", "ä»»åŠ¡å·²åœ¨è¿è¡Œ", task_id)

        threading.Thread(
            target=self._execute_evaluation,
            args=(task_id, input_param),
            daemon=True,
            name=f"eval-{task_id}"
        ).start()

        return self._create_response("started", "ä»»åŠ¡å·²å¯åŠ¨", task_id)

    def _create_response(self, status: str, message: str, task_id: str) -> Dict[str, Any]:
        """åˆ›å»ºç»Ÿä¸€çš„å“åº”æ ¼å¼"""
        return {
            "status": status,
            "message": message,
            "task_id": task_id
        }

    def _execute_evaluation(self, task_id: str, input_param: EvaluationServiceInputParams) -> None:
        """æ‰§è¡Œè¯„ä¼°æµæ°´çº¿"""
        context = self._setup_evaluation_context(task_id, input_param)

        try:
            cancellation_checker = self._create_cancellation_checker(task_id)
            result = self._run_evaluation_pipeline(context, cancellation_checker)
            self.progress_manager.complete_task(task_id, result)

        except TaskCancelledException:
            logger.info(f"ä»»åŠ¡ {task_id} å·²è¢«å–æ¶ˆ")
        except Exception as e:
            self._handle_evaluation_error(task_id, e)
        finally:
            self._cleanup_files(context.temp_files)

    def _create_cancellation_checker(self, task_id: str) -> Callable[[], None]:
        """åˆ›å»ºå–æ¶ˆæ£€æŸ¥å‡½æ•°"""

        def check_cancelled():
            state = self.progress_manager.get_task_state(task_id)
            if state and state.cancelled:
                raise TaskCancelledException()

        return check_cancelled

    def _handle_evaluation_error(self, task_id: str, error: Exception) -> None:
        """å¤„ç†è¯„ä¼°é”™è¯¯"""
        error_info = {
            "error_type": type(error).__name__,
            "error_message": str(error),
            "traceback": traceback.format_exc(),
            "timestamp": datetime.now().isoformat()
        }
        self.progress_manager.fail_task(task_id, str(error), error_info)
        logger.error(f"ä»»åŠ¡ {task_id} å¤±è´¥: {error}", exc_info=True)

    def _cleanup_files(self, file_paths: List[str]):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for file_path in file_paths:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
            except Exception as e:
                logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")

    def _run_evaluation_pipeline(self, context: EvaluationContext, check_cancelled: Callable) -> Dict[str, Any]:
        """è¿è¡Œè¯„ä¼°ç®¡é“"""
        # æ•°æ®åŠ è½½
        input_data = self._execute_data_loading(context, check_cancelled)

        # æ‰§è¡Œè¯„ä¼°
        evaluation_results = self._execute_evaluation_step(context, input_data, check_cancelled)

        # ç”Ÿæˆå›¾è¡¨
        charts = self._execute_chart_generation(context, evaluation_results, check_cancelled)

        # ä¸Šä¼ ç»“æœ
        return self._execute_result_upload(context, evaluation_results, charts, check_cancelled)

    def _execute_data_loading(self, context: EvaluationContext, check_cancelled: Callable) -> EvaluationData:
        """æ‰§è¡Œæ•°æ®åŠ è½½æ­¥éª¤"""
        reporter = StepProgressReporter(self.progress_manager, context.task_id, EvaluationStep.DATA_LOADING)
        reporter.update(0, "å¼€å§‹æ•°æ®åŠ è½½")

        input_data = self.load_input_data(context, reporter)
        check_cancelled()

        self.progress_manager.complete_step(context.task_id, EvaluationStep.DATA_LOADING)
        return input_data

    def _execute_evaluation_step(self, context: EvaluationContext, input_data: EvaluationData,
                                 check_cancelled: Callable) -> EvaluationResults:
        """æ‰§è¡Œè¯„ä¼°æ­¥éª¤"""
        reporter = StepProgressReporter(self.progress_manager, context.task_id, EvaluationStep.EVALUATION)
        reporter.update(0, "å¼€å§‹æ‰§è¡Œè¯„ä¼°")

        results = self.run_evaluation(context, input_data, reporter, check_cancelled)
        self.progress_manager.complete_step(context.task_id, EvaluationStep.EVALUATION)
        return results

    def _execute_chart_generation(self, context: EvaluationContext, results: EvaluationResults,
                                  check_cancelled: Callable) -> List[BaseChart]:
        """æ‰§è¡Œå›¾è¡¨ç”Ÿæˆæ­¥éª¤"""
        reporter = StepProgressReporter(self.progress_manager, context.task_id, EvaluationStep.CHART_GENERATION)
        reporter.update(0, "å¼€å§‹ç”Ÿæˆå›¾è¡¨")

        charts = self.generate_charts(context, results, reporter)
        check_cancelled()

        self.progress_manager.complete_step(context.task_id, EvaluationStep.CHART_GENERATION)
        return charts

    def _execute_result_upload(self, context: EvaluationContext, results: EvaluationResults,
                               charts: List[BaseChart], check_cancelled: Callable) -> Dict[str, Any]:
        """æ‰§è¡Œç»“æœä¸Šä¼ æ­¥éª¤"""
        reporter = StepProgressReporter(self.progress_manager, context.task_id, EvaluationStep.RESULT_UPLOAD)
        reporter.update(0, "å¼€å§‹ä¸Šä¼ ç»“æœ")

        # ä¿å­˜è¯¦ç»†ç»“æœ
        reporter.update(ProgressConstants.UPLOAD_SAVE_DETAIL, "ä¿å­˜è¯¦ç»†ç»“æœ")
        detail_path = self.save_detail_results(context, results, reporter)
        context.add_temp_file(detail_path)
        check_cancelled()

        # ä¸Šä¼ è¯¦ç»†ç»“æœåˆ°S3
        reporter.update(ProgressConstants.UPLOAD_S3_DETAIL, "ä¸Šä¼ è¯¦ç»†ç»“æœ")
        self._put_detail_to_s3(detail_path, context.input_params.result_detail_path)
        check_cancelled()

        # ä¸Šä¼ å›¾è¡¨ç»“æœåˆ°S3
        reporter.update(ProgressConstants.UPLOAD_S3_CHARTS, "ä¸Šä¼ å›¾è¡¨ç»“æœ")
        chart_data = [chart.dict() for chart in charts]
        self._put_json_to_s3(chart_data, context.input_params.result_metric_path)

        self.progress_manager.complete_step(context.task_id, EvaluationStep.RESULT_UPLOAD)

        return {
            "detail_s3_path": context.input_params.result_detail_path,
            "stat_s3_path": context.input_params.result_metric_path,
            "task_id": context.task_id
        }

    def load_input_data(self, context: EvaluationContext, reporter: StepProgressReporter) -> EvaluationData:
        data_list = []

        for chunk_num, df in enumerate(self.read_hdf5_chunks_from_s3(context.input_params.input_path)):
            chunk_list = [
                BaseEvaluationRaw(
                    data_id=row['data_id'],
                    raw_data=json.loads(json.loads(row['_RawData_'])),
                    inputs=json.loads(json.loads(row['inputs'])).get('inputs'),
                    outputs=json.loads(json.loads(row['outputs']))
                )
                for _, row in df.iterrows()
            ]
            data_list.extend(chunk_list)

        return EvaluationData(data_list=data_list)

    def save_detail_results(self, context: EvaluationContext, results: EvaluationResults,
                            reporter: StepProgressReporter) -> str:
        """ä¿å­˜è¯¦ç»†è¯„ä¼°ç»“æœåˆ°H5æ–‡ä»¶"""
        try:
            reporter.update(0, "å¼€å§‹ä¿å­˜è¯¦ç»†ç»“æœ")

            # ç¡®ä¿è·¯å¾„å·²è®¾ç½®
            if not context.local_detail_path:
                self._setup_local_detail_path(context)

            # è½¬æ¢æ•°æ®
            results_data = self._convert_results_to_records(results.results, reporter)

            # ä¿å­˜åˆ°H5æ–‡ä»¶
            h5_path = self._save_results_to_h5(results_data, context, reporter)

            reporter.update(100, f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {h5_path}")
            logger.info(f"è¯¦ç»†ç»“æœä¿å­˜å®Œæˆ: {h5_path}, è®°å½•æ•°: {len(results.results)}")

            return h5_path

        except Exception as e:
            error_msg = f"ä¿å­˜è¯¦ç»†ç»“æœå¤±è´¥: {str(e)}"
            logger.error(error_msg, exc_info=True)
            reporter.update(0, error_msg)
            raise

    def _convert_results_to_records(self, results: List[Any], reporter: StepProgressReporter) -> List[Dict]:
        """è½¬æ¢ç»“æœä¸ºè®°å½•åˆ—è¡¨"""
        records = []
        total_count = len(results)

        for idx, result in enumerate(results):
            record = result.model_dump() if hasattr(result, 'model_dump') else result.dict()
            records.append(record)

            # æ‰¹é‡æ›´æ–°è¿›åº¦
            if idx % ProgressConstants.BATCH_UPDATE_SIZE == 0:
                progress = (idx / total_count) * 70  # 70%ç”¨äºæ•°æ®è½¬æ¢
                reporter.update(progress, f"å¤„ç†æ•°æ® {idx}/{total_count}")

        reporter.update(70, "æ•°æ®è½¬æ¢å®Œæˆ")
        return records

    def _save_results_to_h5(self, records: List[Dict], context: EvaluationContext,
                            reporter: StepProgressReporter) -> str:
        """ä¿å­˜è®°å½•åˆ°H5æ–‡ä»¶"""
        reporter.update(75, "åˆ›å»ºDataFrame")
        df = pd.DataFrame(records)

        reporter.update(85, "ä¿å­˜åˆ°H5æ–‡ä»¶")
        h5_path = context.local_h5_detail_path
        self.append_to_hdf5(df, h5_path, key='df')

        return h5_path

    @api.post()
    def progress(self, task_id: str) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡è¿›åº¦"""
        state = self.progress_manager.get_task_state(task_id)
        if not state:
            return {
                "progress": 0,
                "status": TaskStatus.PENDING.value,  # ğŸ†• ä½¿ç”¨æšä¸¾å€¼
                "status_display": "ä»»åŠ¡ä¸å­˜åœ¨",
                "message": "ä»»åŠ¡ä¸å­˜åœ¨"
            }

        result = state.to_dict()

        # æ ¹æ®çŠ¶æ€æ·»åŠ é¢å¤–ä¿¡æ¯
        if state.status == TaskStatus.COMPLETED and state.result:
            result["result"] = state.result
        elif state.status == TaskStatus.FAILED and state.error_info:
            result["error_detail"] = state.error_info

        return result

    @api.post()
    def cancel(self, task_id: str) -> Dict[str, Any]:
        """å–æ¶ˆä»»åŠ¡"""
        state = self.progress_manager.get_task_state(task_id)

        if not state:
            return {
                "status": "not_found",
                "message": "ä»»åŠ¡ä¸å­˜åœ¨",
                "task_id": task_id
            }

        if self.progress_manager.cancel_task(task_id):
            return {
                "status": TaskStatus.CANCELLED.value,  # ğŸ†• ä½¿ç”¨æšä¸¾å€¼
                "message": "ä»»åŠ¡å·²æˆåŠŸå–æ¶ˆ",
                "task_id": task_id
            }

        # æ£€æŸ¥å½“å‰çŠ¶æ€
        current_status = state.status
        if current_status == TaskStatus.CANCELLED:
            return {
                "status": "already_cancelled",
                "message": f"ä»»åŠ¡å·²ç»è¢«å–æ¶ˆ (çŠ¶æ€: {current_status.display_name})",
                "task_id": task_id
            }
        elif current_status in [TaskStatus.COMPLETED, TaskStatus.FAILED]:
            return {
                "status": "cannot_cancel",
                "message": f"ä»»åŠ¡å·²ç»“æŸï¼Œæ— æ³•å–æ¶ˆ (çŠ¶æ€: {current_status.display_name})",
                "task_id": task_id
            }
        else:
            return {
                "status": "not_running",
                "message": f"ä»»åŠ¡æœªåœ¨è¿è¡Œä¸­ (çŠ¶æ€: {current_status.display_name})",
                "task_id": task_id
            }

    @api.post()
    def get_task_status(self, task_id: str) -> Dict[str, Any]:
        """ğŸ†• è·å–ä»»åŠ¡çŠ¶æ€è¯¦æƒ…ï¼ˆæ–°å¢æ¥å£ï¼‰"""
        state = self.progress_manager.get_task_state(task_id)
        if not state:
            return {"error": "ä»»åŠ¡ä¸å­˜åœ¨"}

        return {
            "task_id": task_id,
            "status": {
                "value": state.status.value,
                "display_name": state.status.display_name,
                "is_active": state.is_active(),
                "is_finished": state.is_finished(),
                "can_be_cancelled": state.can_be_cancelled()
            },
            "progress": state.overall_progress,
            "message": state.message,
            "created_at": state.created_at.isoformat(),
            "updated_at": state.updated_at.isoformat()
        }

    @abstractmethod
    def run_evaluation(self, context: EvaluationContext, data: EvaluationData,
                       reporter: StepProgressReporter, check_cancelled: Callable) -> EvaluationResults:
        """æ‰§è¡Œè¯„ä¼° - å­ç±»é€šè¿‡reporter.update(progress, message)æ›´æ–°è¿›åº¦"""
        pass

    @abstractmethod
    def generate_charts(self, context: EvaluationContext, result: Any, reporter: StepProgressReporter) -> List[
        BaseChart]:
        """ç”Ÿæˆå›¾è¡¨ - å­ç±»é€šè¿‡reporter.update(progress, message)æ›´æ–°è¿›åº¦"""
        pass
