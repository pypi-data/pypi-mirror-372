"""
ConcurrentExecutor æµ‹è¯•è„šæœ¬

ç®€å•çš„åŠŸèƒ½éªŒè¯æµ‹è¯•
"""

import asyncio
import time
import random
from sparrow.async_api.concurrent_executor import ConcurrentExecutor, TaskItem


async def simple_task(data, meta=None):
    """ç®€å•æµ‹è¯•ä»»åŠ¡"""
    delay = random.uniform(0.1, 0.3)
    await asyncio.sleep(delay)
    return f"å¤„ç†å®Œæˆ: {data}"


async def error_task(data, meta=None):
    """å¯èƒ½å‡ºé”™çš„ä»»åŠ¡"""
    await asyncio.sleep(0.1)
    if random.random() < 0.3:  # 30% æ¦‚ç‡å‡ºé”™
        raise ValueError(f"ä»»åŠ¡ {data} å‡ºé”™äº†")
    return f"æˆåŠŸ: {data}"


def custom_error_handler(error, task_data, retry_count):
    """è‡ªå®šä¹‰é”™è¯¯å¤„ç†"""
    print(f"é”™è¯¯å¤„ç†å™¨: {task_data} å‘ç”Ÿé”™è¯¯ {error} (ç¬¬{retry_count}æ¬¡é‡è¯•)")
    return retry_count < 2  # æœ€å¤šé‡è¯•2æ¬¡


async def test_basic_execution():
    """æµ‹è¯•åŸºæœ¬æ‰§è¡ŒåŠŸèƒ½"""
    print("=== æµ‹è¯•åŸºæœ¬æ‰§è¡ŒåŠŸèƒ½ ===")
    
    executor = ConcurrentExecutor(
        concurrency_limit=3,
        max_qps=5,
        retry_times=2
    )
    
    tasks_data = [f"ä»»åŠ¡_{i}" for i in range(10)]
    
    start_time = time.time()
    results, progress = await executor.execute_batch(
        async_func=simple_task,
        tasks_data=tasks_data,
        show_progress=True
    )
    end_time = time.time()
    
    print(f"\næ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
    print(f"æˆåŠŸ: {sum(1 for r in results if r.status == 'success')}")
    print(f"å¤±è´¥: {sum(1 for r in results if r.status == 'error')}")
    
    # éªŒè¯ç»“æœé¡ºåº
    assert len(results) == 10
    assert all(r.task_id == i for i, r in enumerate(results))
    print("âœ… åŸºæœ¬æ‰§è¡Œæµ‹è¯•é€šè¿‡")


async def test_priority_execution():
    """æµ‹è¯•ä¼˜å…ˆçº§æ‰§è¡Œ"""
    print("\n=== æµ‹è¯•ä¼˜å…ˆçº§æ‰§è¡Œ ===")
    
    executor = ConcurrentExecutor(concurrency_limit=2)
    
    priority_tasks = [
        TaskItem(priority=3, task_id=0, data="ä½ä¼˜å…ˆçº§"),
        TaskItem(priority=1, task_id=1, data="é«˜ä¼˜å…ˆçº§"),
        TaskItem(priority=2, task_id=2, data="ä¸­ä¼˜å…ˆçº§"),
        TaskItem(priority=1, task_id=3, data="é«˜ä¼˜å…ˆçº§2"),
    ]
    
    results, _ = await executor.execute_priority_batch(
        async_func=simple_task,
        priority_tasks=priority_tasks,
        show_progress=True
    )
    
    print(f"\næ‰§è¡Œé¡ºåºï¼ˆæŒ‰å®Œæˆæ—¶é—´ï¼‰:")
    for result in results:
        task = next(t for t in priority_tasks if t.task_id == result.task_id)
        print(f"  ä»»åŠ¡ID {result.task_id}: ä¼˜å…ˆçº§ {task.priority} - {task.data}")
    
    print("âœ… ä¼˜å…ˆçº§æ‰§è¡Œæµ‹è¯•é€šè¿‡")


async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†å’Œé‡è¯•"""
    print("\n=== æµ‹è¯•é”™è¯¯å¤„ç†å’Œé‡è¯• ===")
    
    executor = ConcurrentExecutor(
        concurrency_limit=2,
        retry_times=3,
        error_handler=custom_error_handler
    )
    
    tasks_data = [f"ä»»åŠ¡_{i}" for i in range(8)]
    
    results, _ = await executor.execute_batch(
        async_func=error_task,
        tasks_data=tasks_data,
        show_progress=True
    )
    
    success_count = sum(1 for r in results if r.status == 'success')
    error_count = sum(1 for r in results if r.status == 'error')
    
    print(f"\né”™è¯¯å¤„ç†ç»“æœ:")
    print(f"æˆåŠŸ: {success_count}")
    print(f"å¤±è´¥: {error_count}")
    
    # æ˜¾ç¤ºé‡è¯•ä¿¡æ¯
    for result in results:
        if result.status == 'error':
            print(f"  ä»»åŠ¡ {result.task_id} å¤±è´¥ï¼Œé‡è¯•äº† {result.retry_count} æ¬¡")
    
    print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")


async def test_streaming():
    """æµ‹è¯•æµå¼å¤„ç†"""
    print("\n=== æµ‹è¯•æµå¼å¤„ç† ===")
    
    executor = ConcurrentExecutor(concurrency_limit=3)
    tasks_data = [f"æµå¼ä»»åŠ¡_{i}" for i in range(15)]
    
    processed_count = 0
    batch_count = 0
    
    async for batch_result in executor.aiter_execute_batch(
        async_func=simple_task,
        tasks_data=tasks_data,
        batch_size=4,
        show_progress=True
    ):
        batch_count += 1
        batch_size = len(batch_result.completed_tasks)
        processed_count += batch_size
        print(f"  æ‰¹æ¬¡ {batch_count}: æ”¶åˆ° {batch_size} ä¸ªç»“æœï¼Œæ€»è®¡ {processed_count}")
    
    assert processed_count == 15
    print("âœ… æµå¼å¤„ç†æµ‹è¯•é€šè¿‡")


async def test_sync_interface():
    """æµ‹è¯•åŒæ­¥æ¥å£"""
    print("\n=== æµ‹è¯•åŒæ­¥æ¥å£ ===")
    
    executor = ConcurrentExecutor(concurrency_limit=2)
    tasks_data = [f"åŒæ­¥ä»»åŠ¡_{i}" for i in range(5)]
    
    # ä½¿ç”¨åŒæ­¥æ¥å£
    results, _ = executor.execute_batch_sync(
        async_func=simple_task,
        tasks_data=tasks_data,
        show_progress=True
    )
    
    print(f"\nåŒæ­¥æ‰§è¡Œå®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªä»»åŠ¡")
    assert len(results) == 5
    assert all(r.status == 'success' for r in results)
    print("âœ… åŒæ­¥æ¥å£æµ‹è¯•é€šè¿‡")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯• ConcurrentExecutor\n")
    
    try:
        await test_basic_execution()
        await test_priority_execution()
        await test_error_handling()
        await test_streaming()
        await test_sync_interface()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main()) 