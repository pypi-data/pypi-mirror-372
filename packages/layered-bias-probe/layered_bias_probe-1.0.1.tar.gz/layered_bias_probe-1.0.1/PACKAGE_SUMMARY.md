# layered-bias-probe Package Summary

## ğŸ‰ Package Created Successfully!

The `layered-bias-probe` package has been successfully created with all the functionality you requested. Here's what has been built:

## ğŸ“ Package Structure

```
layered-bias-probe/
â”œâ”€â”€ setup.py                           # Package setup and metadata
â”œâ”€â”€ requirements.txt                   # Dependencies
â”œâ”€â”€ README.md                          # Comprehensive documentation
â”œâ”€â”€ install_and_test.py               # Installation and testing script
â”œâ”€â”€ demo.py                           # Quick demo script
â”œâ”€â”€ layered_bias_probe/               # Main package
â”‚   â”œâ”€â”€ __init__.py                   # Package initialization
â”‚   â”œâ”€â”€ cli.py                        # Command-line interface
â”‚   â”œâ”€â”€ core/                         # Core functionality
â”‚   â”‚   â”œâ”€â”€ bias_probe.py             # Main bias analysis class
â”‚   â”‚   â”œâ”€â”€ fine_tuner.py             # Fine-tuning with bias tracking
â”‚   â”‚   â”œâ”€â”€ batch_processor.py        # Batch analysis across models
â”‚   â”‚   â””â”€â”€ results_analyzer.py       # Results visualization and analysis
â”‚   â”œâ”€â”€ utils/                        # Utility modules
â”‚   â”‚   â”œâ”€â”€ model_manager.py          # Model loading and management
â”‚   â”‚   â”œâ”€â”€ weat_category.py          # WEAT category definitions
â”‚   â”‚   â”œâ”€â”€ weathub_loader.py         # Dataset loading
â”‚   â”‚   â”œâ”€â”€ embedding_extractor.py    # Layer embedding extraction
â”‚   â”‚   â””â”€â”€ bias_quantifier.py        # Bias quantification (WEAT scores)
â”‚   â””â”€â”€ config/                       # Configuration
â”‚       â”œâ”€â”€ default.yaml              # Default configuration
â”‚       â””â”€â”€ __init__.py               # Config management
â””â”€â”€ examples/                         # Usage examples
    â”œâ”€â”€ basic_analysis.py             # Basic bias analysis
    â”œâ”€â”€ finetuning_with_bias_tracking.py  # Fine-tuning with bias tracking
    â”œâ”€â”€ batch_model_comparison.py     # Batch model comparison
    â””â”€â”€ results_analysis.py           # Results analysis and visualization
```

## ğŸš€ Quick Start

### 1. Installation
```bash
# Navigate to the package directory
cd layered-bias-probe

# Run the installation and testing script
python install_and_test.py

# Or install manually
pip install -e .
```

### 2. Quick Demo
```bash
# Run the demo script to see the package in action
python demo.py
```

### 3. Command Line Usage
```bash
# Basic bias analysis
python -m layered_bias_probe.cli analyze --model facebook/opt-125m --language english

# With specific WEAT categories
python -m layered_bias_probe.cli analyze \
  --model facebook/opt-125m \
  --language english \
  --categories WEAT1 WEAT6 \
  --output-dir my_results

# Fine-tuning with bias tracking
python -m layered_bias_probe.cli finetune \
  --model facebook/opt-125m \
  --dataset alpaca \
  --language english \
  --epochs 3

# Batch model comparison
python -m layered_bias_probe.cli batch \
  --models facebook/opt-125m microsoft/DialoGPT-small \
  --language english \
  --output-dir comparison_results
```

### 4. Python API Usage
```python
from layered_bias_probe import BiasProbe, FineTuner, BatchProcessor

# Basic bias analysis
probe = BiasProbe(model_name="facebook/opt-125m")
results = probe.analyze_bias(
    languages=["english"],
    weat_categories=["WEAT1", "WEAT6"]
)

# Fine-tuning with bias tracking
tuner = FineTuner(
    model_name="facebook/opt-125m",
    finetune_dataset="alpaca"
)
results = tuner.finetune_and_track_bias(
    epochs=3,
    languages=["english"]
)

# Batch model comparison
processor = BatchProcessor()
results = processor.compare_models(
    model_names=["facebook/opt-125m", "microsoft/DialoGPT-small"],
    languages=["english"]
)
```

## ğŸ”§ Key Features

### âœ… Core Functionality
- **Layer-wise bias analysis** using WEAT (Word Embedding Association Test)
- **Fine-tuning with bias tracking** during training
- **Batch processing** for comparing multiple models
- **Comprehensive results analysis** with visualizations

### âœ… Model Support
- Any HuggingFace transformer model
- Automatic model quantization for memory efficiency
- GPU/CPU support with automatic device detection

### âœ… WEAT Categories
- 20+ predefined WEAT categories covering:
  - Gender bias (career, academic, family)
  - Racial bias (African American names, European American names)
  - Religious bias (Christianity, Islam, Judaism)
  - India-specific biases (caste, religion, regional)

### âœ… Language Support
- English, Hindi, Bengali
- Extensible to other languages

### âœ… Output Formats
- CSV files with detailed bias metrics
- Interactive HTML visualizations
- PNG plots for publications
- Structured results for further analysis

### âœ… Configuration
- YAML-based configuration
- Command-line overrides
- Flexible parameter settings

## ğŸ“Š Available WEAT Categories

| Category | Description | Type |
|----------|-------------|------|
| WEAT1 | Flowers vs. Insects with Pleasant vs. Unpleasant | Valence |
| WEAT2 | Instruments vs. Weapons with Pleasant vs. Unpleasant | Valence |
| WEAT6 | Career vs. Family with Male vs. Female Names | Gender-Profession |
| WEAT7 | Math vs. Arts with Male vs. Female Terms | Gender-Academic |
| WEAT8 | Science vs. Arts with Male vs. Female Terms | Gender-Academic |
| WEAT9 | Mental vs. Physical Disease with Controllable vs. Uncontrollable | Disability |
| WEAT10 | Young vs. Old Names with Pleasant vs. Unpleasant | Age |
| ... | 10+ more categories for comprehensive bias analysis | Various |

## ğŸ” Analysis Outputs

Each analysis produces:
- **Layer-wise bias scores** (WEAT effect sizes)
- **Statistical significance** (p-values)
- **Temporal evolution** during fine-tuning
- **Model comparisons** across architectures
- **Visualization dashboards** for exploration

## ğŸ› ï¸ Extensibility

The package is designed to be easily extended:
- **Add new WEAT categories** in `utils/weat_category.py`
- **Support new languages** by adding datasets
- **Custom analysis workflows** using the core classes
- **Integration with existing pipelines** via Python API

## ğŸ“– Documentation

- **README.md**: Comprehensive usage guide
- **Examples**: Ready-to-run scripts in `examples/`
- **CLI Help**: `python -m layered_bias_probe.cli --help`
- **Docstrings**: Detailed documentation in all modules

## ğŸ§ª Testing

Run the test suite:
```bash
python install_and_test.py
```

This will:
- Install all dependencies
- Test package imports
- Verify CLI functionality
- Run basic analysis tests

## ğŸ¯ Use Cases

1. **Research**: Analyze bias in pre-trained models
2. **Development**: Track bias during model fine-tuning
3. **Comparison**: Evaluate bias across model families
4. **Monitoring**: Continuous bias assessment in ML pipelines
5. **Education**: Learn about bias in language models

## ğŸ“ˆ Performance

- **Memory efficient**: Automatic quantization support
- **Fast analysis**: Optimized layer extraction
- **Scalable**: Batch processing for multiple models
- **Resumable**: Checkpoint support for long analyses

## ğŸ¤ Contributing

The package structure supports easy contributions:
- Modular design for independent development
- Clear separation of concerns
- Comprehensive testing framework
- Standardized configuration system

---

## ğŸ‰ Ready to Use!

Your `layered-bias-probe` package is ready for:
- **Research publications**
- **Production deployment**
- **Educational use**
- **Community sharing**

Start with the demo script (`python demo.py`) to see it in action, then explore the examples and documentation for advanced usage.

Happy bias probing! ğŸ”ğŸ“Š
