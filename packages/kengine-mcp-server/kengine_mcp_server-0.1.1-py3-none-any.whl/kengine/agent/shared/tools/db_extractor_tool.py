"""
æ•°æ®åº“é…ç½®æå–å’ŒæŸ¥è¯¢å·¥å…·

è¯¥æ¨¡å—æä¾›ä»æŒ‡å®šç›®å½•ä¸­æå–æ•°æ®åº“é…ç½®ä¿¡æ¯çš„åŠŸèƒ½ã€‚æ ¸å¿ƒç±»DatabaseConfigExtractor
èƒ½å¤Ÿè§£æSpringé…ç½®æ–‡ä»¶ï¼Œè¿æ¥æ•°æ®åº“å¹¶æ‰§è¡ŒæŸ¥è¯¢æ“ä½œã€‚
å·¥å…·ä»å½“å‰ç›®å½•æˆ–æŒ‡å®šç›®å½•ä¸­è‡ªåŠ¨è·å–é¡¹ç›®åç§°ï¼Œæ— éœ€æ˜¾å¼æŒ‡å®šé¡¹ç›®åç§°ã€‚

åŠŸèƒ½ç‰¹ç‚¹:
- ä»æŒ‡å®šç›®å½•ä¸­æœç´¢é¡¹ç›®çš„æ•°æ®åº“é…ç½®ä¿¡æ¯
- è§£æSpringé…ç½®æ–‡ä»¶å’Œå±æ€§æ–‡ä»¶
- æ ¹æ®ç¯å¢ƒä¼˜å…ˆçº§é€‰æ‹©åˆé€‚çš„é…ç½®
- è¿æ¥æ•°æ®åº“å¹¶æ‰§è¡Œè¡¨ç»“æ„æŸ¥è¯¢

ä½¿ç”¨æ–¹æ³•:
    python -m tools.db_extractor
    python -m tools.db_extractor --table user_info
"""

import argparse
import json
import logging
import os
import re
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Optional

from pydantic import BaseModel, Field

from .base import BasePathTool
from .error_handler import ErrorHandler, handle_tool_errors
from .exceptions import ConfigurationError
from kengine.config import logging_config

logging_config.setup_logging()
logger = logging.getLogger(__name__)


def validate_table_name(table_name: str) -> bool:
    """
    éªŒè¯è¡¨åæ˜¯å¦åˆæ³•ï¼Œé˜²æ­¢SQLæ³¨å…¥
    
    Args:
        table_name: è¦éªŒè¯çš„è¡¨å
        
    Returns:
        bool: è¡¨åæ˜¯å¦åˆæ³•
        
    Raises:
        ValueError: è¡¨åä¸åˆæ³•æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    if not table_name or not isinstance(table_name, str):
        raise ValueError("è¡¨åä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
        
    if not re.fullmatch(r'^[a-zA-Z0-9_]+$', table_name):
        raise ValueError(f"è¡¨å '{table_name}' åŒ…å«éæ³•å­—ç¬¦ï¼Œä»…å…è®¸å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
    
    return True


class DatabaseConfig:
    """æ•°æ®åº“é…ç½®ç±»"""

    def __init__(self, name: str, url: str, username: str, password: str, driver: str):
        self.name = name
        self.url = url
        self.username = username
        self.password = password
        self.driver = driver

    def __str__(self):
        return f"DataSource[{self.name}]: {self.url} (user: {self.username})"


class DatabaseConfigExtractor:
    """æ•°æ®åº“é…ç½®æå–å™¨"""

    def __init__(self, base_dir: str = "."):
        self.base_path = Path(base_dir)
        # ç¯å¢ƒä¼˜å…ˆçº§ï¼šæµ‹è¯• > UAT > ç°åº¦ > å¼€å‘ > ç”Ÿäº§
        self.env_priority = [
            'test', 'uat', 'gray', 'grey', 'dev', 'prod', 'production'
        ]

    def find_project_path(self, project_name: str) -> Optional[Path]:
        """æŸ¥æ‰¾é¡¹ç›®è·¯å¾„"""
        for root, dirs, files in os.walk(self.base_path):
            if project_name in dirs:
                return Path(root) / project_name
        return None

    def find_config_files(self, project_path: Path) -> List[Path]:
        """æŸ¥æ‰¾é…ç½®æ–‡ä»¶"""
        config_files = []

        # æœç´¢Springé…ç½®æ–‡ä»¶
        spring_patterns = [
            "**/spring*.xml",
            "**/applicationContext*.xml",
            "**/*-dao.xml",
            "**/*-datasource.xml"
        ]

        for pattern in spring_patterns:
            config_files.extend(project_path.glob(pattern))

        # æœç´¢å±æ€§æ–‡ä»¶
        properties_patterns = [
            "**/application*.properties",
            "**/database*.properties",
            "**/jdbc*.properties"
        ]

        for pattern in properties_patterns:
            config_files.extend(project_path.glob(pattern))

        return config_files

    def get_env_priority_score(self, file_path: Path) -> int:
        """è·å–ç¯å¢ƒä¼˜å…ˆçº§åˆ†æ•°ï¼Œåˆ†æ•°è¶Šä½ä¼˜å…ˆçº§è¶Šé«˜"""
        file_name = file_path.name.lower()

        for i, env in enumerate(self.env_priority):
            if env in file_name:
                return i

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç¯å¢ƒæ ‡è¯†ï¼Œè¿”å›æœ€ä½ä¼˜å…ˆçº§
        return len(self.env_priority)

    def select_preferred_properties_files(self, properties_files: List[Path]) -> List[Path]:
        """æ ¹æ®ç¯å¢ƒä¼˜å…ˆçº§é€‰æ‹©propertiesæ–‡ä»¶"""
        if not properties_files:
            return []

        # æŒ‰ç¯å¢ƒä¼˜å…ˆçº§æ’åº
        sorted_files = sorted(properties_files, key=self.get_env_priority_score)

        # è·å–æœ€é«˜ä¼˜å…ˆçº§çš„ç¯å¢ƒ
        best_score = self.get_env_priority_score(sorted_files[0])

        # è¿”å›æ‰€æœ‰å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§çš„æ–‡ä»¶
        preferred_files = [f for f in sorted_files if self.get_env_priority_score(f) == best_score]

        return preferred_files

    def _get_env_info(self, file_path: Path) -> str:
        """è·å–æ–‡ä»¶çš„ç¯å¢ƒä¿¡æ¯"""
        file_name = file_path.name.lower()

        for env in self.env_priority:
            if env in file_name:
                return f"({env}ç¯å¢ƒ)"

        return "(é»˜è®¤ç¯å¢ƒ)"

    def parse_properties_file(self, file_path: Path) -> Dict[str, str]:
        """è§£æpropertiesæ–‡ä»¶"""
        properties = {}
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        properties[key.strip()] = value.strip()
        except Exception as e:
            print(f"è§£æpropertiesæ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        return properties

    def resolve_placeholder(self, value: str, properties: Dict[str, str]) -> str:
        """è§£æå ä½ç¬¦å˜é‡"""
        if not value or not value.startswith('${'):
            return value

        # æå–å ä½ç¬¦å˜é‡å
        match = re.match(r'\$\{([^}]+)\}', value)
        if match:
            placeholder = match.group(1)
            return properties.get(placeholder, value)

        return value

    def parse_spring_xml(self, file_path: Path, properties: Dict[str, str]) -> List[DatabaseConfig]:
        """è§£æSpring XMLé…ç½®æ–‡ä»¶"""
        configs = []

        try:
            tree = ET.parse(file_path)
            root = tree.getroot()

            # å®šä¹‰å‘½åç©ºé—´
            namespaces = {
                'beans': 'http://www.springframework.org/schema/beans'
            }

            # æŸ¥æ‰¾æ‰€æœ‰æ•°æ®æºbean
            datasource_classes = [
                'org.apache.commons.dbcp.BasicDataSource',
                'org.apache.commons.dbcp2.BasicDataSource',
                'com.alibaba.druid.pool.DruidDataSource',
                'org.springframework.jdbc.datasource.DriverManagerDataSource'
            ]

            for bean in root.findall('.//beans:bean', namespaces):
                class_attr = bean.get('class', '')
                if any(ds_class in class_attr for ds_class in datasource_classes):
                    config = self._extract_datasource_config(bean, properties, namespaces)
                    if config:
                        configs.append(config)

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å‘½åç©ºé—´çš„beanï¼Œå°è¯•ä¸ä½¿ç”¨å‘½åç©ºé—´
            if not configs:
                for bean in root.findall('.//bean'):
                    class_attr = bean.get('class', '')
                    if any(ds_class in class_attr for ds_class in datasource_classes):
                        config = self._extract_datasource_config(bean, properties, {})
                        if config:
                            configs.append(config)

        except Exception as e:
            logger.error(f"è§£æSpring XMLæ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        return configs

    def _extract_datasource_config(self, bean_element, properties: Dict[str, str], namespaces: Dict[str, str]) -> \
    Optional[DatabaseConfig]:
        """ä»beanå…ƒç´ ä¸­æå–æ•°æ®æºé…ç½®"""
        bean_id = bean_element.get('id', 'unknown')
        url = None
        username = None
        password = None
        driver = None

        # æŸ¥æ‰¾å±æ€§
        property_mappings = {
            'url': ['url', 'jdbcUrl'],
            'username': ['username', 'user'],
            'password': ['password'],
            'driver': ['driverClassName', 'driver-class-name', 'driverClass']
        }

        if namespaces:
            properties_xpath = './/beans:property'
        else:
            properties_xpath = './/property'

        for prop in bean_element.findall(properties_xpath, namespaces):
            prop_name = prop.get('name', '')
            prop_value = prop.get('value', '')

            # è§£æå ä½ç¬¦
            resolved_value = self.resolve_placeholder(prop_value, properties)

            for config_key, prop_names in property_mappings.items():
                if prop_name in prop_names:
                    if config_key == 'url':
                        url = resolved_value
                    elif config_key == 'username':
                        username = resolved_value
                    elif config_key == 'password':
                        password = resolved_value
                    elif config_key == 'driver':
                        driver = resolved_value

        if url and username:  # passwordå¯èƒ½ä¸ºç©º
            return DatabaseConfig(bean_id, url, username, password or '', driver or '')

        return None

    def extract_database_configs(self) -> List[DatabaseConfig]:
        """æå–æ•°æ®åº“é…ç½®"""
        # ä» base_path ä¸­è§£æé¡¹ç›®åç§°
        project_name = self.base_path.name
        project_path = self.base_path
        
        print(f"ä½¿ç”¨é¡¹ç›®è·¯å¾„: {project_path}, é¡¹ç›®åç§°: {project_name}")

        config_files = self.find_config_files(project_path)
        if not config_files:
            print("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶")
            return []

        print(f"æ‰¾åˆ°é…ç½®æ–‡ä»¶: {len(config_files)} ä¸ª")
        for f in config_files:
            print(f"  - {f}")

        # åˆ†ç¦»propertiesæ–‡ä»¶å’ŒXMLæ–‡ä»¶
        properties_files = [f for f in config_files if f.suffix == '.properties']
        xml_files = [f for f in config_files if f.suffix == '.xml']

        # æ ¹æ®ç¯å¢ƒä¼˜å…ˆçº§é€‰æ‹©propertiesæ–‡ä»¶
        preferred_properties = self.select_preferred_properties_files(properties_files)

        if preferred_properties:
            print(f"\næ ¹æ®ç¯å¢ƒä¼˜å…ˆçº§é€‰æ‹©çš„é…ç½®æ–‡ä»¶:")
            for f in preferred_properties:
                env_info = self._get_env_info(f)
                print(f"  - {f} {env_info}")

        # è§£æé€‰ä¸­çš„propertiesæ–‡ä»¶
        all_properties = {}
        for config_file in preferred_properties:
            props = self.parse_properties_file(config_file)
            all_properties.update(props)

        # ç„¶åè§£æXMLæ–‡ä»¶
        all_configs = []
        for config_file in xml_files:
            configs = self.parse_spring_xml(config_file, all_properties)
            all_configs.extend(configs)

        return all_configs

    def connect_and_query(self, config: DatabaseConfig, table_name: Optional[str] = None) -> str:
        """è¿æ¥æ•°æ®åº“å¹¶æ‰§è¡ŒæŸ¥è¯¢ï¼ˆçœŸå®è¿æ¥æ¨¡å¼ï¼‰"""
        result_text = []

        # è§£ææ•°æ®åº“è¿æ¥ä¿¡æ¯
        url_pattern = r'jdbc:mysql://([^:/]+):?(\d+)?/([^?]+)'
        match = re.match(url_pattern, config.url)

        if not match:
            error_msg = f"æ— æ³•è§£ææ•°æ®åº“URL: {config.url}"
            logger.error(error_msg)
            return error_msg

        host = match.group(1)
        port = int(match.group(2)) if match.group(2) else 3306
        database = match.group(3)

        logger.info(f"å°è¯•è¿æ¥æ•°æ®åº“: {host}:{port}/{database}, ç”¨æˆ·: {config.username}")

        try:
            # çœŸå®è¿æ¥æ•°æ®åº“
            import pymysql
            connection = pymysql.connect(
                host=host,
                port=port,
                user=config.username,
                password=config.password,
                database=database,
                charset='utf8mb4',
                connect_timeout=10
            )

            logger.info(f"æ•°æ®åº“è¿æ¥æˆåŠŸ")

            with connection.cursor() as cursor:
                if table_name:
                    # æŸ¥è¯¢ç‰¹å®šè¡¨çš„è¯¦ç»†ä¿¡æ¯
                    logger.info(f"æ­£åœ¨æŸ¥è¯¢è¡¨ '{table_name}' çš„ç»“æ„...")

                    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    cursor.execute(f"SHOW TABLES LIKE '{table_name}'")
                    table_exists = cursor.fetchone()

                    if not table_exists:
                        error_msg = f"âŒ è¡¨ '{table_name}' åœ¨æ•°æ®åº“ {database} ä¸­ä¸å­˜åœ¨"
                        logger.error(error_msg)
                        return error_msg

                    result_text.append(f"## ğŸ“‹ è¡¨ `{table_name}` è¯¦ç»†ä¿¡æ¯")
                    result_text.append(f"**æ•°æ®åº“**: {database}")
                    result_text.append(f"**æœåŠ¡å™¨**: {host}:{port}")
                    result_text.append(f"")
                    result_text.append(
                        "ğŸ”’ **å­—æ®µåä¿æŠ¤å£°æ˜**ï¼šæœ¬æ–‡æ¡£ä¸­æ‰€æœ‰æ•°æ®åº“å­—æ®µåå‡ä¸ºçœŸå®å­—æ®µåï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§åŸæ ·ä½¿ç”¨ï¼Œç¦æ­¢è¿›è¡Œä»»ä½•å½¢å¼çš„å‘½åè½¬æ¢ï¼ˆå¦‚é©¼å³°è½¬ä¸‹åˆ’çº¿ç­‰ï¼‰ï¼")
                    result_text.append(f"")

                    # éªŒè¯è¡¨åï¼Œé˜²æ­¢SQLæ³¨å…¥
                    validate_table_name(table_name)
                    
                    # è·å–è¡¨ç»“æ„
                    logger.info(f"æ‰§è¡Œ DESCRIBE {table_name} æŸ¥è¯¢...")
                    try:
                        cursor.execute(f"DESCRIBE {table_name}")
                        columns = cursor.fetchall()
                        logger.info(f"DESCRIBE æŸ¥è¯¢è¿”å› {len(columns) if columns else 0} è¡Œæ•°æ®")
                    except Exception as e:
                        logger.error(f"DESCRIBE æŸ¥è¯¢å¤±è´¥: {e}")
                        result_text.append(f"è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
                        columns = []

                    if columns:
                        result_text.append(f"## è¡¨ {table_name} çš„ç»“æ„ä¿¡æ¯")
                        result_text.append("")
                        result_text.append(
                            "**âš ï¸ é‡è¦æç¤ºï¼šä»¥ä¸‹å­—æ®µåä¸ºæ•°æ®åº“ä¸­çš„çœŸå®å­—æ®µåï¼Œè¯·ä¿æŒåŸæ ·æ˜¾ç¤ºï¼Œä¸è¦è¿›è¡Œä»»ä½•å‘½åè½¬æ¢ï¼**")
                        result_text.append("")
                        result_text.append("### å­—æ®µä¿¡æ¯")
                        result_text.append("| å­—æ®µå | æ•°æ®ç±»å‹ | æ˜¯å¦ä¸ºç©º | é”® | é»˜è®¤å€¼ | é¢å¤–ä¿¡æ¯ |")
                        result_text.append("|--------|----------|----------|-----|--------|----------|")

                        for column in columns:
                            field = column[0]
                            type_info = column[1]
                            null_info = column[2]
                            key_info = column[3]
                            default_info = column[4] if column[4] is not None else ""
                            extra_info = column[5]

                            # ä½¿ç”¨åå¼•å·åŒ…å›´å­—æ®µåï¼Œå¼ºè°ƒè¿™æ˜¯ç²¾ç¡®çš„å­—æ®µå
                            result_text.append(
                                f"| `{field}` | {type_info} | {null_info} | {key_info} | {default_info} | {extra_info} |")

                        result_text.append("")
                        result_text.append(
                            "**æ³¨æ„ï¼šä¸Šè¿°å­—æ®µåä½¿ç”¨åå¼•å·æ ‡è®°ï¼Œè¡¨ç¤ºè¿™äº›æ˜¯æ•°æ®åº“ä¸­çš„ç²¾ç¡®å­—æ®µåï¼Œè¯·åœ¨å¼•ç”¨æ—¶ä¿æŒå®Œå…¨ä¸€è‡´ã€‚**")
                        result_text.append("")
                    else:
                        result_text.append("âš ï¸ æœªèƒ½è·å–åˆ°è¡¨å­—æ®µä¿¡æ¯")
                        result_text.append("")

                    # è·å–å»ºè¡¨è¯­å¥
                    try:
                        # è¡¨åå·²åœ¨å‰é¢éªŒè¯ï¼Œæ­¤å¤„æ— éœ€é‡å¤éªŒè¯
                        cursor.execute(f"SHOW CREATE TABLE {table_name}")
                        create_table_result = cursor.fetchone()
                        if create_table_result:
                            create_sql = create_table_result[1]
                            result_text.append("### å»ºè¡¨è¯­å¥")
                            result_text.append("```sql")
                            result_text.append(create_sql)
                            result_text.append("```")
                            result_text.append("")
                    except Exception as e:
                        result_text.append(f"è·å–å»ºè¡¨è¯­å¥å¤±è´¥: {e}")
                        result_text.append("")

                    # è·å–ç´¢å¼•ä¿¡æ¯
                    try:
                        # è¡¨åå·²åœ¨å‰é¢éªŒè¯ï¼Œæ­¤å¤„æ— éœ€é‡å¤éªŒè¯
                        cursor.execute(f"SHOW INDEX FROM {table_name}")
                        indexes = cursor.fetchall()
                        if indexes:
                            result_text.append("### ç´¢å¼•ä¿¡æ¯")
                            result_text.append("| ç´¢å¼•å | å­—æ®µå | æ˜¯å¦å”¯ä¸€ | åºåˆ— | æ’åº |")
                            result_text.append("|--------|--------|----------|------|------|")

                            for index in indexes:
                                key_name = index[2]
                                column_name = index[4]
                                non_unique = "å¦" if index[1] == 0 else "æ˜¯"
                                seq_in_index = index[3]
                                collation = index[5] if index[5] else ""

                                result_text.append(
                                    f"| {key_name} | {column_name} | {non_unique} | {seq_in_index} | {collation} |")

                            result_text.append("")
                    except Exception as e:
                        result_text.append(f"è·å–ç´¢å¼•ä¿¡æ¯å¤±è´¥: {e}")
                        result_text.append("")

                else:
                    # æŸ¥è¯¢æ‰€æœ‰è¡¨
                    cursor.execute("SHOW TABLES")
                    tables = cursor.fetchall()
                    table_count = len(tables)
                    logger.info(f"æ‰¾åˆ° {table_count} ä¸ªè¡¨")

                    result_text.append("=" * 50)
                    result_text.append(f"ã€è¡¨æ¸…å•ã€‘æ•°æ®åº“ {database} ä¸­çš„è¡¨:")
                    for i, table in enumerate(tables, 1):
                        result_text.append(f"  {i:2d}. {table[0]}")
                    result_text.append("=" * 50)

            connection.close()

            # è¿”å›æ„å»ºçš„ç»“æœæ–‡æœ¬
            result_string = "\n".join(result_text)
            logger.debug(f"å‡†å¤‡è¿”å›ç»“æœï¼Œé•¿åº¦: {len(result_string)} å­—ç¬¦")
            logger.debug(f"ç»“æœæ–‡æœ¬è¡Œæ•°: {len(result_text)}")
            if result_text:
                logger.debug(f"ç»“æœæ–‡æœ¬å‰3è¡Œ: {result_text[:3]}")
            return result_string

        except Exception as e:
            error_msg = f"è¿æ¥æ•°æ®åº“å¤±è´¥: {e}"
            logger.error(error_msg)
            return error_msg


# Pydantic è¾“å…¥å‚æ•°æ¨¡å‹
class DBExtractorInput(BaseModel):
    """æ•°æ®åº“æå–å·¥å…·è¾“å…¥å‚æ•°æ¨¡å‹
    
    æå–é¡¹ç›®çš„æ•°æ®åº“é…ç½®ä¿¡æ¯ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°æŸ¥è¯¢ç‰¹å®šè¡¨çš„ç»“æ„ã€‚
    ä¹Ÿæ”¯æŒJSONæ ¼å¼å‚æ•°è¾“å…¥ï¼š{"table_name": "user_info"}
    """
    table_name: Optional[str] = Field(
        default=None,
        description="è¡¨åï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºæŸ¥è¯¢ç‰¹å®šè¡¨çš„ç»“æ„ä¿¡æ¯ã€‚å¦‚æœä¸æä¾›ï¼Œå°†è¿”å›æ‰€æœ‰è¡¨çš„åˆ—è¡¨",
        examples=["user_info", "order_detail", "product"]
    )


class DBExtractorTool(BasePathTool):
    """æ•°æ®åº“é…ç½®æå–å’ŒæŸ¥è¯¢å·¥å…·
    
    è¯¥å·¥å…·æä¾›ä»é¡¹ç›®ä¸­æå–æ•°æ®åº“é…ç½®ä¿¡æ¯çš„åŠŸèƒ½ï¼Œå¹¶å¯ä»¥æŸ¥è¯¢æ•°æ®åº“è¡¨ç»“æ„ã€‚
    æ”¯æŒä»Springé…ç½®æ–‡ä»¶å’Œå±æ€§æ–‡ä»¶ä¸­æå–æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼Œå¹¶æ ¹æ®ç¯å¢ƒä¼˜å…ˆçº§é€‰æ‹©åˆé€‚çš„é…ç½®ã€‚
    """
    
    def __init__(self, base_dir: str = "."):
        """åˆå§‹åŒ–æ•°æ®åº“æå–å·¥å…·
        
        Args:
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
        """
        super().__init__(base_dir)
        self.extractor = DatabaseConfigExtractor(base_dir=base_dir)
        self.error_handler = ErrorHandler()
    
    @handle_tool_errors(tool_name="DBExtractor", operation="extract", return_format="json")
    def run(self, table_name: Optional[str] = None) -> str:
        """
        æ‰§è¡Œæ•°æ®åº“é…ç½®æå–å’ŒæŸ¥è¯¢
        
        Args:
            table_name: è¡¨åï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºæŸ¥è¯¢ç‰¹å®šè¡¨çš„ç»“æ„ä¿¡æ¯
            
        Returns:
            JSONæ ¼å¼çš„æŸ¥è¯¢ç»“æœæˆ–é”™è¯¯ä¿¡æ¯
        """
        # ä» base_dir ä¸­è§£æé¡¹ç›®åç§°
        project_name = self.base_dir.name
        
        # æ£€æŸ¥ table_name æ˜¯å¦æ˜¯ JSON å­—ç¬¦ä¸²
        if table_name and isinstance(table_name, str):
            # è§„èŒƒåŒ–å¤„ç†ï¼Œå»é™¤ç©ºç™½å­—ç¬¦
            table_name_normalized = table_name.strip()
            
            # ç‰¹æ®Šå¤„ç†ç©ºJSONå¯¹è±¡ {}
            if table_name_normalized == '{}':
                logger.debug("æ£€æµ‹åˆ°ç©ºJSONå¯¹è±¡ï¼Œå°†è¡¨åè®¾ç½®ä¸ºNoneï¼Œåªæå–é¡¹ç›®æ•°æ®åº“é…ç½®")
                table_name = None
            # å¤„ç†å…¶ä»–JSONå­—ç¬¦ä¸²
            elif table_name_normalized.startswith('{') and table_name_normalized.endswith('}'):
                try:
                    # å°è¯•è§£æ JSON
                    params = json.loads(table_name_normalized)
                    if isinstance(params, dict):
                        # æå– table_name å­—æ®µ
                        extracted_table_name = params.get('table_name')
                        
                        # å¦‚æœ table_name å‚æ•°ä¸º Noneï¼Œä½¿ç”¨ä» JSON ä¸­æå–çš„å€¼
                        if extracted_table_name is not None:
                            table_name = extracted_table_name
                        elif not params:  # ç©ºå­—å…¸æƒ…å†µ
                            logger.debug("æ£€æµ‹åˆ°ç©ºJSONå¯¹è±¡å­—å…¸ï¼Œå°†è¡¨åè®¾ç½®ä¸ºNoneï¼Œåªæå–é¡¹ç›®æ•°æ®åº“é…ç½®")
                            table_name = None
                        
                        logger.debug(f"ä»JSONä¸­æå–å‚æ•°: table_name={table_name}")
                except json.JSONDecodeError:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹å‚æ•°
                    logger.warning(f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å‚æ•°: {table_name}")
        
        return self._extract_internal(table_name)
    
    def _extract_internal(self, table_name: Optional[str] = None) -> str:
        """
        å†…éƒ¨æå–æ–¹æ³•
        
        Args:
            table_name: è¡¨åï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æŸ¥è¯¢ç»“æœ
            
        Raises:
            ConfigurationError: é…ç½®é”™è¯¯
            ServiceUnavailableError: æœåŠ¡ä¸å¯ç”¨
        """
        # ä» base_dir ä¸­è§£æé¡¹ç›®åç§°
        project_name = self.base_dir.name
        
        if not project_name or not project_name.strip():
            raise ConfigurationError(
                "æ— æ³•ä»åŸºç¡€ç›®å½•è§£æé¡¹ç›®åç§°",
                pattern=str(self.base_dir),
                tool_name=self.__class__.__name__
            )
        
        # æå–æ•°æ®åº“é…ç½®
        configs = self.extractor.extract_database_configs()
        
        if not configs:
            return json.dumps({
                "success": False,
                "message": f"æœªæ‰¾åˆ°é¡¹ç›® '{project_name}' çš„æ•°æ®åº“é…ç½®",
                "project_name": project_name,
                "table_name": table_name,
                "configs_found": 0
            }, ensure_ascii=False, indent=2)
        
        # è¿æ¥æ•°æ®åº“å¹¶æŸ¥è¯¢
        results = []
        
        # ç‰¹æ®Šå¤„ç†ç©ºJSONå¯¹è±¡ {}
        if table_name == '{}':
            logger.debug("_extract_internal: æ£€æµ‹åˆ°ç©ºJSONå¯¹è±¡ï¼Œå°†è¡¨åè®¾ç½®ä¸ºNoneï¼Œåªæå–é¡¹ç›®æ•°æ®åº“é…ç½®")
            return json.dumps({
                "success": True,
                "message": f"æˆåŠŸæå–é¡¹ç›® '{project_name}' çš„æ•°æ®åº“é…ç½®",
                "project_name": project_name,
                "table_name": None,
                "configs_found": len(configs),
                "configs": [str(config) for config in configs]
            }, ensure_ascii=False, indent=2)
        
        if table_name:
            # å¦‚æœæŒ‡å®šäº†è¡¨åï¼Œéœ€è¦æ™ºèƒ½é€‰æ‹©æ•°æ®åº“
            table_found = False
            
            # éªŒè¯è¡¨åï¼Œé˜²æ­¢SQLæ³¨å…¥
            validate_table_name(table_name)
            
            # é¦–å…ˆå»é‡æ•°æ®æºï¼Œé¿å…é‡å¤æŸ¥è¯¢ç›¸åŒçš„æ•°æ®åº“
            unique_configs = []
            seen_urls = set()
            
            for config in configs:
                # æå–æ•°æ®åº“URLçš„å…³é”®éƒ¨åˆ†ï¼ˆå»æ‰å‚æ•°ï¼‰
                url_key = config.url.split('?')[0] if '?' in config.url else config.url
                if url_key not in seen_urls:
                    seen_urls.add(url_key)
                    unique_configs.append(config)
            
            for config in unique_configs:
                try:
                    # è§£ææ•°æ®åº“è¿æ¥ä¿¡æ¯
                    url_pattern = r'jdbc:mysql://([^:/]+):?(\d+)?/([^?]+)'
                    match = re.match(url_pattern, config.url)
                    
                    if not match:
                        continue
                    
                    host = match.group(1)
                    port = int(match.group(2)) if match.group(2) else 3306
                    database = match.group(3)
                    
                    # è¿æ¥æ•°æ®åº“æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                    import pymysql
                    try:
                        connection = pymysql.connect(
                            host=host,
                            port=port,
                            user=config.username,
                            password=config.password,
                            database=database,
                            charset='utf8mb4',
                            connect_timeout=5
                        )
                        
                        with connection.cursor() as cursor:
                            # è¡¨åå·²åœ¨å‰é¢éªŒè¯ï¼Œæ­¤å¤„æ— éœ€é‡å¤éªŒè¯
                            cursor.execute(f"SHOW TABLES LIKE '{table_name}'")
                            table_exists = cursor.fetchone()
                            
                            if table_exists:
                                # æŸ¥è¯¢å»ºè¡¨è¯­å¥
                                result = self.extractor.connect_and_query(config, table_name)
                                if result:
                                    results.append(result)
                                    table_found = True
                                    connection.close()
                                    break  # æ‰¾åˆ°è¡¨åç«‹å³é€€å‡ºå¾ªç¯
                        
                        connection.close()
                    
                    except pymysql.err.OperationalError:
                        continue
                
                except Exception:
                    continue
            
            if not table_found:
                return json.dumps({
                    "success": False,
                    "message": f"åœ¨æ‰€æœ‰æ•°æ®åº“ä¸­éƒ½æœªæ‰¾åˆ°è¡¨ '{table_name}'",
                    "project_name": project_name,
                    "table_name": table_name,
                    "configs_found": len(configs),
                    "databases_checked": len(unique_configs)
                }, ensure_ascii=False, indent=2)
        
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¡¨åï¼ŒæŸ¥è¯¢æ‰€æœ‰æ•°æ®åº“çš„è¡¨åˆ—è¡¨
            # é¦–å…ˆå»é‡æ•°æ®æºï¼Œé¿å…é‡å¤è¿æ¥ç›¸åŒçš„æ•°æ®åº“
            unique_configs = []
            seen_urls = set()
            
            for config in configs:
                # æå–æ•°æ®åº“URLçš„å…³é”®éƒ¨åˆ†ï¼ˆå»æ‰å‚æ•°ï¼‰
                url_key = config.url.split('?')[0] if '?' in config.url else config.url
                if url_key not in seen_urls:
                    seen_urls.add(url_key)
                    unique_configs.append(config)
            
            for config in unique_configs:
                try:
                    result = self.extractor.connect_and_query(config)
                    if result:
                        results.append(result)
                except Exception:
                    continue
        
        # è¿”å›æ‰€æœ‰ç»“æœ
        final_result = "\n\n".join(results) if results else "æœªèƒ½è·å–æ•°æ®åº“ä¿¡æ¯"
        
        return json.dumps({
            "success": True,
            "message": f"æˆåŠŸæŸ¥è¯¢é¡¹ç›® '{project_name}' çš„æ•°æ®åº“ä¿¡æ¯",
            "project_name": project_name,
            "table_name": table_name,
            "configs_found": len(configs),
            "result": final_result
        }, ensure_ascii=False, indent=2)


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®åº“é…ç½®æå–å’ŒæŸ¥è¯¢å·¥å…·')
    parser.add_argument('--table', '-t', help='è¡¨å (å¯é€‰ï¼Œç”¨äºæŸ¥è¯¢å»ºè¡¨è¯­å¥)')
    parser.add_argument('--base-path', default='.', help='åŸºç¡€è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)')
    args = parser.parse_args()

    extractor = DatabaseConfigExtractor(args.base_path)
    
    # ä» base_path ä¸­è§£æé¡¹ç›®åç§°
    project_name = Path(args.base_path).resolve().name
    print(f"æœç´¢é¡¹ç›®: {project_name}")
    configs = extractor.extract_database_configs()

    if not configs:
        print("æœªæ‰¾åˆ°æ•°æ®åº“é…ç½®")
        return "æœªæ‰¾åˆ°æ•°æ®åº“é…ç½®"

    print(f"\næ‰¾åˆ° {len(configs)} ä¸ªæ•°æ®åº“é…ç½®:")
    for i, config in enumerate(configs, 1):
        print(f"{i}. {config}")

    # è¿æ¥æ•°æ®åº“å¹¶æŸ¥è¯¢
    results = []

    # ç‰¹æ®Šå¤„ç†ç©ºJSONå¯¹è±¡ {}
    if args.table == '{}':
        print(f"\næ£€æµ‹åˆ°ç©ºJSONå¯¹è±¡ï¼Œåªæå–é¡¹ç›® '{project_name}' çš„æ•°æ®åº“é…ç½®")
        for i, config in enumerate(configs, 1):
            print(f"{i}. {config}")
        return json.dumps({
            "success": True,
            "message": f"æˆåŠŸæå–é¡¹ç›® '{project_name}' çš„æ•°æ®åº“é…ç½®",
            "project_name": project_name,
            "table_name": None,  # æ˜ç¡®è®¾ç½®ä¸ºNone
            "configs_found": len(configs),
            "configs": [str(config) for config in configs]
        }, ensure_ascii=False, indent=2)
    
    if args.table:
        # éªŒè¯è¡¨åï¼Œé˜²æ­¢SQLæ³¨å…¥
        validate_table_name(args.table)
        
        # å¦‚æœæŒ‡å®šäº†è¡¨åï¼Œéœ€è¦æ™ºèƒ½é€‰æ‹©æ•°æ®åº“
        print(f"\næŸ¥è¯¢è¡¨ '{args.table}' çš„ç»“æ„...")
        table_found = False

        # é¦–å…ˆå»é‡æ•°æ®æºï¼Œé¿å…é‡å¤æŸ¥è¯¢ç›¸åŒçš„æ•°æ®åº“
        unique_configs = []
        seen_urls = set()

        for config in configs:
            # æå–æ•°æ®åº“URLçš„å…³é”®éƒ¨åˆ†ï¼ˆå»æ‰å‚æ•°ï¼‰
            url_key = config.url.split('?')[0] if '?' in config.url else config.url
            if url_key not in seen_urls:
                seen_urls.add(url_key)
                unique_configs.append(config)
            else:
                print(f"è·³è¿‡é‡å¤æ•°æ®æº: {config.name} -> {url_key}")

        print(f"å»é‡åå‰©ä½™ {len(unique_configs)} ä¸ªå”¯ä¸€æ•°æ®æº")

        for config in unique_configs:
            try:
                # å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨äºè¯¥æ•°æ®åº“ä¸­
                print(f"æ£€æŸ¥æ•°æ®åº“ {config.name} ä¸­æ˜¯å¦å­˜åœ¨è¡¨ '{args.table}'...")

                # è§£ææ•°æ®åº“è¿æ¥ä¿¡æ¯
                url_pattern = r'jdbc:mysql://([^:/]+):?(\d+)?/([^?]+)'
                match = re.match(url_pattern, config.url)

                if not match:
                    print(f"æ— æ³•è§£ææ•°æ®åº“URL: {config.url}")
                    continue

                host = match.group(1)
                port = int(match.group(2)) if match.group(2) else 3306
                database = match.group(3)

                # è¿æ¥æ•°æ®åº“æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                import pymysql
                try:
                    connection = pymysql.connect(
                        host=host,
                        port=port,
                        user=config.username,
                        password=config.password,
                        database=database,
                        charset='utf8mb4',
                        connect_timeout=5
                    )

                    with connection.cursor() as cursor:
                        # è¡¨åå·²åœ¨å‰é¢éªŒè¯ï¼Œæ­¤å¤„æ— éœ€é‡å¤éªŒè¯
                        cursor.execute(f"SHOW TABLES LIKE '{args.table}'")
                        table_exists = cursor.fetchone()

                        if table_exists:
                            print(f"âœ… åœ¨æ•°æ®åº“ {database} ä¸­æ‰¾åˆ°è¡¨ '{args.table}'")
                            # æŸ¥è¯¢å»ºè¡¨è¯­å¥
                            result = extractor.connect_and_query(config, args.table)
                            if result:
                                results.append(result)
                                table_found = True
                                # æ‰¾åˆ°è¡¨åå°±é€€å‡ºå¾ªç¯ï¼Œé¿å…é‡å¤æŸ¥è¯¢
                                connection.close()

                                # è¾“å‡ºæœ€ç»ˆç»“æœ
                                print("\n" + "=" * 80)
                                print("æœ€ç»ˆç»“æœ:")
                                print("=" * 80)
                                print(result)

                                return result  # æ‰¾åˆ°è¡¨åç«‹å³è¿”å›ç»“æœ
                        else:
                            print(f"âŒ æ•°æ®åº“ {database} ä¸­ä¸å­˜åœ¨è¡¨ '{args.table}'")

                    connection.close()

                except pymysql.err.OperationalError as e:
                    print(f"è¿æ¥æ•°æ®åº“ {database} å¤±è´¥: {e}")
                    continue

            except Exception as e:
                print(f"æ£€æŸ¥æ•°æ®åº“ {config.name} æ—¶å‡ºé”™: {e}")
                continue

        if not table_found:
            error_msg = f"åœ¨æ‰€æœ‰æ•°æ®åº“ä¸­éƒ½æœªæ‰¾åˆ°è¡¨ '{args.table}'"
            print(error_msg)
            return error_msg

    else:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¡¨åï¼ŒæŸ¥è¯¢æ‰€æœ‰æ•°æ®åº“çš„è¡¨åˆ—è¡¨
        # é¦–å…ˆå»é‡æ•°æ®æºï¼Œé¿å…é‡å¤è¿æ¥ç›¸åŒçš„æ•°æ®åº“
        unique_configs = []
        seen_urls = set()

        for config in configs:
            # æå–æ•°æ®åº“URLçš„å…³é”®éƒ¨åˆ†ï¼ˆå»æ‰å‚æ•°ï¼‰
            url_key = config.url.split('?')[0] if '?' in config.url else config.url
            if url_key not in seen_urls:
                seen_urls.add(url_key)
                unique_configs.append(config)
            else:
                print(f"è·³è¿‡é‡å¤æ•°æ®æº: {config.name} -> {url_key}")

        print(f"\nå»é‡åå‰©ä½™ {len(unique_configs)} ä¸ªå”¯ä¸€æ•°æ®æº")

        for config in unique_configs:
            try:
                result = extractor.connect_and_query(config)
                if result:
                    results.append(result)
            except KeyboardInterrupt:
                print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
                break
            except Exception as e:
                error_msg = f"å¤„ç†é…ç½® {config.name} æ—¶å‡ºé”™: {e}"
                print(error_msg)
                # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                import traceback
                detailed_error = traceback.format_exc()
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {detailed_error}")
                results.append(f"{error_msg}\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{detailed_error}")
                continue

    # æå–è¡¨ä¿¡æ¯å¹¶æ”¾åœ¨ç»“æœå‰é¢
    if results:
        all_tables = []
        for result in results:
            # æå–è¡¨ä¿¡æ¯
            tables_section = []
            in_table_section = False

            for line in result.split('\n'):
                if "=" * 50 in line:
                    in_table_section = not in_table_section
                    if in_table_section:  # åªåœ¨è¿›å…¥è¡¨åŒºåŸŸæ—¶æ·»åŠ åˆ†éš”ç¬¦
                        tables_section.append(line)
                elif in_table_section:
                    tables_section.append(line)

            if tables_section:
                all_tables.extend(tables_section)

        # å¦‚æœæ‰¾åˆ°äº†è¡¨ä¿¡æ¯ï¼Œå°†å…¶æ·»åŠ åˆ°ç»“æœçš„å¼€å¤´
        if all_tables:
            tables_summary = "\n".join(all_tables)
            print("\nè¡¨ä¿¡æ¯æ‘˜è¦:")
            print(tables_summary)

            # å°†è¡¨ä¿¡æ¯æ·»åŠ åˆ°ç»“æœçš„å¼€å¤´
            combined_results = f"æ•°æ®åº“è¡¨ä¿¡æ¯æ‘˜è¦:\n{tables_summary}\n\nå®Œæ•´æŸ¥è¯¢ç»“æœ:\n" + "\n\n".join(results)
            return combined_results

    # è¿”å›æ‰€æœ‰ç»“æœ
    final_result = "\n\n".join(results) if results else "æœªèƒ½è·å–æ•°æ®åº“ä¿¡æ¯"

    # è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n" + "=" * 80)
    print("æœ€ç»ˆç»“æœ:")
    print("=" * 80)
    print(final_result)

    return final_result


if __name__ == '__main__':
    main()