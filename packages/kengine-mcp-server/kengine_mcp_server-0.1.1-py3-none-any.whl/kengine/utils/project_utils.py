"""
é¡¹ç›®ä¿¡æ¯æå–å·¥å…·æ¨¡å—

æä¾›ä»æœ¬åœ°ç›®å½•æå–é¡¹ç›®ä¿¡æ¯çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬READMEæ–‡ä»¶ã€é…ç½®æ–‡ä»¶ã€ç›®å½•ç»“æ„åˆ†æç­‰ã€‚
"""

import logging
from pathlib import Path
from typing import Dict, List, Optional, NamedTuple
from dataclasses import dataclass

from .text_reader import TextReader
from .dir_utils import classify_files_by_type
from .dir_utils.markdown_generator import generate_directory_markdown
from ..config.file_extensions import get_language_by_extension

logger = logging.getLogger(__name__)

# ç¼“å­˜åŠŸèƒ½å·²é€šè¿‡ @cached è£…é¥°å™¨å®ç°


MAX_CONFIG_FILE_SIZE = 50000
MAX_STRUCTURE_LINES = 1000
README_MAX_LENGTH = 1000

@dataclass
class ProjectInfo:
    """é¡¹ç›®ä¿¡æ¯æ•°æ®ç±»"""
    directory_path: str
    project_name: str = ""
    readme_content: Optional[str] = None
    config_files: Dict[str, str] = None
    file_statistics: Dict[str, int] = None
    language_statistics: Dict[str, int] = None
    primary_language: Optional[str] = None
    directory_structure: Optional[str] = None
    
    def __post_init__(self):
        if self.config_files is None:
            self.config_files = {}
        if self.file_statistics is None:
            self.file_statistics = {}
        if self.language_statistics is None:
            self.language_statistics = {}


class ProjectAnalyzer:
    """é¡¹ç›®åˆ†æå™¨ï¼Œç”¨äºæå–é¡¹ç›®ä¿¡æ¯"""
    
    # å¸¸è§çš„READMEæ–‡ä»¶å
    README_FILENAMES = [
        "README.md", "README.txt", "README.rst", "README", "readme.md", 
        "readme.txt", "readme.rst", "readme", "Readme.md", "Readme.txt"
    ]
    
    # é¡¹ç›®é…ç½®æ–‡ä»¶åï¼ˆç”¨äºè·å–é¡¹ç›®ä¿¡æ¯ï¼‰
    PROJECT_CONFIG_FILES = [
        "package.json", "setup.py", "requirements.txt", "Cargo.toml", "go.mod",
        "pom.xml", "build.gradle", "composer.json", "Gemfile", "pubspec.yaml",
        "project.clj", "mix.exs", "stack.yaml", "Pipfile", "pyproject.toml"
    ]
    
    
    
    def __init__(self, max_config_file_size: int = MAX_CONFIG_FILE_SIZE, max_structure_lines: int = MAX_STRUCTURE_LINES):
        """
        åˆå§‹åŒ–é¡¹ç›®åˆ†æå™¨
        
        Args:
            max_config_file_size: é…ç½®æ–‡ä»¶æœ€å¤§è¯»å–å­—ç¬¦æ•°
            max_structure_lines: ç›®å½•ç»“æ„æœ€å¤§æ˜¾ç¤ºè¡Œæ•°
        """
        self.text_reader = TextReader()
        self.max_config_file_size = max_config_file_size
        self.max_structure_lines = max_structure_lines
    
    def analyze_project(self, directory_path: str) -> ProjectInfo:
        """
        åˆ†æé¡¹ç›®ç›®å½•ï¼Œæå–é¡¹ç›®ä¿¡æ¯
        
        Args:
            directory_path: é¡¹ç›®ç›®å½•è·¯å¾„
            
        Returns:
            ProjectInfoå¯¹è±¡ï¼ŒåŒ…å«é¡¹ç›®çš„å„ç§ä¿¡æ¯
            
        Raises:
            ValueError: ç›®å½•è·¯å¾„æ— æ•ˆ
            FileNotFoundError: ç›®å½•ä¸å­˜åœ¨
        """
        if not directory_path or not isinstance(directory_path, str):
            raise ValueError("ç›®å½•è·¯å¾„ä¸èƒ½ä¸ºç©º")
        
        dir_path = Path(directory_path)
        if not dir_path.exists():
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        
        if not dir_path.is_dir():
            raise ValueError(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {directory_path}")
        
        logger.info(f"å¼€å§‹åˆ†æé¡¹ç›®: {directory_path}")
        
        # æå–é¡¹ç›®åç§°ï¼ˆç›®å½•è·¯å¾„çš„æœ€åä¸€æ®µï¼‰
        project_name = Path(directory_path).name
        
        project_info = ProjectInfo(directory_path=directory_path, project_name=project_name)
        
        # 1. è¯»å–READMEæ–‡ä»¶
        # å¯¹ readmeè¿›è¡Œå¿…è¦ç²¾ç®€
        readme = self._find_and_read_readme(dir_path)
        
        if readme and len(readme) > README_MAX_LENGTH:
            from kengine.core.utils.summerize import summerize
            logger.info(f"summerize readme to {README_MAX_LENGTH}")
            readme = summerize(readme, "default", README_MAX_LENGTH)
            
        project_info.readme_content = readme
        
        # 2. è¯»å–é…ç½®æ–‡ä»¶
        project_info.config_files = self._read_config_files(dir_path)
        
        # 3. åˆ†ææ–‡ä»¶ç»Ÿè®¡å’Œç¼–ç¨‹è¯­è¨€
        self._analyze_files_and_languages(dir_path, project_info)
        
        # 4. ç”Ÿæˆç›®å½•ç»“æ„
        project_info.directory_structure = self._generate_directory_structure(dir_path)
        
        logger.info(f"é¡¹ç›®åˆ†æå®Œæˆ: {directory_path}")
        return project_info
    
    def _find_and_read_readme(self, dir_path: Path) -> Optional[str]:
        """
        æŸ¥æ‰¾å¹¶è¯»å–READMEæ–‡ä»¶
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            
        Returns:
            READMEæ–‡ä»¶å†…å®¹ï¼Œæœªæ‰¾åˆ°è¿”å›None
        """
        for readme_name in self.README_FILENAMES:
            readme_path = dir_path / readme_name
            if readme_path.exists() and readme_path.is_file():
                content = self.text_reader.read_text_file(str(readme_path))
                if content:
                    logger.info(f"æ‰¾åˆ°READMEæ–‡ä»¶: {readme_path}")
                    return content
        
        logger.info("æœªæ‰¾åˆ°READMEæ–‡ä»¶")
        return None
    
    def _read_config_files(self, dir_path: Path) -> Dict[str, str]:
        """
        è¯»å–é¡¹ç›®é…ç½®æ–‡ä»¶
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            
        Returns:
            é…ç½®æ–‡ä»¶ååˆ°å†…å®¹çš„æ˜ å°„å­—å…¸
        """
        config_files = {}
        
        for config_file in self.PROJECT_CONFIG_FILES:
            config_path = dir_path / config_file
            if config_path.exists() and config_path.is_file():
                content = self.text_reader.read_text_file(
                    str(config_path), 
                    max_length=self.max_config_file_size
                )
                if content:
                    config_files[config_file] = content
                    logger.info(f"è¯»å–é…ç½®æ–‡ä»¶: {config_path}")
        
        return config_files
    
    def _analyze_files_and_languages(self, dir_path: Path, project_info: ProjectInfo) -> None:
        """
        åˆ†ææ–‡ä»¶ç»Ÿè®¡å’Œç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            project_info: é¡¹ç›®ä¿¡æ¯å¯¹è±¡ï¼Œä¼šè¢«ä¿®æ”¹
        """
        try:
            source_files, doc_files, binary_files = classify_files_by_type(
                str(dir_path), recursive=True, include_hidden=False
            )
            
            # æ–‡ä»¶ç»Ÿè®¡
            project_info.file_statistics = {
                'total': len(source_files) + len(doc_files) + len(binary_files),
                'source': len(source_files),
                'document': len(doc_files),
                'binary': len(binary_files)
            }
            
            # ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡
            if source_files:
                project_info.language_statistics = self._analyze_programming_languages(source_files)
                # æ£€æµ‹ä¸»è¦ç¼–ç¨‹è¯­è¨€
                project_info.primary_language = self._detect_primary_language(source_files, project_info.language_statistics)
            
            logger.info(f"æ–‡ä»¶åˆ†æå®Œæˆ: æ€»è®¡ {project_info.file_statistics['total']} ä¸ªæ–‡ä»¶")
            if project_info.primary_language:
                logger.info(f"æ£€æµ‹åˆ°ä¸»è¦ç¼–ç¨‹è¯­è¨€: {project_info.primary_language}")
            
        except Exception as e:
            logger.warning(f"æ–‡ä»¶åˆ†æå¤±è´¥: {e}")
            project_info.file_statistics = {'total': 0, 'source': 0, 'document': 0, 'binary': 0}
            project_info.language_statistics = {}
    
    def _analyze_programming_languages(self, source_files: List[str]) -> Dict[str, int]:
        """
        åˆ†æç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ
        
        Args:
            source_files: æºä»£ç æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡å­—å…¸
        """
        language_stats = {}
        
        for file_path in source_files:
            ext = Path(file_path).suffix.lower()
            
            # ä½¿ç”¨ç»Ÿä¸€é…ç½®æ¨¡å—è·å–è¯­è¨€åç§°ï¼Œæä¾›é™çº§æ–¹æ¡ˆ
            try:
                language = get_language_by_extension(ext)
                if language is None:
                    language = f"å…¶ä»–({ext})"
            except Exception as e:
                logger.warning(f"æ— æ³•ä»ç»Ÿä¸€é…ç½®è·å–è¯­è¨€ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†: {e}")
                language = f"å…¶ä»–({ext})"
            
            language_stats[language] = language_stats.get(language, 0) + 1
        
        # æŒ‰æ–‡ä»¶æ•°é‡æ’åºï¼Œè¿”å›å‰10ä¸ª
        sorted_stats = dict(sorted(language_stats.items(), key=lambda x: x[1], reverse=True)[:10])
        return sorted_stats
    
    def _detect_primary_language(self, source_files: List[str], language_statistics: Dict[str, int]) -> Optional[str]:
        """
        æ£€æµ‹é¡¹ç›®çš„ä¸»è¦ç¼–ç¨‹è¯­è¨€
        
        åŸºäºä»¥ä¸‹ç­–ç•¥è¿›è¡Œæ£€æµ‹ï¼š
        1. æ’é™¤é…ç½®æ–‡ä»¶ã€æ–‡æ¡£æ–‡ä»¶ç­‰éæ ¸å¿ƒä»£ç æ–‡ä»¶
        2. è€ƒè™‘æ–‡ä»¶æ•°é‡æƒé‡
        3. è€ƒè™‘æ–‡ä»¶å¤§å°æƒé‡ï¼ˆå¤§æ–‡ä»¶åº”è¯¥æœ‰æ›´é«˜æƒé‡ï¼‰
        4. å¤„ç†å¤šè¯­è¨€é¡¹ç›®çš„æƒ…å†µ
        
        Args:
            source_files: æºä»£ç æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            language_statistics: è¯­è¨€ç»Ÿè®¡å­—å…¸
            
        Returns:
            ä¸»è¦ç¼–ç¨‹è¯­è¨€åç§°ï¼Œæœªæ£€æµ‹åˆ°è¿”å›None
        """
        if not source_files or not language_statistics:
            return None
        
        try:
            # å®šä¹‰éœ€è¦æ’é™¤çš„è¯­è¨€ç±»å‹ï¼ˆé…ç½®æ–‡ä»¶ã€æ ‡è®°è¯­è¨€ç­‰ï¼‰
            excluded_languages = {
                'JSON', 'YAML', 'XML', 'TOML', 'INI', 'Config',
                'HTML', 'CSS', 'SCSS', 'Sass', 'Less',
                'Markdown', 'Text'
            }
            
            # è®¡ç®—åŠ æƒåˆ†æ•°
            language_scores = {}
            
            for file_path in source_files:
                try:
                    file_path_obj = Path(file_path)
                    ext = file_path_obj.suffix.lower()
                    
                    # è·å–è¯­è¨€åç§°
                    language = get_language_by_extension(ext)
                    if not language:
                        continue
                    
                    # è·³è¿‡æ’é™¤çš„è¯­è¨€ç±»å‹
                    if language in excluded_languages:
                        continue
                    
                    # è·³è¿‡ä»¥"å…¶ä»–"å¼€å¤´çš„è¯­è¨€
                    if language.startswith("å…¶ä»–"):
                        continue
                    
                    # è·å–æ–‡ä»¶å¤§å°æƒé‡
                    try:
                        file_size = file_path_obj.stat().st_size if file_path_obj.exists() else 0
                        # æ–‡ä»¶å¤§å°æƒé‡ï¼šå°æ–‡ä»¶æƒé‡1ï¼Œå¤§æ–‡ä»¶æƒé‡æ›´é«˜
                        size_weight = min(max(file_size / 1000, 1), 10)  # 1KB = æƒé‡1ï¼Œæœ€å¤§æƒé‡10
                    except (OSError, FileNotFoundError):
                        size_weight = 1
                    
                    # ç´¯åŠ æƒé‡åˆ†æ•°
                    if language not in language_scores:
                        language_scores[language] = 0
                    language_scores[language] += size_weight
                    
                except Exception as e:
                    logger.debug(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                    continue
            
            if not language_scores:
                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ç¼–ç¨‹è¯­è¨€ï¼Œä»ç»Ÿè®¡ä¸­é€‰æ‹©æ–‡ä»¶æ•°æœ€å¤šçš„éæ’é™¤è¯­è¨€
                for language, count in sorted(language_statistics.items(), key=lambda x: x[1], reverse=True):
                    if language not in excluded_languages and not language.startswith("å…¶ä»–"):
                        return language
                return None
            
            # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„è¯­è¨€
            sorted_languages = sorted(language_scores.items(), key=lambda x: x[1], reverse=True)
            primary_language, primary_weight = sorted_languages[0]
            
            # éªŒè¯ä¸»è¯­è¨€çš„åˆç†æ€§
            primary_count = language_statistics.get(primary_language, 0)
            total_programming_files = sum(
                count for lang, count in language_statistics.items()
                if lang not in excluded_languages and not lang.startswith("å…¶ä»–")
            )
            
            # è®¡ç®—æƒé‡æ¯”ä¾‹
            total_weight = sum(language_scores.values())
            weight_ratio = primary_weight / total_weight if total_weight > 0 else 0
            
            # æ”¹è¿›çš„é˜ˆå€¼æ¡ä»¶ï¼š
            # 1. è‡³å°‘2ä¸ªæ–‡ä»¶ï¼Œæˆ–
            # 2. æ–‡ä»¶æ•°å æ¯”è¶…è¿‡30%ï¼Œæˆ–
            # 3. æƒé‡å æ¯”è¶…è¿‡50%ï¼ˆè€ƒè™‘å¤§æ–‡ä»¶çš„é‡è¦æ€§ï¼‰
            file_ratio = primary_count / total_programming_files if total_programming_files > 0 else 0
            
            if (primary_count >= 2 or
                file_ratio >= 0.3 or
                weight_ratio >= 0.5):
                return primary_language
            
            return None
            
        except Exception as e:
            logger.warning(f"ä¸»è¯­è¨€æ£€æµ‹å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šè¿”å›æ–‡ä»¶æ•°æœ€å¤šçš„éæ’é™¤è¯­è¨€
            try:
                excluded_languages = {'JSON', 'YAML', 'XML', 'HTML', 'CSS', 'Markdown'}
                for language, count in sorted(language_statistics.items(), key=lambda x: x[1], reverse=True):
                    if language not in excluded_languages and not language.startswith("å…¶ä»–"):
                        return language
            except Exception:
                pass
            return None
    
    def _generate_directory_structure(self, dir_path: Path) -> Optional[str]:
        """
        ç”Ÿæˆç›®å½•ç»“æ„
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            
        Returns:
            ç›®å½•ç»“æ„å­—ç¬¦ä¸²ï¼Œç”Ÿæˆå¤±è´¥è¿”å›None
        """
        max_depth = 4
        structure = generate_directory_markdown(
            str(dir_path), 
            max_depth,
            exclude_extensions=['.png', '.jpeg', '.gif', '.jpg' ,'.bmp', '.tiff', '.svg', '.ico',
                                '.lib', '.so' ,'.dll', '.exe', '.jar', 
                                '.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.xz', '.7z',
                                '.iso', '.img', '.apk', '.deb', '.rpm', '.msi', '.app', 
                                '.dmg', '.pkg', '.exe', '.bat', 
                                '.sql', '.xml', '.json', '.csv', '.tsv', '.log', '.md',
                                '.txt', '.rst', '.yml', '.yaml', '.ini', '.cfg','.http',
                                '.conf', '.properties', '.env', '.bat', '.sh'])
        logger.info(f'project directory \n{structure}')
        return structure


class ProjectInfoFormatter:
    """é¡¹ç›®ä¿¡æ¯æ ¼å¼åŒ–å™¨ï¼Œå°†ProjectInfoè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
    
    @staticmethod
    def format_project_info(project_info: ProjectInfo) -> str:
        """
        å°†é¡¹ç›®ä¿¡æ¯æ ¼å¼åŒ–ä¸ºæ–‡æœ¬
        
        Args:
            project_info: é¡¹ç›®ä¿¡æ¯å¯¹è±¡
            
        Returns:
            æ ¼å¼åŒ–åçš„é¡¹ç›®ä¿¡æ¯æ–‡æœ¬
        """
        sections = []
        
        # é¡¹ç›®åç§°
        if project_info.project_name:
            sections.append("=== é¡¹ç›®ä¿¡æ¯ ===")
            sections.append(f"é¡¹ç›®åç§°: {project_info.project_name}")
            sections.append(f"é¡¹ç›®è·¯å¾„: {project_info.directory_path}")
            if project_info.primary_language:
                sections.append(f"ä¸»è¦ç¼–ç¨‹è¯­è¨€: {project_info.primary_language}")
        
        # READMEå†…å®¹
        if project_info.readme_content:
            sections.append("=== README å†…å®¹ ===")
            sections.append(project_info.readme_content)
        
        # é¡¹ç›®é…ç½®ä¿¡æ¯
        if project_info.config_files:
            sections.append("=== é¡¹ç›®é…ç½®ä¿¡æ¯ ===")
            config_parts = []
            for filename, content in project_info.config_files.items():
                config_parts.append(f"--- {filename} ---")
                config_parts.append(content)
            sections.append("\n\n".join(config_parts))
        
        # ç›®å½•ç»“æ„åˆ†æ
        if project_info.file_statistics or project_info.language_statistics or project_info.directory_structure:
            sections.append("=== ç›®å½•ç»“æ„åˆ†æ ===")
            analysis_parts = []
            
            # æ–‡ä»¶ç»Ÿè®¡
            if project_info.file_statistics and project_info.file_statistics.get('total', 0) > 0:
                stats = project_info.file_statistics
                analysis_parts.append(f"æ–‡ä»¶ç»Ÿè®¡: æ€»è®¡ {stats['total']} ä¸ªæ–‡ä»¶")
                analysis_parts.append(f"- æºä»£ç æ–‡ä»¶: {stats['source']} ä¸ª")
                analysis_parts.append(f"- æ–‡æ¡£æ–‡ä»¶: {stats['document']} ä¸ª")
                analysis_parts.append(f"- äºŒè¿›åˆ¶æ–‡ä»¶: {stats['binary']} ä¸ª")
            
            # ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡
            if project_info.language_statistics:
                analysis_parts.append("\nä¸»è¦ç¼–ç¨‹è¯­è¨€:")
                for lang, count in project_info.language_statistics.items():
                    analysis_parts.append(f"- {lang}: {count} ä¸ªæ–‡ä»¶")
            
            # ç›®å½•ç»“æ„
            if project_info.directory_structure:
                analysis_parts.append(f"\nç›®å½•ç»“æ„æ¦‚è§ˆ:\n{project_info.directory_structure}")
            
            if analysis_parts:
                sections.append("\n".join(analysis_parts))
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•ä¿¡æ¯ï¼Œæä¾›åŸºæœ¬ä¿¡æ¯
        if not sections:
            sections.append("=== åŸºæœ¬ç›®å½•ä¿¡æ¯ ===")
            sections.append(f"ç›®å½•è·¯å¾„: {project_info.directory_path}")
        
        return "\n\n".join(sections)


# ä¾¿æ·å‡½æ•° - ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨
from ..cache.manager import cached

@cached(maxsize=50, ttl=1800)  # ç¼“å­˜50ä¸ªé¡¹ç›®ï¼Œ30åˆ†é’ŸTTL
def analyze_project(directory_path: str) -> ProjectInfo:
    """
    ä¾¿æ·çš„é¡¹ç›®åˆ†æå‡½æ•°ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Args:
        directory_path: é¡¹ç›®ç›®å½•è·¯å¾„
        
    Returns:
        ProjectInfoå¯¹è±¡
    """
    import logging
    logger = logging.getLogger(__name__)
    logger.warning(f"ğŸ” [CACHE] analyze_project() ç¼“å­˜æœªå‘½ä¸­ï¼Œå¼€å§‹åˆ†æé¡¹ç›®: {directory_path}")
    
    import traceback
    stack_trace = traceback.format_stack()
    caller_info = stack_trace[-2].strip() if len(stack_trace) >= 2 else "æœªçŸ¥è°ƒç”¨è€…"
    logger.warning(f"ğŸ” [DEBUG] analyze_project() è°ƒç”¨è€…: {caller_info}")
    
    analyzer = ProjectAnalyzer()
    return analyzer.analyze_project(directory_path)


@cached(maxsize=50, ttl=1800)  # ç¼“å­˜50ä¸ªé¡¹ç›®æ–‡æœ¬ï¼Œ30åˆ†é’ŸTTL
def get_project_info_text(directory_path: str) -> str:
    """
    ä¾¿æ·çš„é¡¹ç›®ä¿¡æ¯è·å–å‡½æ•°ï¼Œç›´æ¥è¿”å›æ ¼å¼åŒ–çš„æ–‡æœ¬ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Args:
        directory_path: é¡¹ç›®ç›®å½•è·¯å¾„
        
    Returns:
        æ ¼å¼åŒ–çš„é¡¹ç›®ä¿¡æ¯æ–‡æœ¬
    """
    import logging
    logger = logging.getLogger(__name__)
    logger.warning(f"ğŸ” [CACHE] get_project_info_text() ç¼“å­˜æœªå‘½ä¸­ï¼Œå¼€å§‹ç”Ÿæˆæ–‡æœ¬: {directory_path}")
    
    project_info = analyze_project(directory_path)
    return ProjectInfoFormatter.format_project_info(project_info)


# åŸå§‹åˆ†æå‡½æ•°ï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼‰
def analyze_project_direct(directory_path: str) -> ProjectInfo:
    """
    ç›´æ¥åˆ†æé¡¹ç›®ï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼‰
    
    Args:
        directory_path: é¡¹ç›®ç›®å½•è·¯å¾„
        
    Returns:
        ProjectInfoå¯¹è±¡
    """
    analyzer = ProjectAnalyzer()
    return analyzer.analyze_project(directory_path)


# ç¼“å­˜ç®¡ç†å‡½æ•°
def clear_project_info_cache():
    """æ¸…é™¤é¡¹ç›®ä¿¡æ¯ç¼“å­˜"""
    import logging
    logger = logging.getLogger(__name__)
    
    if hasattr(analyze_project, 'cache_clear'):
        analyze_project.cache_clear()
        logger.info("å·²æ¸…é™¤ analyze_project ç¼“å­˜")
    
    if hasattr(get_project_info_text, 'cache_clear'):
        get_project_info_text.cache_clear()
        logger.info("å·²æ¸…é™¤ get_project_info_text ç¼“å­˜")


def get_project_info_cache_stats():
    """è·å–é¡¹ç›®ä¿¡æ¯ç¼“å­˜ç»Ÿè®¡"""
    stats = {}
    
    if hasattr(analyze_project, 'cache_info'):
        stats['analyze_project'] = analyze_project.cache_info()
    
    if hasattr(get_project_info_text, 'cache_info'):
        stats['get_project_info_text'] = get_project_info_text.cache_info()
    
    return stats