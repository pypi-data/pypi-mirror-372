Metadata-Version: 2.4
Name: tabaml
Version: 0.2.1
Summary: TabAML is a framework for tabular data classification models
Author-email: xiaoql <xiaoql@hollycrm.com>
Project-URL: Homepage, https://github.com/Qiliang/tabaml
Project-URL: Issues, https://github.com/Qiliang/tabaml/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: fastparquet>=2024.11.0
Requires-Dist: numpy
Requires-Dist: pandas
Requires-Dist: torch

# TabAML - è¡¨æ ¼æ•°æ®æœºå™¨å­¦ä¹ æ¡†æ¶

TabAML (Tabular Machine Learning) æ˜¯ä¸€ä¸ªåŸºäºPyTorchçš„è¡¨æ ¼æ•°æ®åˆ†ç±»æ¡†æ¶ï¼Œæ”¯æŒäºŒåˆ†ç±»å’Œå¤šåˆ†ç±»ä»»åŠ¡ã€‚

## ç‰¹æ€§

- ğŸ”¥ **äºŒåˆ†ç±»æ¨¡å‹**: æ”¯æŒäºŒåˆ†ç±»ä»»åŠ¡ï¼ŒåŒ…å«å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹
- ğŸŒŸ **å¤šåˆ†ç±»æ¨¡å‹**: æ”¯æŒå¤šåˆ†ç±»ä»»åŠ¡ï¼Œè‡ªåŠ¨æ£€æµ‹ç±»åˆ«æ•°é‡
- ğŸ“Š **ä¸°å¯Œçš„è¯„ä¼°æŒ‡æ ‡**: æ”¯æŒå‡†ç¡®ç‡ã€F1åˆ†æ•°ï¼ˆmacro/micro/weightedï¼‰ç­‰å¤šç§è¯„ä¼°æŒ‡æ ‡
- âš¡ **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒåŸºäºéªŒè¯é›†æ€§èƒ½è‡ªåŠ¨åœæ­¢è®­ç»ƒ
- ğŸ› ï¸ **å¯é…ç½®æ€§**: é€šè¿‡è¶…å‚æ•°å­—å…¸çµæ´»é…ç½®æ¨¡å‹ç»“æ„å’Œè®­ç»ƒå‚æ•°
- ğŸ“ˆ **è‡ªåŠ¨åŒ–è®­ç»ƒ**: åŒ…å«æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€éªŒè¯å’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹

## å®‰è£…

ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š

```bash
pip install torch pandas numpy
```

## å¿«é€Ÿå¼€å§‹

### äº¤äº’å¼è¿è¡Œ

```bash
python main.py
```

ç„¶åé€‰æ‹©è¦è¿è¡Œçš„æ¨¡å‹ç±»å‹ï¼š
- 1: äºŒåˆ†ç±»æ¨¡å‹
- 2: å¤šåˆ†ç±»æ¨¡å‹

### äºŒåˆ†ç±»æ¨¡å‹

```python
from binary_cls import BinaryClsModel
import pandas as pd

# åŠ è½½æ•°æ®
df_train = pd.read_csv("sample/binary_cls_train.csv")
df_val = pd.read_csv("sample/binary_cls_val.csv")
X_train = df_train.drop(columns=['label'])
y_train = df_train['label']
X_val = df_val.drop(columns=['label'])
y_val = df_val['label']

# åˆ›å»ºæ¨¡å‹
model = BinaryClsModel(
    hyperparameters={
        'learning_rate': 0.01,
        'batch_size': 32,
        'num_layers': 3,
        'hidden_size': 64,
        'dropout_prob': 0.2,
        'patience': 10,
        'use_early_stopping': True
    }
)

# è®­ç»ƒæ¨¡å‹
model.fit(X=X_train, y=y_train, X_val=X_val, y_val=y_val)

# è¯„ä¼°æ¨¡å‹
accuracy = model.score(X_val, y_val, metric='accuracy')
f1 = model.score(X_val, y_val, metric='f1')
print(f"éªŒè¯é›†å‡†ç¡®ç‡: {accuracy:.4f}")
print(f"éªŒè¯é›†F1åˆ†æ•°: {f1:.4f}")
```

### å¤šåˆ†ç±»æ¨¡å‹

```python
from multi_cls import MultiClassifierModel
import pandas as pd

# åŠ è½½æ•°æ®
df_train = pd.read_csv("sample/multi_cls_train.csv")
df_val = pd.read_csv("sample/multi_cls_val.csv")
X_train = df_train.drop(columns=['label'])
y_train = df_train['label']
X_val = df_val.drop(columns=['label'])
y_val = df_val['label']

# åˆ›å»ºæ¨¡å‹
model = MultiClassifierModel(
    hyperparameters={
        'learning_rate': 0.01,
        'batch_size': 32,
        'num_layers': 3,
        'hidden_size': 64,
        'dropout_prob': 0.2,
        'patience': 10,
        'use_early_stopping': True,
        'f1_average': 'macro'  # F1è®¡ç®—æ–¹å¼: 'macro', 'micro', 'weighted'
    }
)

# è®­ç»ƒæ¨¡å‹
model.fit(X=X_train, y=y_train, X_val=X_val, y_val=y_val)

# è¯„ä¼°æ¨¡å‹
accuracy = model.score(X_val, y_val, metric='accuracy')
f1_macro = model.score(X_val, y_val, metric='f1_macro')
f1_micro = model.score(X_val, y_val, metric='f1_micro')
f1_weighted = model.score(X_val, y_val, metric='f1_weighted')

print(f"éªŒè¯é›†å‡†ç¡®ç‡: {accuracy:.4f}")
print(f"éªŒè¯é›†F1 (macro): {f1_macro:.4f}")
print(f"éªŒè¯é›†F1 (micro): {f1_micro:.4f}")
print(f"éªŒè¯é›†F1 (weighted): {f1_weighted:.4f}")
```

## æ¨¡å‹ç»“æ„

### ç¥ç»ç½‘ç»œæ¶æ„

- **è¾“å…¥å±‚**: è‡ªåŠ¨é€‚åº”ç‰¹å¾ç»´åº¦
- **éšè—å±‚**: å¯é…ç½®çš„å±‚æ•°å’Œç¥ç»å…ƒæ•°é‡
- **æ¿€æ´»å‡½æ•°**: ReLU
- **æ­£åˆ™åŒ–**: Dropout
- **è¾“å‡ºå±‚**: 
  - äºŒåˆ†ç±»: 2ä¸ªç¥ç»å…ƒ + CrossEntropyLoss
  - å¤šåˆ†ç±»: è‡ªåŠ¨æ£€æµ‹ç±»åˆ«æ•°é‡ + CrossEntropyLoss

### å¯é…ç½®è¶…å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `num_epochs` | 200 | æœ€å¤§è®­ç»ƒè½®æ•° |
| `learning_rate` | 0.01 | å­¦ä¹ ç‡ |
| `batch_size` | 32 | æ‰¹æ¬¡å¤§å° |
| `num_layers` | 3 | ç¥ç»ç½‘ç»œå±‚æ•° |
| `hidden_size` | 128 | éšè—å±‚ç¥ç»å…ƒæ•°é‡ |
| `dropout_prob` | 0.1 | Dropoutæ¦‚ç‡ |
| `patience` | 3 | æ—©åœè€å¿ƒå‚æ•° |
| `use_early_stopping` | True | æ˜¯å¦ä½¿ç”¨æ—©åœ |
| `f1_average` | 'macro' | F1åˆ†æ•°è®¡ç®—æ–¹å¼ï¼ˆä»…å¤šåˆ†ç±»ï¼‰ |

## è¯„ä¼°æŒ‡æ ‡

### äºŒåˆ†ç±»

- **å‡†ç¡®ç‡ (Accuracy)**: æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬æ¯”ä¾‹
- **F1åˆ†æ•°**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°

### å¤šåˆ†ç±»

- **å‡†ç¡®ç‡ (Accuracy)**: æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬æ¯”ä¾‹
- **F1åˆ†æ•° (macro)**: æ¯ä¸ªç±»åˆ«F1åˆ†æ•°çš„ç®—æœ¯å¹³å‡
- **F1åˆ†æ•° (micro)**: å…¨å±€è®¡ç®—çš„F1åˆ†æ•°
- **F1åˆ†æ•° (weighted)**: æŒ‰ç±»åˆ«æ”¯æŒæ•°åŠ æƒçš„F1åˆ†æ•°

## æ•°æ®æ ¼å¼

### è¾“å…¥æ•°æ®è¦æ±‚

- **ç‰¹å¾**: æ•°å€¼å‹ç‰¹å¾ï¼Œæ”¯æŒpandas DataFrameæˆ–numpyæ•°ç»„
- **æ ‡ç­¾**: 
  - äºŒåˆ†ç±»: 0å’Œ1
  - å¤šåˆ†ç±»: 0, 1, 2, ..., n-1 (è¿ç»­æ•´æ•°)

### ç¤ºä¾‹æ•°æ®

é¡¹ç›®åŒ…å«ç¤ºä¾‹æ•°æ®ï¼š

- `sample/binary_cls_train.csv` / `sample/binary_cls_val.csv`: äºŒåˆ†ç±»æ•°æ®
- `sample/multi_cls_train.csv` / `sample/multi_cls_val.csv`: å››åˆ†ç±»æ•°æ®

## æ–‡ä»¶ç»“æ„

```
tabaml/
â”œâ”€â”€ main.py              # ä¸»å…¥å£æ–‡ä»¶
â”œâ”€â”€ binary_cls.py        # äºŒåˆ†ç±»æ¨¡å‹å®ç°
â”œâ”€â”€ multi_cls.py         # å¤šåˆ†ç±»æ¨¡å‹å®ç°
â”œâ”€â”€ metrics.py           # è¯„ä¼°æŒ‡æ ‡å®ç°
â”œâ”€â”€ sample/              # ç¤ºä¾‹æ•°æ®
â”‚   â”œâ”€â”€ binary_cls_train.csv
â”‚   â”œâ”€â”€ binary_cls_val.csv
â”‚   â”œâ”€â”€ multi_cls_train.csv
â”‚   â””â”€â”€ multi_cls_val.csv
â””â”€â”€ README.md
```

## æ³¨æ„äº‹é¡¹

1. **GPUæ”¯æŒ**: ä»£ç è‡ªåŠ¨æ£€æµ‹CUDAå¯ç”¨æ€§ï¼Œä¼˜å…ˆä½¿ç”¨GPUè®­ç»ƒ
2. **æ•°æ®é¢„å¤„ç†**: ç¡®ä¿æ•°æ®å·²ç»å®Œæˆæ ‡å‡†åŒ–ã€ç¼ºå¤±å€¼å¤„ç†ç­‰é¢„å¤„ç†æ­¥éª¤
3. **å†…å­˜ä½¿ç”¨**: å¤§æ•°æ®é›†å»ºè®®è°ƒæ•´batch_sizeå‚æ•°
4. **ç±»åˆ«å¹³è¡¡**: ä¸å¹³è¡¡æ•°æ®é›†å¯èƒ½éœ€è¦é¢å¤–çš„å¤„ç†ç­–ç•¥

## è®¸å¯è¯

æœ¬é¡¹ç›®ä½¿ç”¨ MIT è®¸å¯è¯ã€‚
