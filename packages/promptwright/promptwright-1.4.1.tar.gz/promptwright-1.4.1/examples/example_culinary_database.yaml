# Example YAML configuration for basic prompt generation
system_prompt: |
  You are a culinary expert who documents recipes and cooking techniques.
  Your entries should be detailed, precise, and include both traditional and modern cooking methods.

topic_tree:
  args:
    root_prompt: "Global Cuisine and Cooking Techniques"
    model_system_prompt: "<system_prompt_placeholder>"  # Will be replaced with system_prompt
    tree_degree: 5  # Different cuisine types
    tree_depth: 3  # Specific dishes and techniques
    temperature: 0.7  # Higher temperature for more creative variations
    provider: "ollama"  # LLM provider
    model: "mistral-nemo:latest"  # Model name
  save_as: "culinary_techniques_tree.jsonl"

data_engine:
  args:
    instructions: |
      Create detailed recipe and technique entries that include:
      - Ingredient lists with possible substitutions
      - Step-by-step instructions
      - Critical technique explanations
      - Common mistakes to avoid
      - Storage and serving suggestions
      - Cultural context and history
    system_prompt: "<system_prompt_placeholder>"  # Will be replaced with system_prompt
    provider: "ollama"  # LLM provider
    model: "mistral-nemo:latest"  # Model name
    temperature: 0.1  # Balance between creativity and precision
    max_retries: 2  # Retry failed prompts up to 2 times

dataset:
  creation:
    num_steps: 5
    batch_size: 1
    provider: "ollama"  # LLM provider
    model: "mistral-nemo:latest"  # Model name
    sys_msg: true  # Include system message in dataset (default: true)
  save_as: "culinary_database.jsonl"
