# Example YAML configuration for basic prompt generation
system_prompt: "You are a helpful assistant. You provide clear and concise answers to user questions."

topic_tree:
  args:
    root_prompt: "Capital Cities of the World."
    model_system_prompt: "<system_prompt_placeholder>"  # Will be replaced with system_prompt
    tree_degree: 3  # Different continents
    tree_depth: 2  # Deeper tree for more specific topics
    temperature: 0.7  # Higher temperature for more creative variations
    provider: "openai"  # LLM provider
    model: "gpt-4-1106-preview"  # Model name
  save_as: "basic_prompt_topictree.jsonl"

data_engine:
  args:
    instructions: "Please provide training examples with questions about capital cities of the world."
    system_prompt: "<system_prompt_placeholder>"  # Will be replaced with system_prompt
    provider: "openai"  # LLM provider
    model: "gpt-4-1106-preview"  # Model name
    temperature: 0.9  # Higher temperature for more creative variations
    max_retries: 2  # Retry failed prompts up to 2 times

dataset:
  creation:
    num_steps: 5
    batch_size: 1
    provider: "openai"  # LLM provider
    model: "gpt-4-1106-preview"  # Model name
    sys_msg: true  # Include system message in dataset (default: true)
  save_as: "basic_prompt_dataset.jsonl"
