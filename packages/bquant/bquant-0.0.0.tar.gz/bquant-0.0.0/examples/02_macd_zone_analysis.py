#!/usr/bin/env python3
"""
BQuant - –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–æ–Ω MACD

–≠—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ MACDZoneAnalyzer –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–æ–Ω
2. –†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–æ–Ω –∏ –∏—Ö –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é
3. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö –≥–∏–ø–æ—Ç–µ–∑
4. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –∑–æ–Ω –ø–æ —Ñ–æ—Ä–º–µ
5. –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∑–æ–Ω
6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π BQuant –ø–∞–∫–µ—Ç: pip install -e .
- –î–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OHLCV
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: matplotlib –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ BQuant –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from bquant.indicators.macd import (
    MACDZoneAnalyzer, ZoneAnalysisResult, ZoneInfo,
    create_macd_analyzer, analyze_macd_zones
)
from bquant.core.config import get_indicator_params, get_analysis_params


def create_trending_data(rows: int = 500, symbol: str = "EURUSD") -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã–º–∏ —Ç—Ä–µ–Ω–¥–æ–≤—ã–º–∏ –¥–≤–∏–∂–µ–Ω–∏—è–º–∏ –¥–ª—è MACD –∞–Ω–∞–ª–∏–∑–∞.
    
    Args:
        rows: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö
        symbol: –°–∏–º–≤–æ–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        
    Returns:
        DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ —Å —á–µ—Ç–∫–∏–º–∏ —Ç—Ä–µ–Ω–¥–∞–º–∏
    """
    print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} ({rows} –±–∞—Ä–æ–≤)...")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
    dates = pd.date_range(start='2024-01-01', periods=rows, freq='1H')
    np.random.seed(123)  # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    base_price = 1.1000  # EUR/USD
    prices = [base_price]
    
    # –°–æ–∑–¥–∞–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã –¥–ª—è —á–µ—Ç–∫–∏—Ö MACD –∑–æ–Ω
    for i in range(1, rows):
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–¥ - —Å–∏–Ω—É—Å–æ–∏–¥–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏
        long_trend = 0.002 * np.sin(i / 80)  # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π —Ç—Ä–µ–Ω–¥
        medium_trend = 0.001 * np.sin(i / 30)  # –°—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω—ã–π —Ç—Ä–µ–Ω–¥
        short_noise = np.random.normal(0, 0.0005)  # –ö–æ—Ä–æ—Ç–∫–∏–π —à—É–º
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–º–µ–Ω—Ç—ã "–ø—Ä–æ–±–æ–µ–≤" –¥–ª—è —á–µ—Ç–∫–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        if i % 120 == 0:
            breakthrough = 0.003 * (1 if np.random.random() > 0.5 else -1)
        else:
            breakthrough = 0
        
        total_change = long_trend + medium_trend + short_noise + breakthrough
        new_price = prices[-1] * (1 + total_change)
        prices.append(max(new_price, 0.5))  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
    
    # –°–æ–∑–¥–∞–µ–º OHLCV —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    data = []
    for i, close_price in enumerate(prices):
        if i == 0:
            open_price = close_price
        else:
            open_price = prices[i-1]
        
        # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ high/low
        high = max(open_price, close_price) * (1 + abs(np.random.normal(0, 0.0003)))
        low = min(open_price, close_price) * (1 - abs(np.random.normal(0, 0.0003)))
        volume = np.random.randint(100000, 500000)
        
        data.append({
            'open': open_price,
            'high': high,
            'low': low,
            'close': close_price,
            'volume': volume
        })
    
    df = pd.DataFrame(data, index=dates)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} –±–∞—Ä–æ–≤ —Å —Ç—Ä–µ–Ω–¥–æ–≤—ã–º–∏ –¥–≤–∏–∂–µ–Ω–∏—è–º–∏")
    print(f"   –ü–µ—Ä–∏–æ–¥: {df.index[0]} - {df.index[-1]}")
    print(f"   –¶–µ–Ω–æ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {df['close'].min():.4f} - {df['close'].max():.4f}")
    print(f"   –û–±—â–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100:.2f}%")
    
    return df


def demonstrate_macd_zone_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–æ–Ω MACD."""
    
    print("üöÄ BQuant - –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–æ–Ω MACD")
    print("=" * 70)
    
    # 1. –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã–º–∏ —Ç—Ä–µ–Ω–¥–∞–º–∏
    data = create_trending_data(400, "EURUSD")
    
    # 2. –°–æ–∑–¥–∞–µ–º MACD –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    print(f"\n‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MACD –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞:")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    macd_params = get_indicator_params('macd')
    zone_params = get_analysis_params('zone_analysis')
    
    print(f"   üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã MACD: {macd_params}")
    print(f"   üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–æ–Ω: {zone_params}")
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = MACDZoneAnalyzer(macd_params, zone_params)
    print(f"   ‚úÖ MACDZoneAnalyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    # 3. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    print(f"\nüî¨ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–æ–Ω:")
    
    try:
        result = analyzer.analyze_complete(
            data, 
            perform_clustering=True, 
            n_clusters=3
        )
        
        print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        print(f"   üìä –ù–∞–π–¥–µ–Ω–æ –∑–æ–Ω: {len(result.zones)}")
        print(f"   üß™ –ü—Ä–æ–≤–µ–¥–µ–Ω–æ –≥–∏–ø–æ—Ç–µ–∑: {len(result.hypothesis_tests)}")
        print(f"   üéØ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {'–î–∞' if result.clustering else '–ù–µ—Ç'}")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None
    
    # 4. –ê–Ω–∞–ª–∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–æ–Ω
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∑–æ–Ω:")
    
    if not result.zones:
        print("   ‚ö†Ô∏è –ó–æ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return result
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∑–æ–Ω
    bull_zones = [z for z in result.zones if z.type == 'bull']
    bear_zones = [z for z in result.zones if z.type == 'bear']
    
    print(f"   üêÇ –ë—ã—á—å–∏—Ö –∑–æ–Ω: {len(bull_zones)}")
    print(f"   üêª –ú–µ–¥–≤–µ–∂—å–∏—Ö –∑–æ–Ω: {len(bear_zones)}")
    print(f"   ‚öñÔ∏è –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ bull/bear: {len(bull_zones)}/{len(bear_zones)}")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–æ–Ω
    durations = [zone.duration for zone in result.zones]
    if durations:
        print(f"   üìè –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–æ–Ω:")
        print(f"      –°—Ä–µ–¥–Ω—è—è: {np.mean(durations):.1f} –±–∞—Ä–æ–≤")
        print(f"      –ú–µ–¥–∏–∞–Ω–∞: {np.median(durations):.1f} –±–∞—Ä–æ–≤")
        print(f"      –ú–∏–Ω/–ú–∞–∫—Å: {min(durations)}/{max(durations)} –±–∞—Ä–æ–≤")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö 3 –∑–æ–Ω
    print(f"\nüîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö –∑–æ–Ω:")
    
    for i, zone in enumerate(result.zones[:3]):
        print(f"\n   üè∑Ô∏è –ó–æ–Ω–∞ #{zone.zone_id} ({zone.type.upper()}):")
        print(f"      ‚è±Ô∏è –ü–µ—Ä–∏–æ–¥: {zone.start_time} - {zone.end_time}")
        print(f"      üìè –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {zone.duration} –±–∞—Ä–æ–≤")
        
        if zone.features:
            features = zone.features
            print(f"      üí∞ –¶–µ–Ω–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {features['price_return']:.4f} ({features['price_return']*100:.2f}%)")
            print(f"      üìà MACD –∞–º–ø–ª–∏—Ç—É–¥–∞: {features['macd_amplitude']:.6f}")
            print(f"      üìä –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –∞–º–ø–ª–∏—Ç—É–¥–∞: {features['hist_amplitude']:.6f}")
            
            if 'price_hist_corr' in features:
                corr_str = f"{features['price_hist_corr']:.3f}"
                print(f"      üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ü–µ–Ω–∞-–≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞: {corr_str}")
            
            # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ç–∏–ø–∞ –∑–æ–Ω—ã
            if zone.type == 'bull' and 'drawdown_from_peak' in features:
                dd = features['drawdown_from_peak']
                print(f"      üìâ –ü—Ä–æ—Å–∞–¥–∫–∞ –æ—Ç –ø–∏–∫–∞: {dd:.4f} ({dd*100:.2f}%)")
            elif zone.type == 'bear' and 'rally_from_trough' in features:
                rally = features['rally_from_trough']
                print(f"      üìà –û—Ç—Å–∫–æ–∫ –æ—Ç –¥–Ω–∞: {rally:.4f} ({rally*100:.2f}%)")
    
    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –≥–∏–ø–æ—Ç–µ–∑
    print(f"\nüß™ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤:")
    
    if result.hypothesis_tests:
        for test_name, test_result in result.hypothesis_tests.items():
            significance = "‚úÖ –ó–Ω–∞—á–∏–º" if test_result['significant'] else "‚ùå –ù–µ –∑–Ω–∞—á–∏–º"
            p_val = test_result.get('p_value', 'N/A')
            
            print(f"\n   üìã {test_name}:")
            print(f"      üìÑ –û–ø–∏—Å–∞–Ω–∏–µ: {test_result['description']}")
            print(f"      üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {significance}")
            if p_val != 'N/A':
                print(f"      üéØ P-value: {p_val:.4f}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
            if 'long_zones_avg_return' in test_result:
                print(f"      üìà –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –¥–ª–∏–Ω–Ω—ã—Ö –∑–æ–Ω: {test_result['long_zones_avg_return']:.4f}")
                print(f"      üìâ –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–æ–Ω: {test_result['short_zones_avg_return']:.4f}")
            
            if 'correlation' in test_result:
                print(f"      üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {test_result['correlation']:.4f}")
    else:
        print("   ‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–≤–µ–¥–µ–Ω—ã (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)")
    
    # 6. –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∑–æ–Ω
    print(f"\nüîÑ –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∑–æ–Ω:")
    
    if result.sequence_analysis and result.sequence_analysis['total_transitions'] > 0:
        seq_analysis = result.sequence_analysis
        print(f"   üìä –í—Å–µ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤: {seq_analysis['total_transitions']}")
        
        for transition, probability in seq_analysis['transition_probabilities'].items():
            count = seq_analysis['transitions'][transition]
            print(f"   üìà {transition}: {count} —Ä–∞–∑ ({probability:.1%})")
    else:
        print("   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–æ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    
    # 7. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∑–æ–Ω:")
    
    if result.clustering:
        clustering = result.clustering
        n_clusters = clustering['n_clusters']
        features_used = clustering['features_used']
        
        print(f"   üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {n_clusters}")
        print(f"   üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {', '.join(features_used)}")
        
        for cluster_name, cluster_info in clustering['cluster_analysis'].items():
            print(f"\n   üè∑Ô∏è {cluster_name.upper()}:")
            print(f"      üìä –†–∞–∑–º–µ—Ä: {cluster_info['size']} –∑–æ–Ω")
            print(f"      ‚è±Ô∏è –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {cluster_info['avg_duration']:.1f} –±–∞—Ä–æ–≤")
            print(f"      üí∞ –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {cluster_info['avg_price_return']:.4f}")
            print(f"      üêÇ –î–æ–ª—è –±—ã—á—å–∏—Ö –∑–æ–Ω: {cluster_info['bull_ratio']:.1%}")
    else:
        print("   ‚ö†Ô∏è –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
    
    # 8. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:")
    
    if result.statistics:
        stats = result.statistics
        print(f"   üìà –í—Å–µ–≥–æ –∑–æ–Ω: {stats['total_zones']}")
        print(f"   üêÇ –ë—ã—á—å–∏—Ö –∑–æ–Ω: {stats['bull_zones']}")
        print(f"   üêª –ú–µ–¥–≤–µ–∂—å–∏—Ö –∑–æ–Ω: {stats['bear_zones']}")
        print(f"   ‚öñÔ∏è –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –±—ã–∫–æ–≤: {stats['bull_ratio']:.1%}")
        
        if 'bull_duration_mean' in stats:
            print(f"   ‚è±Ô∏è –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±—ã—á—å–∏—Ö –∑–æ–Ω: {stats['bull_duration_mean']:.1f} –±–∞—Ä–æ–≤")
        if 'bear_duration_mean' in stats:
            print(f"   ‚è±Ô∏è –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–µ–¥–≤–µ–∂—å–∏—Ö –∑–æ–Ω: {stats['bear_duration_mean']:.1f} –±–∞—Ä–æ–≤")
        
        if 'bull_price_return_mean' in stats:
            bull_ret = stats['bull_price_return_mean']
            print(f"   üí∞ –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –±—ã—á—å–∏—Ö –∑–æ–Ω: {bull_ret:.4f} ({bull_ret*100:.2f}%)")
        if 'bear_price_return_mean' in stats:
            bear_ret = stats['bear_price_return_mean']
            print(f"   üí∞ –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –º–µ–¥–≤–µ–∂—å–∏—Ö –∑–æ–Ω: {bear_ret:.4f} ({bear_ret*100:.2f}%)")
    
    # 9. –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞
    print(f"\nüìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞:")
    
    if result.metadata:
        meta = result.metadata
        print(f"   üïê –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {meta.get('analysis_timestamp', 'N/A')}")
        print(f"   üìä –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {meta.get('data_period', {}).get('start', 'N/A')} - {meta.get('data_period', {}).get('end', 'N/A')}")
        print(f"   üìà –í—Å–µ–≥–æ –±–∞—Ä–æ–≤: {meta.get('data_period', {}).get('total_bars', 'N/A')}")
        print(f"   ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã MACD: {meta.get('macd_params', 'N/A')}")
        print(f"   üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–æ–Ω: {meta.get('zone_params', 'N/A')}")
    
    return result


def demonstrate_convenience_functions():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —É–¥–æ–±–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."""
    
    print(f"\nüõ†Ô∏è –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è convenience —Ñ—É–Ω–∫—Ü–∏–π:")
    print("-" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    data = create_trending_data(300, "GBPUSD")
    
    # 1. –ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    print(f"\n1Ô∏è‚É£ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ create_macd_analyzer():")
    
    analyzer = create_macd_analyzer(
        macd_params={'fast': 10, 'slow': 21, 'signal': 7},
        zone_params={'min_duration': 3}
    )
    print(f"   ‚úÖ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–æ–∑–¥–∞–Ω —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
    
    # 2. One-shot –∞–Ω–∞–ª–∏–∑
    print(f"\n2Ô∏è‚É£ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ analyze_macd_zones():")
    
    try:
        result = analyze_macd_zones(
            data,
            macd_params={'fast': 8, 'slow': 17, 'signal': 5},
            perform_clustering=False  # –û—Ç–∫–ª—é—á–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        )
        
        print(f"   ‚úÖ One-shot –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
        print(f"   üìä –ù–∞–π–¥–µ–Ω–æ –∑–æ–Ω: {len(result.zones)}")
        print(f"   üß™ –ü—Ä–æ–≤–µ–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {len(result.hypothesis_tests)}")
        
        # –ö—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
        if result.zones:
            bull_count = sum(1 for z in result.zones if z.type == 'bull')
            bear_count = len(result.zones) - bull_count
            print(f"   üêÇ –ë—ã—á—å–∏—Ö –∑–æ–Ω: {bull_count}")
            print(f"   üêª –ú–µ–¥–≤–µ–∂—å–∏—Ö –∑–æ–Ω: {bear_count}")
            
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ one-shot –∞–Ω–∞–ª–∏–∑–∞: {e}")


def save_analysis_results(result: ZoneAnalysisResult, filename_prefix: str = "macd_analysis"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–∞–π–ª—ã."""
    
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞:")
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∑–æ–Ω
        if result.zones:
            zones_data = []
            for zone in result.zones:
                zone_record = {
                    'zone_id': zone.zone_id,
                    'type': zone.type,
                    'start_time': zone.start_time,
                    'end_time': zone.end_time,
                    'duration': zone.duration,
                    'start_idx': zone.start_idx,
                    'end_idx': zone.end_idx
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                if zone.features:
                    zone_record.update(zone.features)
                
                zones_data.append(zone_record)
            
            zones_df = pd.DataFrame(zones_data)
            zones_file = f"examples/{filename_prefix}_zones.csv"
            zones_df.to_csv(zones_file, index=False)
            print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –∑–æ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {zones_file}")
            print(f"      üìä –ó–æ–Ω: {len(zones_df)}, –∫–æ–ª–æ–Ω–æ–∫: {len(zones_df.columns)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if result.statistics:
            stats_file = f"examples/{filename_prefix}_statistics.csv"
            stats_df = pd.DataFrame([result.statistics])
            stats_df.to_csv(stats_file, index=False)
            print(f"   ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {stats_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–∏–ø–æ—Ç–µ–∑
        if result.hypothesis_tests:
            tests_file = f"examples/{filename_prefix}_hypothesis_tests.csv"
            tests_df = pd.DataFrame(result.hypothesis_tests).T
            tests_df.to_csv(tests_file)
            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {tests_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        if result.clustering:
            clustering_file = f"examples/{filename_prefix}_clustering.csv"
            clustering_df = pd.DataFrame(result.clustering['cluster_analysis']).T
            clustering_df.to_csv(clustering_file)
            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {clustering_file}")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


if __name__ == "__main__":
    try:
        # –û—Å–Ω–æ–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è
        main_result = demonstrate_macd_zone_analysis()
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è convenience —Ñ—É–Ω–∫—Ü–∏–π
        demonstrate_convenience_functions()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if main_result:
            save_analysis_results(main_result, "comprehensive_macd")
        
        print(f"\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è MACD –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"\nüí° –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
        print(f"   ‚úì –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–æ–Ω MACD")
        print(f"   ‚úì –†–∞—Å—á–µ—Ç 20+ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–æ–Ω—ã")
        print(f"   ‚úì –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö –≥–∏–ø–æ—Ç–µ–∑")
        print(f"   ‚úì –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–æ–Ω –ø–æ —Ñ–æ—Ä–º–µ")
        print(f"   ‚úì –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∑–æ–Ω")
        print(f"   ‚úì –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
