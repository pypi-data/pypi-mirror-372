"""
–†–µ–µ—Å—Ç—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ BQuant

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö sample –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–∏–º–∏.
"""

from typing import Dict, List, Any
from ...core.logging_config import get_logger

logger = get_logger(__name__)

# –†–µ–µ—Å—Ç—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
AVAILABLE_DATASETS = {
    'tv_xauusd_1h': {
        'name': 'TradingView XAUUSD 1H',
        'description': '–ß–∞—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ XAUUSD —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏',
        'source': 'TradingView via OANDA',
        'symbol': 'XAUUSD',
        'timeframe': '1H',
        'rows': 1000,
        'columns': [
            'time', 'open', 'high', 'low', 'close', 'volume',
            'accumulation_distribution', 'macd', 'signal', 'rsi',
            'rsi_based_ma', 'regular_bullish', 'regular_bullish_label',
            'regular_bearish', 'regular_bearish_label'
        ],
        'period_start': '2025-06-11T20:00:00+07:00',
        'period_end': '2025-08-12T13:00:00+07:00',
        'license': 'Open data, free for research and educational use',
        'disclaimer': 'For demonstration purposes only. Not for production trading.',
        'file_module': 'embedded.tv_xauusd_1h',
        'size_bytes': 555425,
        'updated': '2025-08-25 18:38:50',
        'original_filename': 'OANDA_XAUUSD, 60.csv'
    },
    'mt_xauusd_m15': {
        'name': 'MetaTrader XAUUSD 15M',
        'description': '15-–º–∏–Ω—É—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ XAUUSD —Å –±–∞–∑–æ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏',
        'source': 'MetaTrader',
        'symbol': 'XAUUSD',
        'timeframe': '15M',
        'rows': 1000,
        'columns': [
            'time', 'open', 'high', 'low', 'close', 'volume', 'spread'
        ],
        'period_start': '2025-05-20T02:00:00',
        'period_end': '2025-05-30T07:30:00',
        'license': 'Open data, free for research and educational use',
        'disclaimer': 'For demonstration purposes only. Not for production trading.',
        'file_module': 'embedded.mt_xauusd_m15',
        'size_bytes': 207315,
        'updated': '2025-08-25 18:38:51',
        'original_filename': 'XAUUSDM15.csv'
    }
}


def get_dataset_registry() -> Dict[str, Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    """
    return AVAILABLE_DATASETS.copy()


def get_dataset_info(dataset_name: str) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Raises:
        KeyError: –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    if dataset_name not in AVAILABLE_DATASETS:
        available = list(AVAILABLE_DATASETS.keys())
        raise KeyError(f"Dataset '{dataset_name}' not found. Available datasets: {available}")
    
    return AVAILABLE_DATASETS[dataset_name].copy()


def list_dataset_names() -> List[str]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    """
    return list(AVAILABLE_DATASETS.keys())


def get_datasets_summary() -> List[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –ø–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º.
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–∞–∂–¥–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
    """
    summary = []
    
    for dataset_name, info in AVAILABLE_DATASETS.items():
        summary.append({
            'name': dataset_name,
            'title': info['name'],
            'description': info['description'],
            'symbol': info['symbol'],
            'timeframe': info['timeframe'],
            'rows': info['rows'],
            'columns_count': len(info['columns']),
            'size_kb': round(info['size_bytes'] / 1024, 1),
            'source': info['source'],
            'updated': info['updated']
        })
    
    return summary


def validate_dataset_name(dataset_name: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    
    Returns:
        True –µ—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    """
    return dataset_name in AVAILABLE_DATASETS


def get_dataset_file_module(dataset_name: str) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏–º—è –º–æ–¥—É–ª—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞.
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        –ò–º—è –º–æ–¥—É–ª—è –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
    
    Raises:
        KeyError: –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    if not validate_dataset_name(dataset_name):
        raise KeyError(f"Dataset '{dataset_name}' not found")
    
    return AVAILABLE_DATASETS[dataset_name]['file_module']


def get_datasets_by_symbol(symbol: str) -> List[str]:
    """
    –ù–∞–π—Ç–∏ –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.
    
    Args:
        symbol: –°–∏–º–≤–æ–ª —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'XAUUSD')
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    """
    matching_datasets = []
    
    for dataset_name, info in AVAILABLE_DATASETS.items():
        if info['symbol'].upper() == symbol.upper():
            matching_datasets.append(dataset_name)
    
    return matching_datasets


def get_datasets_by_timeframe(timeframe: str) -> List[str]:
    """
    –ù–∞–π—Ç–∏ –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞.
    
    Args:
        timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, '1H', '15M')
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
    """
    matching_datasets = []
    
    for dataset_name, info in AVAILABLE_DATASETS.items():
        if info['timeframe'].upper() == timeframe.upper():
            matching_datasets.append(dataset_name)
    
    return matching_datasets


def get_datasets_by_source(source: str) -> List[str]:
    """
    –ù–∞–π—Ç–∏ –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –æ—Ç —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.
    
    Args:
        source: –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'TradingView', 'MetaTrader')
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –æ—Ç –¥–∞–Ω–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    """
    matching_datasets = []
    
    for dataset_name, info in AVAILABLE_DATASETS.items():
        if source.lower() in info['source'].lower():
            matching_datasets.append(dataset_name)
    
    return matching_datasets


def print_datasets_info():
    """–í—ã–≤–µ—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö."""
    print("BQuant Sample Datasets")
    print("=" * 50)
    
    for dataset_name, info in AVAILABLE_DATASETS.items():
        print(f"\nüìä {info['name']} ({dataset_name})")
        print(f"   Source: {info['source']}")
        print(f"   Symbol: {info['symbol']} | Timeframe: {info['timeframe']}")
        print(f"   Rows: {info['rows']} | Columns: {len(info['columns'])}")
        print(f"   Size: {round(info['size_bytes'] / 1024, 1)} KB")
        print(f"   Period: {info['period_start']} ‚Üí {info['period_end']}")
        print(f"   Updated: {info['updated']}")
    
    print(f"\nTotal datasets: {len(AVAILABLE_DATASETS)}")
    total_size_kb = sum(info['size_bytes'] for info in AVAILABLE_DATASETS.values()) / 1024
    print(f"Total size: {round(total_size_kb, 1)} KB")


# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
__all__ = [
    'AVAILABLE_DATASETS',
    'get_dataset_registry',
    'get_dataset_info',
    'list_dataset_names',
    'get_datasets_summary',
    'validate_dataset_name',
    'get_dataset_file_module',
    'get_datasets_by_symbol',
    'get_datasets_by_timeframe',
    'get_datasets_by_source',
    'print_datasets_info'
]
