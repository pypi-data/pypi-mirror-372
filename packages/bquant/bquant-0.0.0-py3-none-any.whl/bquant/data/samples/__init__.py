"""
BQuant Sample Data API

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç unified API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
–í–∫–ª—é—á–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ä–∞–±–æ—Ç—ã —Å sample –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏.

–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- get_sample_data(): –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
- list_datasets(): –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- get_dataset_info(): –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
- validate_dataset(): –í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞

–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    >>> from bquant.data.samples import get_sample_data, list_datasets
    >>> 
    >>> # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ pandas DataFrame
    >>> df = get_sample_data('tv_xauusd_1h')
    >>> print(df.shape)  # (1000, 14)
    >>> 
    >>> # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
    >>> data = get_sample_data('mt_xauusd_m15', format='dict')
    >>> print(len(data))  # 1000
    >>> 
    >>> # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    >>> datasets = list_datasets()
    >>> for dataset in datasets:
    ...     print(f"{dataset['name']}: {dataset['rows']} rows")
"""

import pandas as pd
from typing import Dict, List, Any, Optional, Union, Literal

from ...core.logging_config import get_logger
from .datasets import (
    get_dataset_registry,
    get_dataset_info as _get_dataset_info,
    list_dataset_names,
    get_datasets_summary,
    validate_dataset_name,
    get_datasets_by_symbol,
    get_datasets_by_timeframe,
    get_datasets_by_source,
    print_datasets_info
)
from .utils import (
    load_embedded_data,
    convert_to_dataframe,
    convert_to_list_of_dicts,
    validate_data_integrity,
    get_data_sample,
    get_data_info,
    compare_datasets
)

logger = get_logger(__name__)

# Type hints –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö
DataFormat = Literal['pandas', 'dataframe', 'dict', 'list']


def get_sample_data(
    dataset_name: str, 
    format: DataFormat = 'pandas'
) -> Union[pd.DataFrame, List[Dict[str, Any]]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å sample –¥–∞–Ω–Ω—ã–µ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ ('tv_xauusd_1h' –∏–ª–∏ 'mt_xauusd_m15')
        format: –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö ('pandas'/'dataframe' –∏–ª–∏ 'dict'/'list')
    
    Returns:
        –î–∞–Ω–Ω—ã–µ –≤ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:
        - 'pandas'/'dataframe': pandas.DataFrame
        - 'dict'/'list': List[Dict[str, Any]]
    
    Raises:
        KeyError: –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
        ValueError: –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        ImportError: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    
    Examples:
        >>> # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–∫ DataFrame (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        >>> df = get_sample_data('tv_xauusd_1h')
        >>> print(df.shape)  # (1000, 14)
        >>> 
        >>> # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        >>> data = get_sample_data('mt_xauusd_m15', format='dict')
        >>> print(len(data))  # 1000
    """
    logger.debug(f"Loading sample data: {dataset_name}, format: {format}")
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if not validate_dataset_name(dataset_name):
        available = list_dataset_names()
        raise KeyError(f"Dataset '{dataset_name}' not found. Available datasets: {available}")
    
    supported_formats = ['pandas', 'dataframe', 'dict', 'list']
    if format not in supported_formats:
        raise ValueError(f"Unsupported format '{format}'. Supported: {supported_formats}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º embedded –¥–∞–Ω–Ω—ã–µ
        embedded_data = load_embedded_data(dataset_name)
        raw_data = embedded_data['DATA']
        
        logger.debug(f"Loaded {len(raw_data)} records for {dataset_name}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        if format in ['pandas', 'dataframe']:
            result = convert_to_dataframe(raw_data, dataset_name)
            logger.debug(f"Converted to DataFrame with shape {result.shape}")
            return result
            
        elif format in ['dict', 'list']:
            logger.debug(f"Returning {len(raw_data)} records as list of dicts")
            return raw_data
        
    except Exception as e:
        logger.error(f"Failed to load sample data for {dataset_name}: {e}")
        raise


def list_datasets() -> List[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö sample –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å –∏—Ö –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π.
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–∞–∂–¥–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
    
    Examples:
        >>> datasets = list_datasets()
        >>> for dataset in datasets:
        ...     print(f"{dataset['title']}: {dataset['rows']} rows, {dataset['size_kb']} KB")
    """
    logger.debug("Listing all available datasets")
    
    try:
        datasets_summary = get_datasets_summary()
        logger.debug(f"Found {len(datasets_summary)} available datasets")
        return datasets_summary
        
    except Exception as e:
        logger.error(f"Failed to list datasets: {e}")
        return []


def get_dataset_info(dataset_name: str) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
    
    Raises:
        KeyError: –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
    
    Examples:
        >>> info = get_dataset_info('tv_xauusd_1h')
        >>> print(info['name'])  # 'TradingView XAUUSD 1H'
        >>> print(info['symbol'])  # 'XAUUSD'
        >>> print(info['columns'])  # ['time', 'open', 'high', ...]
    """
    logger.debug(f"Getting info for dataset: {dataset_name}")
    
    try:
        info = _get_dataset_info(dataset_name)
        logger.debug(f"Retrieved info for {dataset_name}")
        return info
        
    except KeyError as e:
        logger.error(f"Dataset not found: {dataset_name}")
        raise


def validate_dataset(dataset_name: str) -> Dict[str, Any]:
    """
    –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞.
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:
        - is_valid: bool - –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        - errors: List[str] - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
        - warnings: List[str] - –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        - stats: Dict - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º
    
    Examples:
        >>> result = validate_dataset('tv_xauusd_1h')
        >>> if result['is_valid']:
        ...     print("Dataset is valid!")
        ... else:
        ...     print("Errors:", result['errors'])
    """
    logger.debug(f"Validating dataset: {dataset_name}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        embedded_data = load_embedded_data(dataset_name)
        dataset_info = get_dataset_info(dataset_name)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º
        validation_result = validate_data_integrity(embedded_data['DATA'], dataset_info)
        
        logger.debug(f"Validation completed for {dataset_name}: {'PASSED' if validation_result['is_valid'] else 'FAILED'}")
        return validation_result
        
    except Exception as e:
        logger.error(f"Validation failed for {dataset_name}: {e}")
        return {
            'is_valid': False,
            'errors': [f"Validation exception: {e}"],
            'warnings': [],
            'stats': {}
        }


def get_sample_preview(dataset_name: str, n: int = 5) -> List[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ n –∑–∞–ø–∏—Å–µ–π).
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
        n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)
    
    Returns:
        –°–ø–∏—Å–æ–∫ –ø–µ—Ä–≤—ã—Ö n –∑–∞–ø–∏—Å–µ–π
    
    Examples:
        >>> preview = get_sample_preview('tv_xauusd_1h', 3)
        >>> for record in preview:
        ...     print(f"Time: {record['time']}, Close: {record['close']}")
    """
    logger.debug(f"Getting preview for {dataset_name}, n={n}")
    
    try:
        embedded_data = load_embedded_data(dataset_name)
        sample = get_data_sample(embedded_data['DATA'], n)
        
        logger.debug(f"Retrieved {len(sample)} records for preview")
        return sample
        
    except Exception as e:
        logger.error(f"Failed to get preview for {dataset_name}: {e}")
        return []


def get_data_statistics(dataset_name: str) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞.
    
    Args:
        dataset_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –ø–æ –¥–∞–Ω–Ω—ã–º
    
    Examples:
        >>> stats = get_data_statistics('tv_xauusd_1h')
        >>> print(f"Total records: {stats['total_records']}")
        >>> print(f"Columns: {stats['total_columns']}")
    """
    logger.debug(f"Getting statistics for dataset: {dataset_name}")
    
    try:
        embedded_data = load_embedded_data(dataset_name)
        stats = get_data_info(embedded_data['DATA'], dataset_name)
        
        logger.debug(f"Retrieved statistics for {dataset_name}")
        return stats
        
    except Exception as e:
        logger.error(f"Failed to get statistics for {dataset_name}: {e}")
        return {'error': str(e)}


def find_datasets(
    symbol: Optional[str] = None,
    timeframe: Optional[str] = None,
    source: Optional[str] = None
) -> List[str]:
    """
    –ù–∞–π—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç—ã –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.
    
    Args:
        symbol: –°–∏–º–≤–æ–ª —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'XAUUSD')
        timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, '1H', '15M')
        source: –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'TradingView', 'MetaTrader')
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    
    Examples:
        >>> # –ù–∞–π—Ç–∏ –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è XAUUSD
        >>> xauusd_datasets = find_datasets(symbol='XAUUSD')
        >>> 
        >>> # –ù–∞–π—Ç–∏ –≤—Å–µ —á–∞—Å–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
        >>> hourly_datasets = find_datasets(timeframe='1H')
        >>> 
        >>> # –ù–∞–π—Ç–∏ –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –æ—Ç TradingView
        >>> tv_datasets = find_datasets(source='TradingView')
    """
    logger.debug(f"Finding datasets: symbol={symbol}, timeframe={timeframe}, source={source}")
    
    results = set(list_dataset_names())  # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    
    try:
        if symbol:
            symbol_datasets = set(get_datasets_by_symbol(symbol))
            results = results.intersection(symbol_datasets)
        
        if timeframe:
            timeframe_datasets = set(get_datasets_by_timeframe(timeframe))
            results = results.intersection(timeframe_datasets)
        
        if source:
            source_datasets = set(get_datasets_by_source(source))
            results = results.intersection(source_datasets)
        
        result_list = list(results)
        logger.debug(f"Found {len(result_list)} datasets matching criteria")
        return result_list
        
    except Exception as e:
        logger.error(f"Failed to find datasets: {e}")
        return []


def compare_sample_datasets(dataset1: str, dataset2: str) -> Dict[str, Any]:
    """
    –°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ sample –¥–∞—Ç–∞—Å–µ—Ç–∞.
    
    Args:
        dataset1: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset2: –ù–∞–∑–≤–∞–Ω–∏–µ –≤—Ç–æ—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    
    Examples:
        >>> comparison = compare_sample_datasets('tv_xauusd_1h', 'mt_xauusd_m15')
        >>> print(f"Common columns: {comparison['common_columns']}")
    """
    logger.debug(f"Comparing datasets: {dataset1} vs {dataset2}")
    
    try:
        comparison = compare_datasets(dataset1, dataset2)
        logger.debug(f"Successfully compared {dataset1} and {dataset2}")
        return comparison
        
    except Exception as e:
        logger.error(f"Failed to compare datasets: {e}")
        return {'error': str(e)}


def print_sample_data_status():
    """
    –í—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö sample –¥–∞–Ω–Ω—ã—Ö.
    
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö,
    –∏—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö, —Å—Ç–∞—Ç—É—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç.–¥.
    """
    print("üéØ BQuant Sample Data Status")
    print("=" * 50)
    
    try:
        datasets = list_datasets()
        
        if not datasets:
            print("‚ùå No datasets available")
            return
        
        total_size = 0
        valid_count = 0
        
        for dataset in datasets:
            dataset_name = dataset['name']
            
            print(f"\nüìä {dataset['title']} ({dataset_name})")
            print(f"   Source: {dataset['source']}")
            print(f"   Symbol: {dataset['symbol']} | Timeframe: {dataset['timeframe']}")
            print(f"   Rows: {dataset['rows']:,} | Columns: {dataset['columns_count']}")
            print(f"   Size: {dataset['size_kb']} KB")
            print(f"   Updated: {dataset['updated']}")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            try:
                validation = validate_dataset(dataset_name)
                if validation['is_valid']:
                    print("   Status: ‚úÖ Valid")
                    valid_count += 1
                else:
                    print("   Status: ‚ùå Invalid")
                    if validation['errors']:
                        print(f"   Errors: {', '.join(validation['errors'])}")
            except Exception:
                print("   Status: ‚ùì Could not validate")
            
            total_size += dataset['size_kb']
        
        print(f"\nüìà Summary:")
        print(f"   Total datasets: {len(datasets)}")
        print(f"   Valid datasets: {valid_count}/{len(datasets)}")
        print(f"   Total size: {total_size:.1f} KB")
        
        if valid_count == len(datasets):
            print("   üéâ All datasets are valid and ready to use!")
        
    except Exception as e:
        print(f"‚ùå Failed to get status: {e}")


# –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
load_sample_data = get_sample_data

# –û—Å–Ω–æ–≤–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç—ã
__all__ = [
    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
    'get_sample_data',
    'load_sample_data',  # –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    'list_datasets', 
    'get_dataset_info',
    'validate_dataset',
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
    'get_sample_preview',
    'get_data_statistics',
    'find_datasets',
    'compare_sample_datasets',
    'print_sample_data_status',
    
    # –†–µ—ç–∫—Å–ø–æ—Ä—Ç –∏–∑ –ø–æ–¥–º–æ–¥—É–ª–µ–π
    'get_datasets_by_symbol',
    'get_datasets_by_timeframe', 
    'get_datasets_by_source',
    'print_datasets_info'
]
