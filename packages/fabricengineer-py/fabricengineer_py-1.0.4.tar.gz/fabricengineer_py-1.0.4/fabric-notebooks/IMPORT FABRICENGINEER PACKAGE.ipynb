{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538390c8-a1be-4791-9b7d-636ab6321edd",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Import FabricEngineer Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8fe87-b274-46b4-849a-dc0e39ac169a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83378889-ad73-47a1-b336-573ceb548c89",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34270e2-5f23-4a96-8570-f3c8230e153a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Global IDs\n",
    "GLOBAL_UTILS_WORKSPACE_ID = \"b50e79c4-1140-479c-b5c1-225982ea6783\"\n",
    "\n",
    "# FabricEngineer\n",
    "FABRICENGINEER_PACKAGE_ABFSS = \"abfss://b50e79c4-1140-479c-b5c1-225982ea6783@onelake.dfs.fabric.microsoft.com/c7ab73ce-7e20-45c4-9bbf-004d37143759\"\n",
    "FABRICENGINEER_NOTEBOOK_NAME = \"Export FabricEngineer-Py Modules\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46b1e0-ddab-4b6d-b115-f95fa53e9e31",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5de01e-646a-44f2-8b36-53fbfe5cdb0d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def _get_module_code_from_lakehouse(module: str, version: str) -> str | None:\n",
    "    filepath = f\"{FABRICENGINEER_PACKAGE_ABFSS}/Files/py-packages/fabricengineer/{version}/{module}.py.txt\"\n",
    "    if not notebookutils.fs.exists(filepath):\n",
    "        return None\n",
    "    print(\"Code from lakehouse.\")\n",
    "    code = spark.read.text(filepath, wholetext=True).collect()[0][0]\n",
    "    return code\n",
    "\n",
    "\n",
    "def _get_module_code_from_notebook(module: str, version: str):\n",
    "    print(\"Fetch code from notebook.\")\n",
    "    payload_str = notebookutils.notebook.run(\n",
    "        path=FABRICENGINEER_NOTEBOOK_NAME,\n",
    "        workspace=GLOBAL_UTILS_WORKSPACE_ID,\n",
    "        arguments={\n",
    "            \"IS_DEV\": False,\n",
    "            \"VERSION\": version,\n",
    "            \"MODULES\": module,\n",
    "            \"LAKEHOUSE_CODE_ABFSS\": FABRICENGINEER_PACKAGE_ABFSS,\n",
    "            \"useRootDefaultLakehouse\": True\n",
    "        }\n",
    "    )\n",
    "\n",
    "    payload = json.loads(payload_str)\n",
    "    return payload[\"modules\"][module]\n",
    "\n",
    "\n",
    "def get_module_code(module: str, version: str):\n",
    "    code = _get_module_code_from_lakehouse(module, version)\n",
    "    if code:\n",
    "        return code\n",
    "    return _get_module_code_from_notebook(module, version)\n",
    "\n",
    "\n",
    "log = f\"Passed functions {[get_module_code]}\"\n",
    "print(log)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
