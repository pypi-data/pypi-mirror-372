llm:
  provider: llama.cpp
  model_path: "assistant\\model\\mistral-7b-instruct-v0.2.Q4_K_M.gguf"
  max_tokens: 256
  temperature: 0.2


