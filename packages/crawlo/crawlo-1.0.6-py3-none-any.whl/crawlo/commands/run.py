# crawlo/commands/run.py
import asyncio
import importlib
import sys
from pathlib import Path
import configparser

from crawlo.crawler import CrawlerProcess
from crawlo.utils.project import get_settings
from crawlo.utils.log import get_logger
from crawlo.utils.spider_loader import SpiderLoader

logger = get_logger(__name__)


def main(args):
    """
    è¿è¡ŒæŒ‡å®šçˆ¬è™«çš„ä¸»å‡½æ•°
    ç”¨æ³•: crawlo run <spider_name>
    """
    if len(args) < 1:
        print("Usage: crawlo run <spider_name>")
        print("Example: crawlo run baidu")
        return 1

    spider_name = args[0]

    try:
        # 1. è·å–é¡¹ç›®æ ¹ç›®å½•
        project_root = get_settings()

        # å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))

        # 2. è¯»å–é…ç½®æ–‡ä»¶è·å–é¡¹ç›®åŒ…å
        cfg_file = project_root / 'crawlo.cfg'
        if not cfg_file.exists():
            print(f"âŒ Error: crawlo.cfg not found in {project_root}")
            return 1

        config = configparser.ConfigParser()
        config.read(cfg_file, encoding='utf-8')

        if not config.has_section('settings') or not config.has_option('settings', 'default'):
            print("âŒ Error: Missing [settings] section or 'default' option in crawlo.cfg")
            return 1

        settings_module = config.get('settings', 'default')
        project_package = settings_module.split('.')[0]

        # 3. æŸ¥æ‰¾å¹¶åŠ è½½æŒ‡å®šåç§°çš„ Spider
        spider_class = find_spider_by_name(project_package, spider_name)
        if spider_class is None:
            return 1

        # 4. åˆ›å»º CrawlerProcess å¹¶è¿è¡Œå•ä¸ªçˆ¬è™«
        settings = get_settings()
        process = CrawlerProcess(settings)

        print(f"ğŸš€ Starting spider: {spider_class.name}")
        print(f"ğŸ“ Project: {project_package}")
        print(f"ğŸ•·ï¸  Class: {spider_class.__name__}")
        print("-" * 50)

        # è¿è¡Œå•ä¸ªçˆ¬è™«
        asyncio.run(process.crawl(spider_class))

        print("-" * 50)
        print("âœ… Spider completed successfully!")
        return 0

    except Exception as e:
        print(f"âŒ Error running spider: {e}")
        import traceback
        traceback.print_exc()
        return 1


def find_spider_by_name(project_package: str, target_spider_name: str):
    """ä½¿ç”¨ SpiderLoader æŸ¥æ‰¾çˆ¬è™«"""
    loader = SpiderLoader(project_package)
    spider_class = loader.load(target_spider_name)

    if spider_class is None:
        print(f"âŒ Error: Spider with name '{target_spider_name}' not found")
        print("ğŸ’¡ Available spiders:")
        available_spiders = loader.list()
        for spider_name in available_spiders:
            print(f"   - {spider_name}")
        return None

    return spider_class


def list_available_spiders(project_package: str):
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„çˆ¬è™«
    """
    spiders_dir = Path.cwd() / project_package / 'spiders'
    if not spiders_dir.exists():
        print("   No spiders directory found")
        return

    spider_count = 0
    for py_file in spiders_dir.glob("*.py"):
        if py_file.name.startswith('_'):
            continue

        module_name = py_file.stem
        spider_module_path = f"{project_package}.spiders.{module_name}"

        try:
            module = importlib.import_module(spider_module_path)
        except ImportError:
            continue

        # æŸ¥æ‰¾æ¨¡å—ä¸­æ‰€æœ‰ Spider å­ç±»
        from crawlo.spider import Spider
        for attr_name in dir(module):
            attr_value = getattr(module, attr_name)
            if (isinstance(attr_value, type) and
                    issubclass(attr_value, Spider) and
                    attr_value != Spider and
                    hasattr(attr_value, 'name')):
                print(f"   - {attr_value.name} (class: {attr_value.__name__}, module: {module_name})")
                spider_count += 1

    if spider_count == 0:
        print("   No spiders found")


def run_spider_by_name(spider_name: str, project_root: Path = None):
    """
    ç›´æ¥åœ¨ä»£ç ä¸­é€šè¿‡ spider name è¿è¡Œçˆ¬è™«
    """
    if project_root:
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))

    args = [spider_name]
    return main(args)


if __name__ == '__main__':
    # å…è®¸ç›´æ¥è¿è¡Œ: python -m crawlo.commands.run <spider_name>
    import sys

    sys.exit(main(sys.argv[1:]))