# 
# Generated by the nebius.base.protos.compiler.  DO NOT EDIT!
# 

import builtins as builtins
import collections.abc as abc
import datetime as datetime
import google.protobuf.descriptor as descriptor_1
import google.protobuf.duration_pb2 as duration_pb2
import google.protobuf.message as message_1
import google.protobuf.timestamp_pb2 as timestamp_pb2
import grpc as grpc
import nebius.aio.client as client
import nebius.aio.operation as operation
import nebius.aio.request as request_1
import nebius.api.nebius.common.v1 as v1_1
import nebius.api.nebius.common.v1.metadata_pb2 as metadata_pb2
import nebius.api.nebius.common.v1.operation_pb2 as operation_pb2
import nebius.api.nebius.storage.v1.base_pb2 as base_pb2
import nebius.api.nebius.storage.v1.bucket_counters_pb2 as bucket_counters_pb2
import nebius.api.nebius.storage.v1.bucket_pb2 as bucket_pb2
import nebius.api.nebius.storage.v1.bucket_service_pb2 as bucket_service_pb2
import nebius.api.nebius.storage.v1.lifecycle_pb2 as lifecycle_pb2
import nebius.base.fieldmask_protobuf as fieldmask_protobuf
import nebius.base.protos.descriptor as descriptor
import nebius.base.protos.pb_classes as pb_classes
import nebius.base.protos.pb_enum as pb_enum
import nebius.base.protos.unset as unset
import nebius.base.protos.well_known as well_known_1
import typing as typing
#@ local imports here @#

# file: nebius/storage/v1/base.proto
class StorageClass(pb_enum.Enum):
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.EnumDescriptor](".nebius.storage.v1.StorageClass",base_pb2.DESCRIPTOR,descriptor_1.EnumDescriptor)
    STORAGE_CLASS_UNSPECIFIED = 0
    STANDARD = 1
    ENHANCED_THROUGHPUT = 2

class VersioningPolicy(pb_enum.Enum):
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.EnumDescriptor](".nebius.storage.v1.VersioningPolicy",base_pb2.DESCRIPTOR,descriptor_1.EnumDescriptor)
    VERSIONING_POLICY_UNSPECIFIED = 0
    DISABLED = 1
    ENABLED = 2
    SUSPENDED = 3

# file: nebius/storage/v1/bucket_counters.proto
class CurrentBucketCounters(pb_classes.Message):
    __PB2_CLASS__ = bucket_counters_pb2.CurrentBucketCounters
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.CurrentBucketCounters",bucket_counters_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        simple_objects_quantity: "builtins.int|None|unset.UnsetType" = unset.Unset,
        simple_objects_size: "builtins.int|None|unset.UnsetType" = unset.Unset,
        multipart_objects_quantity: "builtins.int|None|unset.UnsetType" = unset.Unset,
        multipart_objects_size: "builtins.int|None|unset.UnsetType" = unset.Unset,
        multipart_uploads_quantity: "builtins.int|None|unset.UnsetType" = unset.Unset,
        inflight_parts_quantity: "builtins.int|None|unset.UnsetType" = unset.Unset,
        inflight_parts_size: "builtins.int|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(simple_objects_quantity, unset.UnsetType):
            self.simple_objects_quantity = simple_objects_quantity
        if not isinstance(simple_objects_size, unset.UnsetType):
            self.simple_objects_size = simple_objects_size
        if not isinstance(multipart_objects_quantity, unset.UnsetType):
            self.multipart_objects_quantity = multipart_objects_quantity
        if not isinstance(multipart_objects_size, unset.UnsetType):
            self.multipart_objects_size = multipart_objects_size
        if not isinstance(multipart_uploads_quantity, unset.UnsetType):
            self.multipart_uploads_quantity = multipart_uploads_quantity
        if not isinstance(inflight_parts_quantity, unset.UnsetType):
            self.inflight_parts_quantity = inflight_parts_quantity
        if not isinstance(inflight_parts_size, unset.UnsetType):
            self.inflight_parts_size = inflight_parts_size
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "simple_objects_quantity",
            "simple_objects_size",
            "multipart_objects_quantity",
            "multipart_objects_size",
            "multipart_uploads_quantity",
            "inflight_parts_quantity",
            "inflight_parts_size",
        ]
    
    @builtins.property
    def simple_objects_quantity(self) -> "builtins.int":
        return super()._get_field("simple_objects_quantity", explicit_presence=False,
        )
    @simple_objects_quantity.setter
    def simple_objects_quantity(self, value: "builtins.int|None") -> None:
        return super()._set_field("simple_objects_quantity",value,explicit_presence=False,
        )
    
    @builtins.property
    def simple_objects_size(self) -> "builtins.int":
        return super()._get_field("simple_objects_size", explicit_presence=False,
        )
    @simple_objects_size.setter
    def simple_objects_size(self, value: "builtins.int|None") -> None:
        return super()._set_field("simple_objects_size",value,explicit_presence=False,
        )
    
    @builtins.property
    def multipart_objects_quantity(self) -> "builtins.int":
        return super()._get_field("multipart_objects_quantity", explicit_presence=False,
        )
    @multipart_objects_quantity.setter
    def multipart_objects_quantity(self, value: "builtins.int|None") -> None:
        return super()._set_field("multipart_objects_quantity",value,explicit_presence=False,
        )
    
    @builtins.property
    def multipart_objects_size(self) -> "builtins.int":
        return super()._get_field("multipart_objects_size", explicit_presence=False,
        )
    @multipart_objects_size.setter
    def multipart_objects_size(self, value: "builtins.int|None") -> None:
        return super()._set_field("multipart_objects_size",value,explicit_presence=False,
        )
    
    @builtins.property
    def multipart_uploads_quantity(self) -> "builtins.int":
        return super()._get_field("multipart_uploads_quantity", explicit_presence=False,
        )
    @multipart_uploads_quantity.setter
    def multipart_uploads_quantity(self, value: "builtins.int|None") -> None:
        return super()._set_field("multipart_uploads_quantity",value,explicit_presence=False,
        )
    
    @builtins.property
    def inflight_parts_quantity(self) -> "builtins.int":
        return super()._get_field("inflight_parts_quantity", explicit_presence=False,
        )
    @inflight_parts_quantity.setter
    def inflight_parts_quantity(self, value: "builtins.int|None") -> None:
        return super()._set_field("inflight_parts_quantity",value,explicit_presence=False,
        )
    
    @builtins.property
    def inflight_parts_size(self) -> "builtins.int":
        return super()._get_field("inflight_parts_size", explicit_presence=False,
        )
    @inflight_parts_size.setter
    def inflight_parts_size(self, value: "builtins.int|None") -> None:
        return super()._set_field("inflight_parts_size",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "simple_objects_quantity":"simple_objects_quantity",
        "simple_objects_size":"simple_objects_size",
        "multipart_objects_quantity":"multipart_objects_quantity",
        "multipart_objects_size":"multipart_objects_size",
        "multipart_uploads_quantity":"multipart_uploads_quantity",
        "inflight_parts_quantity":"inflight_parts_quantity",
        "inflight_parts_size":"inflight_parts_size",
    }
    
class NonCurrentBucketCounters(pb_classes.Message):
    """
    Counters for non-current object versions (for versioning buckets).
    """
    
    __PB2_CLASS__ = bucket_counters_pb2.NonCurrentBucketCounters
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.NonCurrentBucketCounters",bucket_counters_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        simple_objects_quantity: "builtins.int|None|unset.UnsetType" = unset.Unset,
        simple_objects_size: "builtins.int|None|unset.UnsetType" = unset.Unset,
        multipart_objects_quantity: "builtins.int|None|unset.UnsetType" = unset.Unset,
        multipart_objects_size: "builtins.int|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(simple_objects_quantity, unset.UnsetType):
            self.simple_objects_quantity = simple_objects_quantity
        if not isinstance(simple_objects_size, unset.UnsetType):
            self.simple_objects_size = simple_objects_size
        if not isinstance(multipart_objects_quantity, unset.UnsetType):
            self.multipart_objects_quantity = multipart_objects_quantity
        if not isinstance(multipart_objects_size, unset.UnsetType):
            self.multipart_objects_size = multipart_objects_size
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "simple_objects_quantity",
            "simple_objects_size",
            "multipart_objects_quantity",
            "multipart_objects_size",
        ]
    
    @builtins.property
    def simple_objects_quantity(self) -> "builtins.int":
        return super()._get_field("simple_objects_quantity", explicit_presence=False,
        )
    @simple_objects_quantity.setter
    def simple_objects_quantity(self, value: "builtins.int|None") -> None:
        return super()._set_field("simple_objects_quantity",value,explicit_presence=False,
        )
    
    @builtins.property
    def simple_objects_size(self) -> "builtins.int":
        return super()._get_field("simple_objects_size", explicit_presence=False,
        )
    @simple_objects_size.setter
    def simple_objects_size(self, value: "builtins.int|None") -> None:
        return super()._set_field("simple_objects_size",value,explicit_presence=False,
        )
    
    @builtins.property
    def multipart_objects_quantity(self) -> "builtins.int":
        return super()._get_field("multipart_objects_quantity", explicit_presence=False,
        )
    @multipart_objects_quantity.setter
    def multipart_objects_quantity(self, value: "builtins.int|None") -> None:
        return super()._set_field("multipart_objects_quantity",value,explicit_presence=False,
        )
    
    @builtins.property
    def multipart_objects_size(self) -> "builtins.int":
        return super()._get_field("multipart_objects_size", explicit_presence=False,
        )
    @multipart_objects_size.setter
    def multipart_objects_size(self, value: "builtins.int|None") -> None:
        return super()._set_field("multipart_objects_size",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "simple_objects_quantity":"simple_objects_quantity",
        "simple_objects_size":"simple_objects_size",
        "multipart_objects_quantity":"multipart_objects_quantity",
        "multipart_objects_size":"multipart_objects_size",
    }
    
class BucketCounters(pb_classes.Message):
    __PB2_CLASS__ = bucket_counters_pb2.BucketCounters
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.BucketCounters",bucket_counters_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        storage_class: "StorageClass|base_pb2.StorageClass|None|unset.UnsetType" = unset.Unset,
        counters: "CurrentBucketCounters|bucket_counters_pb2.CurrentBucketCounters|None|unset.UnsetType" = unset.Unset,
        non_current_counters: "NonCurrentBucketCounters|bucket_counters_pb2.NonCurrentBucketCounters|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(storage_class, unset.UnsetType):
            self.storage_class = storage_class
        if not isinstance(counters, unset.UnsetType):
            self.counters = counters
        if not isinstance(non_current_counters, unset.UnsetType):
            self.non_current_counters = non_current_counters
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "storage_class",
            "counters",
            "non_current_counters",
        ]
    
    @builtins.property
    def storage_class(self) -> "StorageClass":
        return super()._get_field("storage_class", explicit_presence=False,
        wrap=StorageClass,
        )
    @storage_class.setter
    def storage_class(self, value: "StorageClass|base_pb2.StorageClass|None") -> None:
        return super()._set_field("storage_class",value,explicit_presence=False,
        )
    
    @builtins.property
    def counters(self) -> "CurrentBucketCounters":
        return super()._get_field("counters", explicit_presence=False,
        wrap=CurrentBucketCounters,
        )
    @counters.setter
    def counters(self, value: "CurrentBucketCounters|bucket_counters_pb2.CurrentBucketCounters|None") -> None:
        return super()._set_field("counters",value,explicit_presence=False,
        )
    
    @builtins.property
    def non_current_counters(self) -> "NonCurrentBucketCounters":
        return super()._get_field("non_current_counters", explicit_presence=False,
        wrap=NonCurrentBucketCounters,
        )
    @non_current_counters.setter
    def non_current_counters(self, value: "NonCurrentBucketCounters|bucket_counters_pb2.NonCurrentBucketCounters|None") -> None:
        return super()._set_field("non_current_counters",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "storage_class":"storage_class",
        "counters":"counters",
        "non_current_counters":"non_current_counters",
    }
    
# file: nebius/storage/v1/lifecycle.proto
class LifecycleConfiguration(pb_classes.Message):
    """
    The lifecycle configuration consists of one or more rules.
    An Lifecycle configuration can have up to 1,000 rules.
    Each rule consists of the following:
    - A filter identifying a subset of objects to which the rule applies.
      The filter can be based on a key name prefix, object size, or any combination of these.
    - A status indicating whether the rule is currently active.
    - One or more lifecycle expiration actions that you want to be performed on the objects
      identified by the filter. If the state of your bucket is versioning-enabled or versioning-suspended
      (bucket.spec.versioning_policy equals to ENABLED or SUSPENDED) you can have many versions of the same
      object (one current version and zero or more noncurrent versions). The system provides predefined actions
      that you can specify for current and noncurrent object versions.
    """
    
    __PB2_CLASS__ = lifecycle_pb2.LifecycleConfiguration
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleConfiguration",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        rules: "abc.Iterable[LifecycleRule]|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(rules, unset.UnsetType):
            self.rules = rules
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "rules",
        ]
    
    @builtins.property
    def rules(self) -> "abc.MutableSequence[LifecycleRule]":
        return super()._get_field("rules", explicit_presence=False,
        wrap=pb_classes.Repeated.with_wrap(LifecycleRule,None,None),
        )
    @rules.setter
    def rules(self, value: "abc.Iterable[LifecycleRule]|None") -> None:
        return super()._set_field("rules",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "rules":"rules",
    }
    
class LifecycleRule(pb_classes.Message):
    __PB2_CLASS__ = lifecycle_pb2.LifecycleRule
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleRule",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    class Status(pb_enum.Enum):
        __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.EnumDescriptor](".nebius.storage.v1.LifecycleRule.Status",lifecycle_pb2.DESCRIPTOR,descriptor_1.EnumDescriptor)
        STATUS_UNSPECIFIED = 0
        ENABLED = 1
        DISABLED = 2
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None|unset.UnsetType" = unset.Unset,
        status: "LifecycleRule.Status|lifecycle_pb2.LifecycleRule.Status|None|unset.UnsetType" = unset.Unset,
        filter: "LifecycleFilter|lifecycle_pb2.LifecycleFilter|None|unset.UnsetType" = unset.Unset,
        expiration: "LifecycleExpiration|lifecycle_pb2.LifecycleExpiration|None|unset.UnsetType" = unset.Unset,
        noncurrent_version_expiration: "LifecycleNoncurrentVersionExpiration|lifecycle_pb2.LifecycleNoncurrentVersionExpiration|None|unset.UnsetType" = unset.Unset,
        abort_incomplete_multipart_upload: "LifecycleAbortIncompleteMultipartUpload|lifecycle_pb2.LifecycleAbortIncompleteMultipartUpload|None|unset.UnsetType" = unset.Unset,
        transition: "LifecycleTransition|lifecycle_pb2.LifecycleTransition|None|unset.UnsetType" = unset.Unset,
        noncurrent_version_transition: "LifecycleNoncurrentVersionTransition|lifecycle_pb2.LifecycleNoncurrentVersionTransition|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(id, unset.UnsetType):
            self.id = id
        if not isinstance(status, unset.UnsetType):
            self.status = status
        if not isinstance(filter, unset.UnsetType):
            self.filter = filter
        if not isinstance(expiration, unset.UnsetType):
            self.expiration = expiration
        if not isinstance(noncurrent_version_expiration, unset.UnsetType):
            self.noncurrent_version_expiration = noncurrent_version_expiration
        if not isinstance(abort_incomplete_multipart_upload, unset.UnsetType):
            self.abort_incomplete_multipart_upload = abort_incomplete_multipart_upload
        if not isinstance(transition, unset.UnsetType):
            self.transition = transition
        if not isinstance(noncurrent_version_transition, unset.UnsetType):
            self.noncurrent_version_transition = noncurrent_version_transition
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "id",
            "status",
            "filter",
            "expiration",
            "noncurrent_version_expiration",
            "abort_incomplete_multipart_upload",
            "transition",
            "noncurrent_version_transition",
            "Status",
        ]
    
    @builtins.property
    def id(self) -> "builtins.str":
        """
        Unique identifier for the rule per configuration.
        The value cannot be longer than 255 characters.
        """
        
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str|None") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
    @builtins.property
    def status(self) -> "LifecycleRule.Status":
        return super()._get_field("status", explicit_presence=False,
        wrap=LifecycleRule.Status,
        )
    @status.setter
    def status(self, value: "LifecycleRule.Status|lifecycle_pb2.LifecycleRule.Status|None") -> None:
        return super()._set_field("status",value,explicit_presence=False,
        )
    
    @builtins.property
    def filter(self) -> "LifecycleFilter":
        """
        The Filter is used to identify objects that a Lifecycle Rule applies to.
        The Lifecycle Rule will apply to any object matching all of the predicates
        configured inside (using logical AND).
        """
        
        return super()._get_field("filter", explicit_presence=False,
        wrap=LifecycleFilter,
        )
    @filter.setter
    def filter(self, value: "LifecycleFilter|lifecycle_pb2.LifecycleFilter|None") -> None:
        return super()._set_field("filter",value,explicit_presence=False,
        )
    
    @builtins.property
    def expiration(self) -> "LifecycleExpiration":
        """
        Specifies the expiration for the lifecycle of the object in the form of date, days and,
        whether the object has a delete marker.
        """
        
        return super()._get_field("expiration", explicit_presence=False,
        wrap=LifecycleExpiration,
        )
    @expiration.setter
    def expiration(self, value: "LifecycleExpiration|lifecycle_pb2.LifecycleExpiration|None") -> None:
        return super()._set_field("expiration",value,explicit_presence=False,
        )
    
    @builtins.property
    def noncurrent_version_expiration(self) -> "LifecycleNoncurrentVersionExpiration":
        """
        Specifies when noncurrent object versions expire.
        It works only on a bucket that has versioning enabled (or suspended).
        """
        
        return super()._get_field("noncurrent_version_expiration", explicit_presence=False,
        wrap=LifecycleNoncurrentVersionExpiration,
        )
    @noncurrent_version_expiration.setter
    def noncurrent_version_expiration(self, value: "LifecycleNoncurrentVersionExpiration|lifecycle_pb2.LifecycleNoncurrentVersionExpiration|None") -> None:
        return super()._set_field("noncurrent_version_expiration",value,explicit_presence=False,
        )
    
    @builtins.property
    def abort_incomplete_multipart_upload(self) -> "LifecycleAbortIncompleteMultipartUpload":
        """
        Specifies the days since the initiation of an incomplete multipart upload that
        the system will wait before permanently removing all parts of the upload.
        """
        
        return super()._get_field("abort_incomplete_multipart_upload", explicit_presence=False,
        wrap=LifecycleAbortIncompleteMultipartUpload,
        )
    @abort_incomplete_multipart_upload.setter
    def abort_incomplete_multipart_upload(self, value: "LifecycleAbortIncompleteMultipartUpload|lifecycle_pb2.LifecycleAbortIncompleteMultipartUpload|None") -> None:
        return super()._set_field("abort_incomplete_multipart_upload",value,explicit_presence=False,
        )
    
    @builtins.property
    def transition(self) -> "LifecycleTransition":
        """
        Specifies the transition for the lifecycle of an object in the form of date or days and
        target storage class to transit object to.
        """
        
        return super()._get_field("transition", explicit_presence=False,
        wrap=LifecycleTransition,
        )
    @transition.setter
    def transition(self, value: "LifecycleTransition|lifecycle_pb2.LifecycleTransition|None") -> None:
        return super()._set_field("transition",value,explicit_presence=False,
        )
    
    @builtins.property
    def noncurrent_version_transition(self) -> "LifecycleNoncurrentVersionTransition":
        """
        Spicifies the transition for the lifecycle of a noncurrent object.
        It works only on a bucket that has versioning enabled (or suspended).
        """
        
        return super()._get_field("noncurrent_version_transition", explicit_presence=False,
        wrap=LifecycleNoncurrentVersionTransition,
        )
    @noncurrent_version_transition.setter
    def noncurrent_version_transition(self, value: "LifecycleNoncurrentVersionTransition|lifecycle_pb2.LifecycleNoncurrentVersionTransition|None") -> None:
        return super()._set_field("noncurrent_version_transition",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "id":"id",
        "status":"status",
        "filter":"filter",
        "expiration":"expiration",
        "noncurrent_version_expiration":"noncurrent_version_expiration",
        "abort_incomplete_multipart_upload":"abort_incomplete_multipart_upload",
        "transition":"transition",
        "noncurrent_version_transition":"noncurrent_version_transition",
        "Status":"Status",
    }
    
class LifecycleFilter(pb_classes.Message):
    __PB2_CLASS__ = lifecycle_pb2.LifecycleFilter
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleFilter",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        prefix: "builtins.str|None|unset.UnsetType" = unset.Unset,
        object_size_greater_than_bytes: "builtins.int|None|unset.UnsetType" = unset.Unset,
        object_size_less_than_bytes: "builtins.int|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(prefix, unset.UnsetType):
            self.prefix = prefix
        if not isinstance(object_size_greater_than_bytes, unset.UnsetType):
            self.object_size_greater_than_bytes = object_size_greater_than_bytes
        if not isinstance(object_size_less_than_bytes, unset.UnsetType):
            self.object_size_less_than_bytes = object_size_less_than_bytes
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "prefix",
            "object_size_greater_than_bytes",
            "object_size_less_than_bytes",
        ]
    
    @builtins.property
    def prefix(self) -> "builtins.str":
        """
        Prefix identifying one or more objects to which the rule applies.
        If prefix is empty, the rule applies to all objects in the bucket.
        """
        
        return super()._get_field("prefix", explicit_presence=False,
        )
    @prefix.setter
    def prefix(self, value: "builtins.str|None") -> None:
        return super()._set_field("prefix",value,explicit_presence=False,
        )
    
    @builtins.property
    def object_size_greater_than_bytes(self) -> "builtins.int":
        """
        Minimum object size to which the rule applies.
        """
        
        return super()._get_field("object_size_greater_than_bytes", explicit_presence=False,
        )
    @object_size_greater_than_bytes.setter
    def object_size_greater_than_bytes(self, value: "builtins.int|None") -> None:
        return super()._set_field("object_size_greater_than_bytes",value,explicit_presence=False,
        )
    
    @builtins.property
    def object_size_less_than_bytes(self) -> "builtins.int":
        """
        Maximum object size to which the rule applies.
        """
        
        return super()._get_field("object_size_less_than_bytes", explicit_presence=False,
        )
    @object_size_less_than_bytes.setter
    def object_size_less_than_bytes(self, value: "builtins.int|None") -> None:
        return super()._set_field("object_size_less_than_bytes",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "prefix":"prefix",
        "object_size_greater_than_bytes":"object_size_greater_than_bytes",
        "object_size_less_than_bytes":"object_size_less_than_bytes",
    }
    
class LifecycleExpiration(pb_classes.Message):
    __PB2_CLASS__ = lifecycle_pb2.LifecycleExpiration
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleExpiration",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
        "date": well_known_1.ts_mask,
    }
    
    class __OneOfClass_expired_with__(pb_classes.OneOf):
        name: builtins.str= "expired_with"
        
        def __init__(self, msg: "LifecycleExpiration") -> None:
            super().__init__()
            self._message: "LifecycleExpiration" = msg
    
    class __OneOfClass_expired_with_date__(__OneOfClass_expired_with__):
        field: typing.Literal["date"] = "date"
        
        def __init__(self, msg: "LifecycleExpiration") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "datetime.datetime":
            return self._message.date
    
    class __OneOfClass_expired_with_days__(__OneOfClass_expired_with__):
        field: typing.Literal["days"] = "days"
        
        def __init__(self, msg: "LifecycleExpiration") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.int":
            return self._message.days
    
    @builtins.property
    def expired_with(self) -> __OneOfClass_expired_with_date__|__OneOfClass_expired_with_days__|None:
        field_name_1: str|None = super().which_field_in_oneof("expired_with")
        match field_name_1:
            case "date":
                return self.__OneOfClass_expired_with_date__(self)
            case "days":
                return self.__OneOfClass_expired_with_days__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name_1)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        date: "timestamp_pb2.Timestamp|datetime.datetime|None|unset.UnsetType" = unset.Unset,
        days: "builtins.int|None|unset.UnsetType" = unset.Unset,
        expired_object_delete_marker: "builtins.bool|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(date, unset.UnsetType):
            self.date = date
        if not isinstance(days, unset.UnsetType):
            self.days = days
        if not isinstance(expired_object_delete_marker, unset.UnsetType):
            self.expired_object_delete_marker = expired_object_delete_marker
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "date",
            "days",
            "expired_object_delete_marker",
            "expired_with",
        ]
    
    @builtins.property
    def date(self) -> "datetime.datetime|None":
        """
        Indicates at what date the object will be deleted. The time is always midnight UTC.
        """
        
        return super()._get_field("date", explicit_presence=True,
        wrap=well_known_1.from_timestamp
        )
    @date.setter
    def date(self, value: "timestamp_pb2.Timestamp|datetime.datetime|None") -> None:
        return super()._set_field("date",value,explicit_presence=True,
        unwrap=well_known_1.to_timestamp
        )
    
    @builtins.property
    def days(self) -> "builtins.int|None":
        """
        Indicates the lifetime, in days, of the objects that are subject to the rule.
        The value must be a non-zero positive integer.
        """
        
        return super()._get_field("days", explicit_presence=True,
        )
    @days.setter
    def days(self, value: "builtins.int|None") -> None:
        return super()._set_field("days",value,explicit_presence=True,
        )
    
    @builtins.property
    def expired_object_delete_marker(self) -> "builtins.bool":
        """
        Indicates whether the system will remove a "delete marker" with no noncurrent versions.
        If set to true, the "delete marker" will be permanently removed.
        If set to false the policy takes no action.
        This cannot be specified with Days or Date in a LifecycleExpiration Policy.
        """
        
        return super()._get_field("expired_object_delete_marker", explicit_presence=False,
        )
    @expired_object_delete_marker.setter
    def expired_object_delete_marker(self, value: "builtins.bool|None") -> None:
        return super()._set_field("expired_object_delete_marker",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "date":"date",
        "days":"days",
        "expired_object_delete_marker":"expired_object_delete_marker",
        "expired_with":"expired_with",
    }
    
class LifecycleNoncurrentVersionExpiration(pb_classes.Message):
    __PB2_CLASS__ = lifecycle_pb2.LifecycleNoncurrentVersionExpiration
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleNoncurrentVersionExpiration",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    class __OneOfClass__newer_noncurrent_versions__(pb_classes.OneOf):
        name: builtins.str= "_newer_noncurrent_versions"
        
        def __init__(self, msg: "LifecycleNoncurrentVersionExpiration") -> None:
            super().__init__()
            self._message: "LifecycleNoncurrentVersionExpiration" = msg
    
    class __OneOfClass__newer_noncurrent_versions_newer_noncurrent_versions__(__OneOfClass__newer_noncurrent_versions__):
        field: typing.Literal["newer_noncurrent_versions"] = "newer_noncurrent_versions"
        
        def __init__(self, msg: "LifecycleNoncurrentVersionExpiration") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.int":
            return self._message.newer_noncurrent_versions
    
    @builtins.property
    def _newer_noncurrent_versions(self) -> __OneOfClass__newer_noncurrent_versions_newer_noncurrent_versions__|None:
        field_name_1: str|None = super().which_field_in_oneof("_newer_noncurrent_versions")
        match field_name_1:
            case "newer_noncurrent_versions":
                return self.__OneOfClass__newer_noncurrent_versions_newer_noncurrent_versions__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name_1)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        newer_noncurrent_versions: "builtins.int|None|unset.UnsetType" = unset.Unset,
        noncurrent_days: "builtins.int|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(newer_noncurrent_versions, unset.UnsetType):
            self.newer_noncurrent_versions = newer_noncurrent_versions
        if not isinstance(noncurrent_days, unset.UnsetType):
            self.noncurrent_days = noncurrent_days
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "newer_noncurrent_versions",
            "noncurrent_days",
            "_newer_noncurrent_versions",
        ]
    
    @builtins.property
    def newer_noncurrent_versions(self) -> "builtins.int|None":
        """
        Specifies how many noncurrent versions the system will retain.
        """
        
        return super()._get_field("newer_noncurrent_versions", explicit_presence=True,
        )
    @newer_noncurrent_versions.setter
    def newer_noncurrent_versions(self, value: "builtins.int|None") -> None:
        return super()._set_field("newer_noncurrent_versions",value,explicit_presence=True,
        )
    
    @builtins.property
    def noncurrent_days(self) -> "builtins.int":
        """
        Specifies the number of days an object is noncurrent before the system will expire it.
        """
        
        return super()._get_field("noncurrent_days", explicit_presence=False,
        )
    @noncurrent_days.setter
    def noncurrent_days(self, value: "builtins.int|None") -> None:
        return super()._set_field("noncurrent_days",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "newer_noncurrent_versions":"newer_noncurrent_versions",
        "noncurrent_days":"noncurrent_days",
        "_newer_noncurrent_versions":"_newer_noncurrent_versions",
    }
    
class LifecycleAbortIncompleteMultipartUpload(pb_classes.Message):
    __PB2_CLASS__ = lifecycle_pb2.LifecycleAbortIncompleteMultipartUpload
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleAbortIncompleteMultipartUpload",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        days_after_initiation: "builtins.int|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(days_after_initiation, unset.UnsetType):
            self.days_after_initiation = days_after_initiation
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "days_after_initiation",
        ]
    
    @builtins.property
    def days_after_initiation(self) -> "builtins.int":
        """
        Specifies the days since the initiation of an incomplete multipart upload that
        the system will wait before permanently removing all parts of the upload.
        """
        
        return super()._get_field("days_after_initiation", explicit_presence=False,
        )
    @days_after_initiation.setter
    def days_after_initiation(self, value: "builtins.int|None") -> None:
        return super()._set_field("days_after_initiation",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "days_after_initiation":"days_after_initiation",
    }
    
class LifecycleTransition(pb_classes.Message):
    __PB2_CLASS__ = lifecycle_pb2.LifecycleTransition
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleTransition",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
        "date": well_known_1.ts_mask,
    }
    
    class __OneOfClass_transited_with__(pb_classes.OneOf):
        name: builtins.str= "transited_with"
        
        def __init__(self, msg: "LifecycleTransition") -> None:
            super().__init__()
            self._message: "LifecycleTransition" = msg
    
    class __OneOfClass_transited_with_date__(__OneOfClass_transited_with__):
        field: typing.Literal["date"] = "date"
        
        def __init__(self, msg: "LifecycleTransition") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "datetime.datetime":
            return self._message.date
    
    class __OneOfClass_transited_with_days__(__OneOfClass_transited_with__):
        field: typing.Literal["days"] = "days"
        
        def __init__(self, msg: "LifecycleTransition") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.int":
            return self._message.days
    
    @builtins.property
    def transited_with(self) -> __OneOfClass_transited_with_date__|__OneOfClass_transited_with_days__|None:
        field_name_1: str|None = super().which_field_in_oneof("transited_with")
        match field_name_1:
            case "date":
                return self.__OneOfClass_transited_with_date__(self)
            case "days":
                return self.__OneOfClass_transited_with_days__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name_1)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        date: "timestamp_pb2.Timestamp|datetime.datetime|None|unset.UnsetType" = unset.Unset,
        days: "builtins.int|None|unset.UnsetType" = unset.Unset,
        storage_class: "StorageClass|base_pb2.StorageClass|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(date, unset.UnsetType):
            self.date = date
        if not isinstance(days, unset.UnsetType):
            self.days = days
        if not isinstance(storage_class, unset.UnsetType):
            self.storage_class = storage_class
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "date",
            "days",
            "storage_class",
            "transited_with",
        ]
    
    @builtins.property
    def date(self) -> "datetime.datetime|None":
        """
        Indicates at what date the object will be transited. The time is always midnight UTC.
        """
        
        return super()._get_field("date", explicit_presence=True,
        wrap=well_known_1.from_timestamp
        )
    @date.setter
    def date(self, value: "timestamp_pb2.Timestamp|datetime.datetime|None") -> None:
        return super()._set_field("date",value,explicit_presence=True,
        unwrap=well_known_1.to_timestamp
        )
    
    @builtins.property
    def days(self) -> "builtins.int|None":
        """
        Amount of days since object was uploaded before it's transited to a new storage class.
        The value must be a non-zero positive integer.
        """
        
        return super()._get_field("days", explicit_presence=True,
        )
    @days.setter
    def days(self, value: "builtins.int|None") -> None:
        return super()._set_field("days",value,explicit_presence=True,
        )
    
    @builtins.property
    def storage_class(self) -> "StorageClass":
        """
        Target storage class to transit to.
        """
        
        return super()._get_field("storage_class", explicit_presence=False,
        wrap=StorageClass,
        )
    @storage_class.setter
    def storage_class(self, value: "StorageClass|base_pb2.StorageClass|None") -> None:
        return super()._set_field("storage_class",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "date":"date",
        "days":"days",
        "storage_class":"storage_class",
        "transited_with":"transited_with",
    }
    
class LifecycleNoncurrentVersionTransition(pb_classes.Message):
    __PB2_CLASS__ = lifecycle_pb2.LifecycleNoncurrentVersionTransition
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.LifecycleNoncurrentVersionTransition",lifecycle_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    class __OneOfClass__newer_noncurrent_versions__(pb_classes.OneOf):
        name: builtins.str= "_newer_noncurrent_versions"
        
        def __init__(self, msg: "LifecycleNoncurrentVersionTransition") -> None:
            super().__init__()
            self._message: "LifecycleNoncurrentVersionTransition" = msg
    
    class __OneOfClass__newer_noncurrent_versions_newer_noncurrent_versions__(__OneOfClass__newer_noncurrent_versions__):
        field: typing.Literal["newer_noncurrent_versions"] = "newer_noncurrent_versions"
        
        def __init__(self, msg: "LifecycleNoncurrentVersionTransition") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "builtins.int":
            return self._message.newer_noncurrent_versions
    
    @builtins.property
    def _newer_noncurrent_versions(self) -> __OneOfClass__newer_noncurrent_versions_newer_noncurrent_versions__|None:
        field_name_1: str|None = super().which_field_in_oneof("_newer_noncurrent_versions")
        match field_name_1:
            case "newer_noncurrent_versions":
                return self.__OneOfClass__newer_noncurrent_versions_newer_noncurrent_versions__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name_1)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        newer_noncurrent_versions: "builtins.int|None|unset.UnsetType" = unset.Unset,
        noncurrent_days: "builtins.int|None|unset.UnsetType" = unset.Unset,
        storage_class: "StorageClass|base_pb2.StorageClass|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(newer_noncurrent_versions, unset.UnsetType):
            self.newer_noncurrent_versions = newer_noncurrent_versions
        if not isinstance(noncurrent_days, unset.UnsetType):
            self.noncurrent_days = noncurrent_days
        if not isinstance(storage_class, unset.UnsetType):
            self.storage_class = storage_class
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "newer_noncurrent_versions",
            "noncurrent_days",
            "storage_class",
            "_newer_noncurrent_versions",
        ]
    
    @builtins.property
    def newer_noncurrent_versions(self) -> "builtins.int|None":
        """
        Specifies how many noncurrent versions the system will retain without transition.
        """
        
        return super()._get_field("newer_noncurrent_versions", explicit_presence=True,
        )
    @newer_noncurrent_versions.setter
    def newer_noncurrent_versions(self, value: "builtins.int|None") -> None:
        return super()._set_field("newer_noncurrent_versions",value,explicit_presence=True,
        )
    
    @builtins.property
    def noncurrent_days(self) -> "builtins.int":
        """
        Specifies the number of days an object is noncurrent before the system will transit it.
        """
        
        return super()._get_field("noncurrent_days", explicit_presence=False,
        )
    @noncurrent_days.setter
    def noncurrent_days(self, value: "builtins.int|None") -> None:
        return super()._set_field("noncurrent_days",value,explicit_presence=False,
        )
    
    @builtins.property
    def storage_class(self) -> "StorageClass":
        """
        Target storage class to transit to.
        """
        
        return super()._get_field("storage_class", explicit_presence=False,
        wrap=StorageClass,
        )
    @storage_class.setter
    def storage_class(self, value: "StorageClass|base_pb2.StorageClass|None") -> None:
        return super()._set_field("storage_class",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "newer_noncurrent_versions":"newer_noncurrent_versions",
        "noncurrent_days":"noncurrent_days",
        "storage_class":"storage_class",
        "_newer_noncurrent_versions":"_newer_noncurrent_versions",
    }
    
# file: nebius/storage/v1/bucket.proto
class Bucket(pb_classes.Message):
    __PB2_CLASS__ = bucket_pb2.Bucket
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.Bucket",bucket_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None|unset.UnsetType" = unset.Unset,
        spec: "BucketSpec|bucket_pb2.BucketSpec|None|unset.UnsetType" = unset.Unset,
        status: "BucketStatus|bucket_pb2.BucketStatus|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(metadata, unset.UnsetType):
            self.metadata = metadata
        if not isinstance(spec, unset.UnsetType):
            self.spec = spec
        if not isinstance(status, unset.UnsetType):
            self.status = status
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "metadata",
            "spec",
            "status",
        ]
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "BucketSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=BucketSpec,
        )
    @spec.setter
    def spec(self, value: "BucketSpec|bucket_pb2.BucketSpec|None") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
    @builtins.property
    def status(self) -> "BucketStatus":
        return super()._get_field("status", explicit_presence=False,
        wrap=BucketStatus,
        )
    @status.setter
    def status(self, value: "BucketStatus|bucket_pb2.BucketStatus|None") -> None:
        return super()._set_field("status",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "metadata":"metadata",
        "spec":"spec",
        "status":"status",
    }
    
class BucketSpec(pb_classes.Message):
    __PB2_CLASS__ = bucket_pb2.BucketSpec
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.BucketSpec",bucket_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        versioning_policy: "VersioningPolicy|base_pb2.VersioningPolicy|None|unset.UnsetType" = unset.Unset,
        max_size_bytes: "builtins.int|None|unset.UnsetType" = unset.Unset,
        lifecycle_configuration: "LifecycleConfiguration|lifecycle_pb2.LifecycleConfiguration|None|unset.UnsetType" = unset.Unset,
        default_storage_class: "StorageClass|base_pb2.StorageClass|None|unset.UnsetType" = unset.Unset,
        override_storage_class: "StorageClass|base_pb2.StorageClass|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(versioning_policy, unset.UnsetType):
            self.versioning_policy = versioning_policy
        if not isinstance(max_size_bytes, unset.UnsetType):
            self.max_size_bytes = max_size_bytes
        if not isinstance(lifecycle_configuration, unset.UnsetType):
            self.lifecycle_configuration = lifecycle_configuration
        if not isinstance(default_storage_class, unset.UnsetType):
            self.default_storage_class = default_storage_class
        if not isinstance(override_storage_class, unset.UnsetType):
            self.override_storage_class = override_storage_class
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "versioning_policy",
            "max_size_bytes",
            "lifecycle_configuration",
            "default_storage_class",
            "override_storage_class",
        ]
    
    @builtins.property
    def versioning_policy(self) -> "VersioningPolicy":
        """
        Supports transitions:
         * disabled -> enabled
         * disabled -> suspended
         * enabled <-> suspended
        """
        
        return super()._get_field("versioning_policy", explicit_presence=False,
        wrap=VersioningPolicy,
        )
    @versioning_policy.setter
    def versioning_policy(self, value: "VersioningPolicy|base_pb2.VersioningPolicy|None") -> None:
        return super()._set_field("versioning_policy",value,explicit_presence=False,
        )
    
    @builtins.property
    def max_size_bytes(self) -> "builtins.int":
        """
        Maximum bucket size.
        Zero means unlimited.
        Actual limit can be lower if customer doesn't have enough quota.
        Real bucket size can go a little higher if customer writes too fast.
        """
        
        return super()._get_field("max_size_bytes", explicit_presence=False,
        )
    @max_size_bytes.setter
    def max_size_bytes(self, value: "builtins.int|None") -> None:
        return super()._set_field("max_size_bytes",value,explicit_presence=False,
        )
    
    @builtins.property
    def lifecycle_configuration(self) -> "LifecycleConfiguration":
        return super()._get_field("lifecycle_configuration", explicit_presence=False,
        wrap=LifecycleConfiguration,
        )
    @lifecycle_configuration.setter
    def lifecycle_configuration(self, value: "LifecycleConfiguration|lifecycle_pb2.LifecycleConfiguration|None") -> None:
        return super()._set_field("lifecycle_configuration",value,explicit_presence=False,
        )
    
    @builtins.property
    def default_storage_class(self) -> "StorageClass":
        """
        Storage class to use by default for uploads to the bucket. It may be overridden by `x-amz-storage-class` header.
        If not set - STANDARD is used as a default storage class.
        """
        
        return super()._get_field("default_storage_class", explicit_presence=False,
        wrap=StorageClass,
        )
    @default_storage_class.setter
    def default_storage_class(self, value: "StorageClass|base_pb2.StorageClass|None") -> None:
        return super()._set_field("default_storage_class",value,explicit_presence=False,
        )
    
    @builtins.property
    def override_storage_class(self) -> "StorageClass":
        """
        Storage class to override any other storage class of uploading objects. It overrides the storage class regardless
        of how the original storage class was specified - either the default storage class
        or the one provided via the `x-amz-storage-class` header.
        """
        
        return super()._get_field("override_storage_class", explicit_presence=False,
        wrap=StorageClass,
        )
    @override_storage_class.setter
    def override_storage_class(self, value: "StorageClass|base_pb2.StorageClass|None") -> None:
        return super()._set_field("override_storage_class",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "versioning_policy":"versioning_policy",
        "max_size_bytes":"max_size_bytes",
        "lifecycle_configuration":"lifecycle_configuration",
        "default_storage_class":"default_storage_class",
        "override_storage_class":"override_storage_class",
    }
    
class BucketStatus(pb_classes.Message):
    __PB2_CLASS__ = bucket_pb2.BucketStatus
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.BucketStatus",bucket_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
        "deleted_at": well_known_1.ts_mask,
        "purge_at": well_known_1.ts_mask,
    }
    
    class State(pb_enum.Enum):
        __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.EnumDescriptor](".nebius.storage.v1.BucketStatus.State",bucket_pb2.DESCRIPTOR,descriptor_1.EnumDescriptor)
        STATE_UNSPECIFIED = 0
        CREATING = 1
        """
        Bucket is under creation and cannot be used yet.
        """
        
        ACTIVE = 2
        """
        Bucket is active and ready for usage.
        """
        
        UPDATING = 3
        """
        Bucket is being updated.
        It can be used, but some settings are being modified and you can observe their inconsistency.
        """
        
        SCHEDULED_FOR_DELETION = 4
        """
        Bucket is scheduled for deletion.
        It cannot be used in s3 api anymore.
        """
        
    
    class SuspensionState(pb_enum.Enum):
        __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.EnumDescriptor](".nebius.storage.v1.BucketStatus.SuspensionState",bucket_pb2.DESCRIPTOR,descriptor_1.EnumDescriptor)
        SUSPENSION_STATE_UNSPECIFIED = 0
        NOT_SUSPENDED = 1
        SUSPENDED = 2
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        counters: "abc.Iterable[BucketCounters]|None|unset.UnsetType" = unset.Unset,
        state: "BucketStatus.State|bucket_pb2.BucketStatus.State|None|unset.UnsetType" = unset.Unset,
        suspension_state: "BucketStatus.SuspensionState|bucket_pb2.BucketStatus.SuspensionState|None|unset.UnsetType" = unset.Unset,
        deleted_at: "timestamp_pb2.Timestamp|datetime.datetime|None|unset.UnsetType" = unset.Unset,
        purge_at: "timestamp_pb2.Timestamp|datetime.datetime|None|unset.UnsetType" = unset.Unset,
        domain_name: "builtins.str|None|unset.UnsetType" = unset.Unset,
        region: "builtins.str|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(counters, unset.UnsetType):
            self.counters = counters
        if not isinstance(state, unset.UnsetType):
            self.state = state
        if not isinstance(suspension_state, unset.UnsetType):
            self.suspension_state = suspension_state
        if not isinstance(deleted_at, unset.UnsetType):
            self.deleted_at = deleted_at
        if not isinstance(purge_at, unset.UnsetType):
            self.purge_at = purge_at
        if not isinstance(domain_name, unset.UnsetType):
            self.domain_name = domain_name
        if not isinstance(region, unset.UnsetType):
            self.region = region
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "counters",
            "state",
            "suspension_state",
            "deleted_at",
            "purge_at",
            "domain_name",
            "region",
            "State",
            "SuspensionState",
        ]
    
    @builtins.property
    def counters(self) -> "abc.MutableSequence[BucketCounters]":
        return super()._get_field("counters", explicit_presence=False,
        wrap=pb_classes.Repeated.with_wrap(BucketCounters,None,None),
        )
    @counters.setter
    def counters(self, value: "abc.Iterable[BucketCounters]|None") -> None:
        return super()._set_field("counters",value,explicit_presence=False,
        )
    
    @builtins.property
    def state(self) -> "BucketStatus.State":
        return super()._get_field("state", explicit_presence=False,
        wrap=BucketStatus.State,
        )
    @state.setter
    def state(self, value: "BucketStatus.State|bucket_pb2.BucketStatus.State|None") -> None:
        return super()._set_field("state",value,explicit_presence=False,
        )
    
    @builtins.property
    def suspension_state(self) -> "BucketStatus.SuspensionState":
        return super()._get_field("suspension_state", explicit_presence=False,
        wrap=BucketStatus.SuspensionState,
        )
    @suspension_state.setter
    def suspension_state(self, value: "BucketStatus.SuspensionState|bucket_pb2.BucketStatus.SuspensionState|None") -> None:
        return super()._set_field("suspension_state",value,explicit_presence=False,
        )
    
    @builtins.property
    def deleted_at(self) -> "datetime.datetime":
        """
        The time when the bucket was deleted (or scheduled for deletion).
        It resets to null if the bucket is undeleted.
        """
        
        return super()._get_field("deleted_at", explicit_presence=False,
        wrap=well_known_1.from_timestamp
        )
    @deleted_at.setter
    def deleted_at(self, value: "timestamp_pb2.Timestamp|datetime.datetime|None") -> None:
        return super()._set_field("deleted_at",value,explicit_presence=False,
        unwrap=well_known_1.to_timestamp
        )
    
    @builtins.property
    def purge_at(self) -> "datetime.datetime":
        """
        The time when the bucket will be automatically purged in case it was soft-deleted.
        """
        
        return super()._get_field("purge_at", explicit_presence=False,
        wrap=well_known_1.from_timestamp
        )
    @purge_at.setter
    def purge_at(self, value: "timestamp_pb2.Timestamp|datetime.datetime|None") -> None:
        return super()._set_field("purge_at",value,explicit_presence=False,
        unwrap=well_known_1.to_timestamp
        )
    
    @builtins.property
    def domain_name(self) -> "builtins.str":
        """
        The domain of the endpoint where the bucket can be accessed. It omits the scheme (HTTPS) and the port (443)
        and contains only the FQDN address.
        """
        
        return super()._get_field("domain_name", explicit_presence=False,
        )
    @domain_name.setter
    def domain_name(self, value: "builtins.str|None") -> None:
        return super()._set_field("domain_name",value,explicit_presence=False,
        )
    
    @builtins.property
    def region(self) -> "builtins.str":
        """
        The name of the region where the bucket is located for use with S3 clients, i.e. "eu-west1".
        """
        
        return super()._get_field("region", explicit_presence=False,
        )
    @region.setter
    def region(self, value: "builtins.str|None") -> None:
        return super()._set_field("region",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "counters":"counters",
        "state":"state",
        "suspension_state":"suspension_state",
        "deleted_at":"deleted_at",
        "purge_at":"purge_at",
        "domain_name":"domain_name",
        "region":"region",
        "State":"State",
        "SuspensionState":"SuspensionState",
    }
    
# file: nebius/storage/v1/bucket_service.proto
class GetBucketRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.GetBucketRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.GetBucketRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(id, unset.UnsetType):
            self.id = id
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "id",
        ]
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str|None") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "id":"id",
    }
    
class GetBucketByNameRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.GetBucketByNameRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.GetBucketByNameRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        parent_id: "builtins.str|None|unset.UnsetType" = unset.Unset,
        name: "builtins.str|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(parent_id, unset.UnsetType):
            self.parent_id = parent_id
        if not isinstance(name, unset.UnsetType):
            self.name = name
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "parent_id",
            "name",
        ]
    
    @builtins.property
    def parent_id(self) -> "builtins.str":
        return super()._get_field("parent_id", explicit_presence=False,
        )
    @parent_id.setter
    def parent_id(self, value: "builtins.str|None") -> None:
        return super()._set_field("parent_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def name(self) -> "builtins.str":
        return super()._get_field("name", explicit_presence=False,
        )
    @name.setter
    def name(self, value: "builtins.str|None") -> None:
        return super()._set_field("name",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "parent_id":"parent_id",
        "name":"name",
    }
    
class CreateBucketRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.CreateBucketRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.CreateBucketRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None|unset.UnsetType" = unset.Unset,
        spec: "BucketSpec|bucket_pb2.BucketSpec|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(metadata, unset.UnsetType):
            self.metadata = metadata
        if not isinstance(spec, unset.UnsetType):
            self.spec = spec
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "metadata",
            "spec",
        ]
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "BucketSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=BucketSpec,
        )
    @spec.setter
    def spec(self, value: "BucketSpec|bucket_pb2.BucketSpec|None") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "metadata":"metadata",
        "spec":"spec",
    }
    
class UpdateBucketRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.UpdateBucketRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.UpdateBucketRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        metadata: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None|unset.UnsetType" = unset.Unset,
        spec: "BucketSpec|bucket_pb2.BucketSpec|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(metadata, unset.UnsetType):
            self.metadata = metadata
        if not isinstance(spec, unset.UnsetType):
            self.spec = spec
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "metadata",
            "spec",
        ]
    
    @builtins.property
    def metadata(self) -> "v1_1.ResourceMetadata":
        return super()._get_field("metadata", explicit_presence=False,
        wrap=v1_1.ResourceMetadata,
        )
    @metadata.setter
    def metadata(self, value: "v1_1.ResourceMetadata|metadata_pb2.ResourceMetadata|None") -> None:
        return super()._set_field("metadata",value,explicit_presence=False,
        )
    
    @builtins.property
    def spec(self) -> "BucketSpec":
        return super()._get_field("spec", explicit_presence=False,
        wrap=BucketSpec,
        )
    @spec.setter
    def spec(self, value: "BucketSpec|bucket_pb2.BucketSpec|None") -> None:
        return super()._set_field("spec",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "metadata":"metadata",
        "spec":"spec",
    }
    
class DeleteBucketRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.DeleteBucketRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.DeleteBucketRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
        "purge_at": well_known_1.ts_mask,
        "ttl": well_known_1.duration_mask,
    }
    
    class __OneOfClass_purge__(pb_classes.OneOf):
        name: builtins.str= "purge"
        
        def __init__(self, msg: "DeleteBucketRequest") -> None:
            super().__init__()
            self._message: "DeleteBucketRequest" = msg
    
    class __OneOfClass_purge_purge_at__(__OneOfClass_purge__):
        field: typing.Literal["purge_at"] = "purge_at"
        
        def __init__(self, msg: "DeleteBucketRequest") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "datetime.datetime":
            return self._message.purge_at
    
    class __OneOfClass_purge_ttl__(__OneOfClass_purge__):
        field: typing.Literal["ttl"] = "ttl"
        
        def __init__(self, msg: "DeleteBucketRequest") -> None:
            super().__init__(msg)
        @builtins.property
        def value(self) -> "datetime.timedelta":
            return self._message.ttl
    
    @builtins.property
    def purge(self) -> __OneOfClass_purge_purge_at__|__OneOfClass_purge_ttl__|None:
        """
        You can provide purge_at or ttl after which the bucket will be purged automatically.
        Otherwise, default ttl of 7 days will be applied.
        """
        
        field_name_1: str|None = super().which_field_in_oneof("purge")
        match field_name_1:
            case "purge_at":
                return self.__OneOfClass_purge_purge_at__(self)
            case "ttl":
                return self.__OneOfClass_purge_ttl__(self)
            case None:
                return None
            case _:
                raise pb_classes.OneOfMatchError(field_name_1)
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None|unset.UnsetType" = unset.Unset,
        purge_at: "timestamp_pb2.Timestamp|datetime.datetime|None|unset.UnsetType" = unset.Unset,
        ttl: "duration_pb2.Duration|datetime.timedelta|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(id, unset.UnsetType):
            self.id = id
        if not isinstance(purge_at, unset.UnsetType):
            self.purge_at = purge_at
        if not isinstance(ttl, unset.UnsetType):
            self.ttl = ttl
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "id",
            "purge_at",
            "ttl",
            "purge",
        ]
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str|None") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
    @builtins.property
    def purge_at(self) -> "datetime.datetime|None":
        """
        Absolute purging time: status.purge_at will be set to this value.
        """
        
        return super()._get_field("purge_at", explicit_presence=True,
        wrap=well_known_1.from_timestamp
        )
    @purge_at.setter
    def purge_at(self, value: "timestamp_pb2.Timestamp|datetime.datetime|None") -> None:
        return super()._set_field("purge_at",value,explicit_presence=True,
        unwrap=well_known_1.to_timestamp
        )
    
    @builtins.property
    def ttl(self) -> "datetime.timedelta|None":
        """
        Relative purging time: status.purge_at will be set to (current timestamp + ttl).
        """
        
        return super()._get_field("ttl", explicit_presence=True,
        wrap=well_known_1.from_duration
        )
    @ttl.setter
    def ttl(self, value: "duration_pb2.Duration|datetime.timedelta|None") -> None:
        return super()._set_field("ttl",value,explicit_presence=True,
        unwrap=well_known_1.to_duration
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "id":"id",
        "purge_at":"purge_at",
        "ttl":"ttl",
        "purge":"purge",
    }
    
class PurgeBucketRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.PurgeBucketRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.PurgeBucketRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(id, unset.UnsetType):
            self.id = id
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "id",
        ]
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str|None") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "id":"id",
    }
    
class UndeleteBucketRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.UndeleteBucketRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.UndeleteBucketRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        id: "builtins.str|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(id, unset.UnsetType):
            self.id = id
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "id",
        ]
    
    @builtins.property
    def id(self) -> "builtins.str":
        return super()._get_field("id", explicit_presence=False,
        )
    @id.setter
    def id(self, value: "builtins.str|None") -> None:
        return super()._set_field("id",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "id":"id",
    }
    
class ListBucketsRequest(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.ListBucketsRequest
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.ListBucketsRequest",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        parent_id: "builtins.str|None|unset.UnsetType" = unset.Unset,
        page_size: "builtins.int|None|unset.UnsetType" = unset.Unset,
        page_token: "builtins.str|None|unset.UnsetType" = unset.Unset,
        filter: "builtins.str|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(parent_id, unset.UnsetType):
            self.parent_id = parent_id
        if not isinstance(page_size, unset.UnsetType):
            self.page_size = page_size
        if not isinstance(page_token, unset.UnsetType):
            self.page_token = page_token
        if not isinstance(filter, unset.UnsetType):
            self.filter = filter
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "parent_id",
            "page_size",
            "page_token",
            "filter",
        ]
    
    @builtins.property
    def parent_id(self) -> "builtins.str":
        """
        Represents the container ID.
        """
        
        return super()._get_field("parent_id", explicit_presence=False,
        )
    @parent_id.setter
    def parent_id(self, value: "builtins.str|None") -> None:
        return super()._set_field("parent_id",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_size(self) -> "builtins.int":
        """
        Specifies the maximum number of items to return in the response.
        """
        
        return super()._get_field("page_size", explicit_presence=False,
        )
    @page_size.setter
    def page_size(self, value: "builtins.int|None") -> None:
        return super()._set_field("page_size",value,explicit_presence=False,
        )
    
    @builtins.property
    def page_token(self) -> "builtins.str":
        """
        Token for pagination, allowing the retrieval of the next set of results.
        """
        
        return super()._get_field("page_token", explicit_presence=False,
        )
    @page_token.setter
    def page_token(self, value: "builtins.str|None") -> None:
        return super()._set_field("page_token",value,explicit_presence=False,
        )
    
    @builtins.property
    def filter(self) -> "builtins.str":
        """
        A filter to narrow down the results based on specific criteria.
        """
        
        return super()._get_field("filter", explicit_presence=False,
        )
    @filter.setter
    def filter(self, value: "builtins.str|None") -> None:
        return super()._set_field("filter",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "parent_id":"parent_id",
        "page_size":"page_size",
        "page_token":"page_token",
        "filter":"filter",
    }
    
class ListBucketsResponse(pb_classes.Message):
    __PB2_CLASS__ = bucket_service_pb2.ListBucketsResponse
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.Descriptor](".nebius.storage.v1.ListBucketsResponse",bucket_service_pb2.DESCRIPTOR,descriptor_1.Descriptor)
    __mask_functions__ = {
    }
    
    def __init__(
        self,
        initial_message: message_1.Message|None = None,
        *,
        items: "abc.Iterable[Bucket]|None|unset.UnsetType" = unset.Unset,
        next_page_token: "builtins.str|None|unset.UnsetType" = unset.Unset,
    ) -> None:
        super().__init__(initial_message)
        if not isinstance(items, unset.UnsetType):
            self.items = items
        if not isinstance(next_page_token, unset.UnsetType):
            self.next_page_token = next_page_token
    
    def __dir__(self) ->abc.Iterable[builtins.str]:
        return [
            "items",
            "next_page_token",
        ]
    
    @builtins.property
    def items(self) -> "abc.MutableSequence[Bucket]":
        """
        List of buckets returned in the response. The field should be named as `items` for consistency.
        """
        
        return super()._get_field("items", explicit_presence=False,
        wrap=pb_classes.Repeated.with_wrap(Bucket,None,None),
        )
    @items.setter
    def items(self, value: "abc.Iterable[Bucket]|None") -> None:
        return super()._set_field("items",value,explicit_presence=False,
        )
    
    @builtins.property
    def next_page_token(self) -> "builtins.str":
        """
        Token for pagination, indicating the next set of results can be retrieved using this token.
        """
        
        return super()._get_field("next_page_token", explicit_presence=False,
        )
    @next_page_token.setter
    def next_page_token(self, value: "builtins.str|None") -> None:
        return super()._set_field("next_page_token",value,explicit_presence=False,
        )
    
    __PY_TO_PB2__: builtins.dict[builtins.str,builtins.str] = {
        "items":"items",
        "next_page_token":"next_page_token",
    }
    

class BucketServiceClient(client.ClientWithOperations[v1_1.Operation,v1_1.OperationServiceClient]):
    __PB2_DESCRIPTOR__ = descriptor.DescriptorWrap[descriptor_1.ServiceDescriptor](".nebius.storage.v1.BucketService",bucket_service_pb2.DESCRIPTOR,descriptor_1.ServiceDescriptor)
    __service_name__ = ".nebius.storage.v1.BucketService"
    __operation_type__ = v1_1.Operation
    __operation_service_class__ = v1_1.OperationServiceClient
    __operation_source_method__ = "Create"
    
    def get(self,
        request: "GetBucketRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["GetBucketRequest","Bucket"]:
        return super().request(
            method="Get",
            request=request,
            result_pb2_class=bucket_pb2.Bucket,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=pb_classes.simple_wrapper(Bucket),
        )
    
    def get_by_name(self,
        request: "GetBucketByNameRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["GetBucketByNameRequest","Bucket"]:
        return super().request(
            method="GetByName",
            request=request,
            result_pb2_class=bucket_pb2.Bucket,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=pb_classes.simple_wrapper(Bucket),
        )
    
    def list(self,
        request: "ListBucketsRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["ListBucketsRequest","ListBucketsResponse"]:
        return super().request(
            method="List",
            request=request,
            result_pb2_class=bucket_service_pb2.ListBucketsResponse,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=pb_classes.simple_wrapper(ListBucketsResponse),
        )
    
    def create(self,
        request: "CreateBucketRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["CreateBucketRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Create",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=operation.Operation,
        )
    
    def update(self,
        request: "UpdateBucketRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["UpdateBucketRequest","operation.Operation[v1_1.Operation]"]:
        metadata = fieldmask_protobuf.ensure_reset_mask_in_metadata(request, metadata)
        return super().request(
            method="Update",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=operation.Operation,
        )
    
    def delete(self,
        request: "DeleteBucketRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["DeleteBucketRequest","operation.Operation[v1_1.Operation]"]:
        return super().request(
            method="Delete",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=operation.Operation,
        )
    
    def purge(self,
        request: "PurgeBucketRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["PurgeBucketRequest","operation.Operation[v1_1.Operation]"]:
        """
        Purge instantly deletes the bucket in ScheduledForDeletion state.
        It can be used only for buckets in ScheduledForDeletion state.
        If you want to delete Active bucket instantly, use Delete with zero ttl.
        """
        
        return super().request(
            method="Purge",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=operation.Operation,
        )
    
    def undelete(self,
        request: "UndeleteBucketRequest",
        metadata: abc.Iterable[builtins.tuple[builtins.str,builtins.str]]|None = None,
        timeout: builtins.float|None = None,
        credentials: grpc.CallCredentials | None = None,
        compression: grpc.Compression | None = None,
        retries: builtins.int | None = 3,
        per_retry_timeout: builtins.float | None = None,
    ) -> request_1.Request["UndeleteBucketRequest","operation.Operation[v1_1.Operation]"]:
        """
        Undelete recovers the bucket from ScheduledForDeletion state to Active.
        """
        
        return super().request(
            method="Undelete",
            request=request,
            result_pb2_class=operation_pb2.Operation,
            metadata=metadata,
            timeout=timeout,
            credentials=credentials,
            compression=compression,
            retries=retries,
            per_retry_timeout=per_retry_timeout,
            result_wrapper=operation.Operation,
        )
    

__all__ = [
    #@ local import names here @#
    "StorageClass",
    "VersioningPolicy",
    "CurrentBucketCounters",
    "NonCurrentBucketCounters",
    "BucketCounters",
    "LifecycleConfiguration",
    "LifecycleRule",
    "LifecycleFilter",
    "LifecycleExpiration",
    "LifecycleNoncurrentVersionExpiration",
    "LifecycleAbortIncompleteMultipartUpload",
    "LifecycleTransition",
    "LifecycleNoncurrentVersionTransition",
    "Bucket",
    "BucketSpec",
    "BucketStatus",
    "GetBucketRequest",
    "GetBucketByNameRequest",
    "CreateBucketRequest",
    "UpdateBucketRequest",
    "DeleteBucketRequest",
    "PurgeBucketRequest",
    "UndeleteBucketRequest",
    "ListBucketsRequest",
    "ListBucketsResponse",
    "BucketServiceClient",
]
