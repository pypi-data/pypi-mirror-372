{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registry Client Example\n",
    "\n",
    "This notebook demonstrates how to use the `LocalRegistryClient` to access model information from LangGate's model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# Optional environment variables\n",
    "# os.environ[\"LANGGATE_CONFIG\"] = \"path/to/langgate_config.yaml\"\n",
    "# os.environ[\"LANGGATE_MODELS\"] = \"path/to/langgate_models.json\"\n",
    "# os.environ[\"LOG_LEVEL\"] = \"debug\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Registry Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgate.registry import LocalRegistryClient\n",
    "\n",
    "# Initialize the registry client\n",
    "# LocalRegistryClient is a singleton\n",
    "client = LocalRegistryClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-08-18 14:00:12\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mrefreshing_model_caches       \u001b[0m\n",
      "\u001b[2m2025-08-18 14:00:12\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mrefreshed_model_caches        \u001b[0m \u001b[36mimage_count\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mllm_count\u001b[0m=\u001b[35m5\u001b[0m\n",
      "Available LLMs: 5\n",
      "- openai/gpt-5-chat: ChatGPT-5\n",
      "- openai/gpt-5: GPT-5\n",
      "- openai/gpt-5-high: GPT-5 high\n",
      "- anthropic/claude-sonnet-4: Claude-4 Sonnet\n",
      "- anthropic/claude-sonnet-4-reasoning: Claude-4 Sonnet R\n",
      "\n",
      "==================================================\n",
      "\n",
      "Available Image Models: 4\n",
      "- openai/gpt-image-1: GPT Image 1\n",
      "- openai/dall-e-3: DALL-E 3\n",
      "- black-forest-labs/flux-dev: FLUX.1 [dev]\n",
      "- stability-ai/sd-3.5-large: SD 3.5 Large\n"
     ]
    }
   ],
   "source": [
    "# List available LLMs\n",
    "llms = await client.list_llms()\n",
    "print(f\"Available LLMs: {len(llms)}\")\n",
    "for model in llms[:5]:\n",
    "    print(f\"- {model.id}: {model.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# List available image models\n",
    "image_models = await client.list_image_models()\n",
    "print(f\"Available Image Models: {len(image_models)}\")\n",
    "for model in image_models[:5]:\n",
    "    print(f\"- {model.id}: {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Detailed Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Model: ChatGPT-5\n",
      "Provider: OpenAI\n",
      "\n",
      "LLM metadata:\n",
      "{'capabilities': {'supports_files': True,\n",
      "                  'supports_max_tokens': True,\n",
      "                  'supports_prompt_caching': True,\n",
      "                  'supports_reasoning': True,\n",
      "                  'supports_response_schema': True,\n",
      "                  'supports_seed': True,\n",
      "                  'supports_tools': False,\n",
      "                  'supports_vision': True},\n",
      " 'context_window': {'max_input_tokens': 400000, 'max_output_tokens': 128000},\n",
      " 'costs': {'cache_read_input_token_cost': Decimal('1.25E-7'),\n",
      "           'input_cost_per_token': Decimal('0.00000125'),\n",
      "           'output_cost_per_token': Decimal('0.00001')},\n",
      " 'description': 'ChatGPT-5 from OpenAI is designed for advanced, natural, '\n",
      "                'multimodal, and context-aware conversations.',\n",
      " 'id': 'openai/gpt-5-chat',\n",
      " 'name': 'ChatGPT-5',\n",
      " 'provider': {'id': 'openai', 'name': 'OpenAI'},\n",
      " 'provider_id': 'openai',\n",
      " 'updated_dt': datetime.datetime(2025, 8, 18, 13, 0, 7, 738859, tzinfo=datetime.timezone.utc)}\n"
     ]
    }
   ],
   "source": [
    "# Get a specific LLM\n",
    "if llms:\n",
    "    llm_id = llms[0].id\n",
    "    llm_info = await client.get_llm_info(llm_id)\n",
    "\n",
    "    print(f\"\\nLLM Model: {llm_info.name}\")\n",
    "    print(f\"Provider: {llm_info.provider.name}\")\n",
    "\n",
    "    print(\"\\nLLM metadata:\")\n",
    "    pp(llm_info.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Model: GPT Image 1\n",
      "Provider: OpenAI\n",
      "\n",
      "Image model metadata:\n",
      "{'costs': {'image_generation': {'quality_tiers': {'high': {'1024x1024': Decimal('0.167'),\n",
      "                                                           '1024x1536': Decimal('0.25'),\n",
      "                                                           '1536x1024': Decimal('0.25')},\n",
      "                                                  'low': {'1024x1024': Decimal('0.011'),\n",
      "                                                          '1024x1536': Decimal('0.016'),\n",
      "                                                          '1536x1024': Decimal('0.016')},\n",
      "                                                  'medium': {'1024x1024': Decimal('0.042'),\n",
      "                                                             '1024x1536': Decimal('0.063'),\n",
      "                                                             '1536x1024': Decimal('0.063')}}},\n",
      "           'token_costs': {'input_cached_cost_per_token': Decimal('0.0000025'),\n",
      "                           'input_cost_per_token': Decimal('0.00001'),\n",
      "                           'output_cost_per_token': Decimal('0.00004')}},\n",
      " 'description': 'GPT-Image-1 is a multimodal model that accepts both text and '\n",
      "                'image inputs, and produces image outputs.',\n",
      " 'id': 'openai/gpt-image-1',\n",
      " 'name': 'GPT Image 1',\n",
      " 'provider': {'id': 'openai', 'name': 'OpenAI'},\n",
      " 'provider_id': 'openai',\n",
      " 'updated_dt': datetime.datetime(2025, 8, 18, 13, 0, 7, 738941, tzinfo=datetime.timezone.utc)}\n"
     ]
    }
   ],
   "source": [
    "# Get a specific image model\n",
    "if image_models:\n",
    "    image_id = image_models[0].id\n",
    "    image_info = await client.get_image_model_info(image_id)\n",
    "\n",
    "    print(f\"Image Model: {image_info.name}\")\n",
    "    print(f\"Provider: {image_info.provider.name}\")\n",
    "\n",
    "    print(\"\\nImage model metadata:\")\n",
    "    pp(image_info.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI models: 3\n",
      "- openai/gpt-5-chat: ChatGPT-5\n",
      "- openai/gpt-5: GPT-5\n",
      "- openai/gpt-5-high: GPT-5 high\n"
     ]
    }
   ],
   "source": [
    "# Filter models by provider\n",
    "openai_models = [model for model in llms if model.provider.id == \"openai\"]\n",
    "print(f\"OpenAI models: {len(openai_models)}\")\n",
    "for model in openai_models[:3]:\n",
    "    print(f\"- {model.id}: {model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models with vision capabilities: 5\n",
      "- openai/gpt-5-chat: ChatGPT-5\n",
      "- openai/gpt-5: GPT-5\n",
      "- openai/gpt-5-high: GPT-5 high\n",
      "- anthropic/claude-sonnet-4: Claude-4 Sonnet\n",
      "- anthropic/claude-sonnet-4-reasoning: Claude-4 Sonnet R\n"
     ]
    }
   ],
   "source": [
    "# Filter models by capability\n",
    "vision_models = [model for model in llms if model.capabilities.supports_vision]\n",
    "print(f\"\\nModels with vision capabilities: {len(vision_models)}\")\n",
    "for model in vision_models[:5]:\n",
    "    print(f\"- {model.id}: {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Model Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost information for ChatGPT-5:\n",
      "{'cache_read_input_token_cost': Decimal('1.25E-7'),\n",
      " 'input_cost_per_token': Decimal('0.00000125'),\n",
      " 'output_cost_per_token': Decimal('0.00001')}\n"
     ]
    }
   ],
   "source": [
    "# Get cost information for an LLM\n",
    "if llms:\n",
    "    llm_id = llms[0].id\n",
    "    llm_info = await client.get_llm_info(llm_id)\n",
    "\n",
    "    print(f\"Cost information for {llm_info.name}:\")\n",
    "    pp(llm_info.costs.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost information for GPT Image 1:\n",
      "{'image_generation': {'quality_tiers': {'high': {'1024x1024': Decimal('0.167'),\n",
      "                                                 '1024x1536': Decimal('0.25'),\n",
      "                                                 '1536x1024': Decimal('0.25')},\n",
      "                                        'low': {'1024x1024': Decimal('0.011'),\n",
      "                                                '1024x1536': Decimal('0.016'),\n",
      "                                                '1536x1024': Decimal('0.016')},\n",
      "                                        'medium': {'1024x1024': Decimal('0.042'),\n",
      "                                                   '1024x1536': Decimal('0.063'),\n",
      "                                                   '1536x1024': Decimal('0.063')}}},\n",
      " 'token_costs': {'input_cached_cost_per_token': Decimal('0.0000025'),\n",
      "                 'input_cost_per_token': Decimal('0.00001'),\n",
      "                 'output_cost_per_token': Decimal('0.00004')}}\n"
     ]
    }
   ],
   "source": [
    "# Get cost information for an image model\n",
    "if image_models:\n",
    "    image_id = image_models[0].id\n",
    "    image_info = await client.get_image_model_info(image_id)\n",
    "\n",
    "    print(f\"Cost information for {image_info.name}:\")\n",
    "    pp(image_info.costs.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Model Cost Structures:\n",
      "\n",
      "GPT Image 1:\n",
      "  - Quality-based pricing:\n",
      "    low:\n",
      "      1024x1024: $0.011\n",
      "      1024x1536: $0.016\n",
      "      1536x1024: $0.016\n",
      "    medium:\n",
      "      1024x1024: $0.042\n",
      "      1024x1536: $0.063\n",
      "      1536x1024: $0.063\n",
      "    high:\n",
      "      1024x1024: $0.167\n",
      "      1024x1536: $0.25\n",
      "      1536x1024: $0.25\n",
      "  - Also has token-based costs:\n",
      "    Input: $0.00001/token\n",
      "    Output: $0.00004/token\n",
      "\n",
      "DALL-E 3:\n",
      "  - Quality-based pricing:\n",
      "    standard:\n",
      "      1024x1024: $0.04\n",
      "      1024x1792: $0.08\n",
      "      1792x1024: $0.08\n",
      "    hd:\n",
      "      1024x1024: $0.08\n",
      "      1024x1792: $0.12\n",
      "      1792x1024: $0.12\n",
      "\n",
      "FLUX.1 [dev]:\n",
      "  - Flat rate: $0.025\n",
      "\n",
      "SD 3.5 Large:\n",
      "  - Flat rate: $0.065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare different image model cost structures\n",
    "print(\"Image Model Cost Structures:\\n\")\n",
    "\n",
    "# Show different pricing models\n",
    "for model in image_models[:5]:\n",
    "    model_info = await client.get_image_model_info(model.id)\n",
    "    print(f\"{model_info.name}:\")\n",
    "\n",
    "    if model_info.costs.image_generation.flat_rate:\n",
    "        print(f\"  - Flat rate: ${model_info.costs.image_generation.flat_rate}\")\n",
    "    elif model_info.costs.image_generation.quality_tiers:\n",
    "        print(\"  - Quality-based pricing:\")\n",
    "        for quality, sizes in model_info.costs.image_generation.quality_tiers.items():\n",
    "            print(f\"    {quality}:\")\n",
    "            for size, price in sizes.items():\n",
    "                print(f\"      {size}: ${price}\")\n",
    "\n",
    "    # Check if model also has token costs (hybrid pricing)\n",
    "    if model_info.costs.token_costs:\n",
    "        print(\"  - Also has token-based costs:\")\n",
    "        print(f\"    Input: ${model_info.costs.token_costs.input_cost_per_token}/token\")\n",
    "        print(\n",
    "            f\"    Output: ${model_info.costs.token_costs.output_cost_per_token}/token\"\n",
    "        )\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
