Metadata-Version: 2.4
Name: iflow-mcp_dw-mcp-server
Version: 0.1.0
Summary: è¯­éŸ³è½¬æ–‡å­— MCP æœåŠ¡å™¨ - æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼å’Œè¯†åˆ«å¼•æ“
Requires-Python: >=3.13
Requires-Dist: mcp[cli]>=1.11.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: pydub>=0.25.1
Requires-Dist: requests>=2.31.0
Requires-Dist: speechrecognition>=3.10.0
Requires-Dist: uvicorn>=0.24.0
Provides-Extra: dev
Requires-Dist: black>=23.0.0; extra == 'dev'
Requires-Dist: isort>=5.12.0; extra == 'dev'
Requires-Dist: mypy>=1.0.0; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.21.0; extra == 'dev'
Requires-Dist: pytest>=7.0.0; extra == 'dev'
Description-Content-Type: text/markdown

# è¯­éŸ³è½¬æ–‡å­— MCP æœåŠ¡å™¨

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„è¯­éŸ³è½¬æ–‡å­— MCP æœåŠ¡å™¨ï¼Œæ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼å’Œè¯†åˆ«å¼•æ“ã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- **å¤šå¼•æ“æ”¯æŒ**: è¿œç¨‹APIè°ƒç”¨ï¼ˆé˜¿é‡Œäº‘ç™¾ç‚¼ã€OpenAI Whisperã€è®¯é£ç­‰ï¼‰ã€Google Speech Recognitionã€CMU Sphinx
- **å¤šæ ¼å¼æ”¯æŒ**: WAVã€MP3ã€M4Aã€FLACã€OGGã€AAC
- **å¤šè¯­è¨€æ”¯æŒ**: ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ã€æ³•æ–‡ã€å¾·æ–‡ã€è¥¿ç­ç‰™æ–‡ã€ä¿„æ–‡
- **æ‰¹é‡å¤„ç†**: æ”¯æŒæ‰¹é‡è½¬å†™å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
- **å®æ—¶è¿›åº¦**: æä¾›è¯¦ç»†çš„è½¬å†™è¿›åº¦ä¿¡æ¯
- **æ— æœ¬åœ°æ¨¡å‹**: å…¨éƒ¨é€šè¿‡è¿œç¨‹APIè°ƒç”¨ï¼Œæ— éœ€ä¸‹è½½å¤§æ¨¡å‹

### ğŸ› ï¸ å·¥å…·åŠŸèƒ½
- `transcribe_audio_file`: è½¬å†™éŸ³é¢‘æ–‡ä»¶
- `transcribe_audio_data`: è½¬å†™éŸ³é¢‘æ•°æ®
- `transcribe_with_remote_api`: é€šè¿‡è¿œç¨‹APIè½¬å†™éŸ³é¢‘
- `batch_transcribe`: æ‰¹é‡è½¬å†™å¤šä¸ªæ–‡ä»¶
- `analyze_audio_file`: åˆ†æéŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
- `convert_audio_file_format`: è½¬æ¢éŸ³é¢‘æ ¼å¼
- `get_supported_formats`: è·å–æ”¯æŒçš„æ ¼å¼

### ğŸ“š èµ„æºåŠŸèƒ½
- `audio://info/{file_path}`: è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
- `audio://formats`: è·å–æ”¯æŒçš„éŸ³é¢‘æ ¼å¼

### ğŸ’¡ æç¤ºæ¨¡æ¿
- è¯­éŸ³è½¬æ–‡å­—åŠ©æ‰‹
- éŸ³é¢‘æ ¼å¼è½¬æ¢åŠ©æ‰‹

## å®‰è£…

### ä½¿ç”¨ uv (æ¨è)

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd DW_MCP_Server

# å®‰è£…ä¾èµ–
uv sync

# è¿è¡ŒæœåŠ¡å™¨
uv run python main.py
```

### ä½¿ç”¨ pip

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡ŒæœåŠ¡å™¨
python main.py
```

## ä½¿ç”¨æ–¹æ³•

### 1. å¯åŠ¨æœåŠ¡å™¨

```bash
# å¼€å‘æ¨¡å¼
uv run mcp dev main.py

# æˆ–è€…ç›´æ¥è¿è¡Œ
uv run python main.py
```

### 2. åœ¨ Claude Desktop ä¸­å®‰è£…

```bash
uv run mcp install main.py
```

### 3. ä½¿ç”¨ç¤ºä¾‹

#### è½¬å†™å•ä¸ªéŸ³é¢‘æ–‡ä»¶

```python
# ä½¿ç”¨ Google Speech Recognition
result = await transcribe_audio_file(
    file_path="/path/to/audio.wav",
    language="zh-CN",
    engine="google"
)

# ä½¿ç”¨è¿œç¨‹APIï¼ˆéœ€é…ç½®APIå¯†é’¥ï¼‰
result = await transcribe_audio_file(
    file_path="/path/to/audio.mp3",
    language="zh-CN",
    engine="remote_api"
)

# ç›´æ¥è°ƒç”¨è¿œç¨‹API
result = await transcribe_with_remote_api(
    file_path="/path/to/audio.wav",
    api_type="bailian",  # æ”¯æŒ bailian, openai, xunfei
    api_key="your_api_key",
    api_url="your_api_url",
    language="zh-CN"
)
```

#### æ‰¹é‡è½¬å†™

```python
file_paths = [
    "/path/to/audio1.wav",
    "/path/to/audio2.mp3",
    "/path/to/audio3.m4a"
]

results = await batch_transcribe(
    file_paths=file_paths,
    language="zh-CN",
    engine="whisper"
)
```

#### åˆ†æéŸ³é¢‘æ–‡ä»¶

```python
info = await analyze_audio_file("/path/to/audio.wav")
print(f"æ ¼å¼: {info.format}")
print(f"æ—¶é•¿: {info.duration}ç§’")
print(f"é‡‡æ ·ç‡: {info.sample_rate}Hz")
```

#### è½¬æ¢éŸ³é¢‘æ ¼å¼

```python
output_path = await convert_audio_file_format(
    input_path="/path/to/audio.mp3",
    output_path="/path/to/output.wav",
    target_format="wav"
)
```

## æ”¯æŒçš„æ ¼å¼

### è¾“å…¥æ ¼å¼
- WAV
- MP3
- M4A
- FLAC
- OGG
- AAC

### è¾“å‡ºæ ¼å¼
- WAV
- MP3
- TXT (è½¬å†™æ–‡æœ¬)
- SRT (å­—å¹•æ–‡ä»¶)
- VTT (WebVTT å­—å¹•)

### æ”¯æŒçš„è¯­è¨€
- ä¸­æ–‡ (zh-CN)
- è‹±æ–‡ (en-US)
- æ—¥æ–‡ (ja-JP)
- éŸ©æ–‡ (ko-KR)
- æ³•æ–‡ (fr-FR)
- å¾·æ–‡ (de-DE)
- è¥¿ç­ç‰™æ–‡ (es-ES)
- ä¿„æ–‡ (ru-RU)

## è¯†åˆ«å¼•æ“å¯¹æ¯”

| å¼•æ“ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| è¿œç¨‹APIï¼ˆç™¾ç‚¼/OpenAI/è®¯é£ï¼‰ | å‡†ç¡®ç‡é«˜ï¼Œæ”¯æŒå¤šç§è¯­è¨€ï¼Œæ— éœ€æœ¬åœ°æ¨¡å‹ | éœ€è¦ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥ | åœ¨çº¿åº”ç”¨ |
| Google Speech Recognition | å‡†ç¡®ç‡é«˜ï¼Œæ”¯æŒå¤šç§è¯­è¨€ | éœ€è¦ç½‘ç»œè¿æ¥ | åœ¨çº¿åº”ç”¨ |
| CMU Sphinx | å®Œå…¨ç¦»çº¿ï¼Œè½»é‡çº§ | å‡†ç¡®ç‡ç›¸å¯¹è¾ƒä½ | åµŒå…¥å¼è®¾å¤‡ |

## é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

```bash
# è®¾ç½®é»˜è®¤è¯­è¨€
export DEFAULT_LANGUAGE=zh-CN

# è®¾ç½®é»˜è®¤å¼•æ“
export DEFAULT_ENGINE=remote_api

# è®¾ç½®é»˜è®¤APIç±»å‹
export DEFAULT_API_TYPE=bailian

# é…ç½®APIå¯†é’¥å’Œåœ°å€
export BAILIAN_API_KEY=your_bailian_api_key
export BAILIAN_API_URL=https://bailian.aliyuncs.com/v1/audio/transcriptions
```

### æœåŠ¡å™¨é…ç½®

```python
# åœ¨ main.py ä¸­ä¿®æ”¹æœåŠ¡å™¨é…ç½®
mcp = FastMCP(
    "è¯­éŸ³è½¬æ–‡å­—æœåŠ¡",
    dependencies=["speechrecognition", "pydub", "openai-whisper", "torch"]
)
```

## å¼€å‘

### å®‰è£…å¼€å‘ä¾èµ–

```bash
uv sync --extra dev
```

### è¿è¡Œæµ‹è¯•

```bash
uv run pytest
```

### ä»£ç æ ¼å¼åŒ–

```bash
uv run black main.py
uv run isort main.py
```

### ç±»å‹æ£€æŸ¥

```bash
uv run mypy main.py
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥é…ç½®é”™è¯¯**
   ```bash
   # æ£€æŸ¥ç¯å¢ƒå˜é‡
   echo $BAILIAN_API_KEY
   echo $BAILIAN_API_URL
   
   # æˆ–åœ¨ä»£ç ä¸­ç›´æ¥ä¼ å…¥
   result = await transcribe_with_remote_api(
       file_path="audio.wav",
       api_key="your_api_key",
       api_url="your_api_url"
   )
   ```

2. **éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒ**
   ```bash
   # å®‰è£… ffmpeg
   # Windows: ä¸‹è½½ ffmpeg å¹¶æ·»åŠ åˆ° PATH
   # macOS: brew install ffmpeg
   # Linux: sudo apt install ffmpeg
   ```

3. **ç½‘ç»œè¿æ¥é”™è¯¯**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - æ£€æŸ¥APIåœ°å€æ˜¯å¦æ­£ç¡®
   - è€ƒè™‘ä½¿ç”¨æœ¬åœ°å¼•æ“ï¼ˆGoogle Speech Recognitionï¼‰

### æ—¥å¿—è°ƒè¯•

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)
```

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

### å¼€å‘æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»º Pull Request

## è®¸å¯è¯

MIT License

## æ›´æ–°æ—¥å¿—

### v0.1.0
- åˆå§‹ç‰ˆæœ¬
- æ”¯æŒ Google Speech Recognitionã€Whisperã€CMU Sphinx
- æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼
- æ”¯æŒæ‰¹é‡å¤„ç†
- æä¾›è¿›åº¦åé¦ˆ

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤ Issue
- å‘é€é‚®ä»¶
- åŠ å…¥è®¨è®ºç¾¤

---

**æ³¨æ„**: ä½¿ç”¨è¿œç¨‹APIéœ€è¦é…ç½®APIå¯†é’¥å’Œåœ°å€ï¼Œè¯·åœ¨ä½¿ç”¨å‰è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡æˆ–åœ¨è°ƒç”¨æ—¶ä¼ å…¥å‚æ•°ã€‚æ¨èä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼ã€OpenAI Whisperã€è®¯é£ç­‰ä¸»æµè¯­éŸ³è¯†åˆ«APIã€‚
