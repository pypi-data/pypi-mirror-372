[
  {
    "moduleName": "default",
    "category": "USE CASES",
    "title": "Basics",
    "type": "image",
    "templates": [
      {
        "name": "default",
        "title": "Génération d'images",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images à partir de prompts textuels.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      },
      {
        "name": "image2image",
        "title": "Image vers Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Transformer des images existantes en utilisant des prompts textuels.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/image-to-image",
        "tags": ["Image vers Image", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      },
      {
        "name": "lora",
        "title": "LoRA",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec des modèles LoRA pour des styles ou sujets spécialisés.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      },
      {
        "name": "lora_multiple",
        "title": "LoRA Multiple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en combinant plusieurs modèles LoRA.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Texte vers Image", "Image", "LoRA"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      },
      {
        "name": "inpaint_example",
        "title": "Inpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Éditer des parties spécifiques d'images de manière transparente.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Inpainting", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      },
      {
        "name": "inpaint_model_outpainting",
        "title": "Outpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Étendre les images au-delà de leurs limites d'origine.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Outpainting", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      },
      {
        "name": "embedding_example",
        "title": "Embedding",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en utilisant l'inversion textuelle pour des styles cohérents.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/",
        "tags": ["Embedding", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      },
      {
        "name": "gligen_textbox_example",
        "title": "Gligen Textbox",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec un placement précis d'objets en utilisant des boîtes de texte.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/gligen/",
        "tags": ["Gligen", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "USE CASES",
    "title": "Flux",
    "type": "image",
    "templates": [
      {
        "name": "image_chroma_text_to_image",
        "title": "Chroma texte vers image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Chroma est modifié à partir de Flux et présente quelques changements dans l'architecture.",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Chroma", "Flux"],
        "date": "2025-06-04"
      },
      {
        "name": "flux_kontext_dev_basic",
        "title": "Flux Kontext Dev (Basique)",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "description": "Éditer une image en utilisant Flux Kontext avec une visibilité complète des nœuds, parfait pour apprendre le flux de travail.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-kontext-dev",
        "tags": ["Édition d'Image", "Image vers Image"],
        "models": ["Flux"],
        "date": "2025-06-26"
      },
      {
        "name": "flux_dev_checkpoint_example",
        "title": "Flux Dev fp8",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en utilisant la version quantifiée Flux Dev fp8. Convient aux appareils avec une VRAM limitée, ne nécessite qu'un seul fichier de modèle, mais la qualité de l'image est légèrement inférieure à la version complète.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux_schnell",
        "title": "Flux Schnell fp8",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer rapidement des images avec la version quantifiée Flux Schnell fp8. Idéal pour le matériel d'entrée de gamme, ne nécessite que 4 étapes pour générer des images.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux1_krea_dev",
        "title": "Flux.1 Krea Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Un modèle FLUX affiné poussant le photoréalisme à son maximum",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux1-krea-dev",
        "tags": ["Texte vers Image", "Image", "Photoréalisme"],
        "models": ["Flux.1 Krea Dev"],
        "date": "2025-07-31"
      },
      {
        "name": "flux_dev_full_text_to_image",
        "title": "Flux Dev texte vers image complet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images de haute qualité avec la version complète de Flux Dev. Nécessite plus de VRAM et plusieurs fichiers de modèles, mais offre la meilleure capacité de suivi des prompts et la qualité d'image.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux_schnell_full_text_to_image",
        "title": "Flux Schnell texte vers image complet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images rapidement avec la version complète de Flux Schnell. Utilise la licence Apache2.0, ne nécessite que 4 étapes pour générer des images tout en maintenant une bonne qualité d'image.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-text-to-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux_fill_inpaint_example",
        "title": "Flux Inpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Combler les parties manquantes des images en utilisant l'inpainting Flux.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-fill-dev",
        "tags": ["Image vers Image", "Inpainting", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux_fill_outpaint_example",
        "title": "Flux Outpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Étendre les images au-delà des limites en utilisant l'outpainting Flux.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-fill-dev",
        "tags": ["Outpainting", "Image", "Image vers Image"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux_canny_model_example",
        "title": "Modèle Flux Canny",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par la détection de contours en utilisant Flux Canny.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image vers Image", "ControlNet", "Image"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux_depth_lora_example",
        "title": "Flux Depth LoRA",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant Flux LoRA.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "ttps://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image vers Image", "ControlNet", "Image", "LoRA"],
        "models": ["Flux"],
        "date": "2025-03-01"
      },
      {
        "name": "flux_redux_model_example",
        "title": "Modèle Flux Redux",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en transférant le style à partir d'images de référence en utilisant Flux Redux.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/flux/flux-1-controlnet",
        "tags": ["Image vers Image", "ControlNet", "Image", "LoRA"],
        "models": ["Flux"],
        "date": "2025-03-01"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "USE CASES",
    "title": "Image",
    "type": "image",
    "templates": [
      {
        "name": "image_qwen_image",
        "title": "Qwen-Image Texte vers Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec des capacités exceptionnelles de rendu et d'édition de texte multilingue en utilisant le modèle MMDiT 20B de Qwen-Image.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image",
        "tags": ["Texte vers Image", "Image"],
        "models": ["Qwen-Image"],
        "date": "2025-08-05"
      },
      {
        "name": "image_qwen_image_union_control_lora",
        "title": "Qwen-Image Union Control",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec un contrôle structurel précis en utilisant le LoRA ControlNet unifié de Qwen-Image. Prend en charge plusieurs types de contrôle incluant canny, depth, lineart, softedge, normal et openpose pour diverses applications créatives.",
        "tags": ["Texte vers Image", "Image", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-08-23"
      },
      {
        "name": "image_qwen_image_controlnet_patch",
        "title": "Qwen-Image ControlNet Basique",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Contrôler la génération d'images en utilisant les modèles ControlNet de Qwen-Image. Prend en charge les contrôles canny, depth et inpainting via le patching de modèles.",
        "tags": ["Texte vers Image", "Image", "ControlNet"],
        "models": ["Qwen-Image"],
        "date": "2025-08-24"
      },
      {
        "name": "image_qwen_image_edit",
        "title": "Édition d'Image Qwen",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Éditer des images avec une édition de texte bilingue précise et des capacités d'édition sémantique/apparence duales en utilisant le modèle MMDiT 20B de Qwen-Image-Edit.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/qwen/qwen-image-edit",
        "tags": ["Image vers Image", "Édition d'Image"],
        "models": ["Qwen-Image"],
        "date": "2025-08-18"
      },
      {
        "name": "image_omnigen2_t2i",
        "title": "OmniGen2 Texte vers Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images de haute qualité à partir de prompts textuels en utilisant le modèle multimodal unifié 7B d'OmniGen2 avec une architecture à double chemin.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/omnigen/omnigen2",
        "tags": ["Texte vers Image", "Image"],
        "models": ["OmniGen"],
        "date": "2025-06-30"
      },
      {
        "name": "image_omnigen2_image_edit",
        "title": "Édition d'Image OmniGen2",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "description": "Éditer des images avec des instructions en langage naturel en utilisant les capacités avancées d'édition d'images d'OmniGen2 et le support de rendu de texte.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/omnigen/omnigen2",
        "tags": ["Édition d'Image", "Image"],
        "models": ["OmniGen"],
        "date": "2025-06-30"
      },
      {
        "name": "hidream_i1_dev",
        "title": "HiDream I1 Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec HiDream I1 Dev - Version équilibrée avec 28 étapes d'inférence, adaptée au matériel de gamme moyenne.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Texte vers Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17"
      },
      {
        "name": "hidream_i1_fast",
        "title": "HiDream I1 Fast",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images rapidement avec HiDream I1 Fast - Version légère avec 16 étapes d'inférence, idéale pour des aperçus rapides sur du matériel d'entrée de gamme.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Texte vers Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17"
      },
      {
        "name": "hidream_i1_full",
        "title": "HiDream I1 Full",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec HiDream I1 Full - Version complète avec 50 étapes d'inférence pour une sortie de la plus haute qualité.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-i1",
        "tags": ["Texte vers Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-04-17"
      },
      {
        "name": "hidream_e1_1",
        "title": "Édition d'Image HiDream E1.1",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Éditer des images avec HiDream E1.1 – il est meilleur en qualité d'image et en précision d'édition que HiDream-E1-Full.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-e1",
        "tags": ["Édition d'Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-07-21"
      },
      {
        "name": "hidream_e1_full",
        "title": "Édition d'Image HiDream E1",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Éditer des images avec HiDream E1 - Modèle professionnel d'édition d'images en langage naturel.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/image/hidream/hidream-e1",
        "tags": ["Édition d'Image", "Image"],
        "models": ["HiDream"],
        "date": "2025-05-01"
      },
      {
        "name": "sd3.5_simple_example",
        "title": "SD3.5 Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en utilisant SD 3.5.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SD3.5"],
        "date": "2025-03-01"
      },
      {
        "name": "sd3.5_large_canny_controlnet_example",
        "title": "SD3.5 Large Canny ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par la détection de contours en utilisant SD 3.5 Canny ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image vers Image", "Image", "ControlNet"],
        "models": ["SD3.5"],
        "date": "2025-03-01"
      },
      {
        "name": "sd3.5_large_depth",
        "title": "SD3.5 Large Depth",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image vers Image", "Image", "ControlNet"],
        "models": ["SD3.5"],
        "date": "2025-03-01"
      },
      {
        "name": "sd3.5_large_blur",
        "title": "SD3.5 Large Blur",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par des images de référence floues en utilisant SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets",
        "tags": ["Image vers Image", "Image"],
        "models": ["SD3.5"],
        "date": "2025-03-01"
      },
      {
        "name": "sdxl_simple_example",
        "title": "SDXL Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images de haute qualité en utilisant SDXL.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL"],
        "date": "2025-03-01"
      },
      {
        "name": "sdxl_refiner_prompt_example",
        "title": "SDXL Refiner Prompt",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Améliorer les images SDXL en utilisant des modèles de raffinement.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL"],
        "date": "2025-03-01"
      },
      {
        "name": "sdxl_revision_text_prompts",
        "title": "SDXL Revision Text Prompts",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en transférant des concepts à partir d'images de référence en utilisant SDXL Revision.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/#revision",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL"],
        "date": "2025-03-01"
      },
      {
        "name": "sdxl_revision_zero_positive",
        "title": "SDXL Revision Zero Positive",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en utilisant à la fois des prompts textuels et des images de référence avec SDXL Revision.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/#revision",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL"],
        "date": "2025-03-01"
      },
      {
        "name": "sdxlturbo_example",
        "title": "SDXL Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en une seule étape en utilisant SDXL Turbo.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/",
        "tags": ["Texte vers Image", "Image"],
        "models": ["SDXL Turbo"],
        "date": "2025-03-01"
      },
      {
        "name": "image_lotus_depth_v1_1",
        "title": "Lotus Depth",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Exécuter Lotus Depth dans ComfyUI pour une estimation de profondeur monoculaire efficace zero-shot avec une haute rétention de détails.",
        "tags": ["Profondeur", "Image"],
        "models": ["SD1.5"],
        "date": "2025-05-21"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "USE CASES",
    "title": "Vidéo",
    "type": "video",
    "templates": [
      {
        "name": "video_wan2_2_14B_t2v",
        "title": "Wan 2.2 14B Text to Video",
        "description": "Generate high-quality videos from text prompts with cinematic aesthetic control and dynamic motion generation using Wan 2.2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan"],
        "date": "2025-07-29"
      },
      {
        "name": "video_wan2_2_14B_i2v",
        "title": "Wan 2.2 14B Image to Video",
        "description": "Transform static images into dynamic videos with precise motion control and style preservation using Wan 2.2.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Image vers Vidéo", "Vidéo"],
        "models": ["Wan2.2"],
        "date": "2025-07-29"
      },
      {
        "name": "video_wan2_2_14B_flf2v",
        "title": "Wan 2.2 14B First-Last Frame to Video",
        "description": "Generate smooth video transitions by defining start and end frames.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["FLF2V", "Vidéo"],
        "models": ["Wan2.2"],
        "date": "2025-08-02"
      },
      {
        "name": "video_wan2_2_14B_fun_inpaint",
        "title": "Wan 2.2 14B Fun Inp",
        "description": "Generate videos from start and end frames using Wan 2.2 Fun Inp.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-inp",
        "tags": ["FLF2V", "Vidéo"],
        "models": ["Wan2.2"],
        "date": "2025-08-12"
      },
      {
        "name": "video_wan2_2_14B_fun_control",
        "title": "Wan 2.2 14B Fun Control",
        "description": "Generate videos guided by pose, depth, and edge controls using Wan 2.2 Fun Control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-control",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.2"],
        "date": "2025-08-12"
      },
      {
        "name": "video_wan2_2_14B_fun_camera",
        "title": "Wan 2.2 14B Fun Camera Control",
        "description": "Generate videos with camera motion controls including pan, zoom, and rotation using Wan 2.2 Fun Camera Control.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2-2-fun-camera",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.2"],
        "date": "2025-08-17"
      },
      {
        "name": "video_wan2_2_5B_ti2v",
        "title": "Wan 2.2 5B Video Generation",
        "description": "Generate videos from text or images using Wan 2.2 5B hybrid model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan2_2",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.2"],
        "date": "2025-07-29"
      },
      {
        "name": "video_wan_vace_14B_t2v",
        "title": "Wan VACE Text to Video",
        "description": "Transform text descriptions into high-quality videos. Supports both 480p and 720p with VACE-14B model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-05-21"
      },
      {
        "name": "video_wan_vace_14B_ref2v",
        "title": "Wan VACE Reference to Video",
        "description": "Create videos that match the style and content of a reference image. Perfect for style-consistent video generation.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Référence vers Vidéo", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-05-21"
      },
      {
        "name": "video_wan_vace_14B_v2v",
        "title": "Wan VACE Control Video",
        "description": "Generate videos by controlling input videos and reference images using Wan VACE.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-05-21"
      },
      {
        "name": "video_wan_vace_outpainting",
        "title": "Wan VACE Outpainting",
        "description": "Generate extended videos by expanding video size using Wan VACE outpainting.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Outpainting", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-05-21"
      },
      {
        "name": "video_wan_vace_flf2v",
        "title": "Wan VACE First-Last Frame",
        "description": "Generate smooth video transitions by defining start and end frames. Supports custom keyframe sequences.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["FLF2V", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-05-21"
      },
      {
        "name": "video_wan_vace_inpainting",
        "title": "Wan VACE Inpainting",
        "description": "Edit specific regions in videos while preserving surrounding content. Great for object removal or replacement.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/vace",
        "tags": ["Inpainting", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-05-21"
      },
      {
        "name": "video_wan_ati",
        "title": "Wan ATI",
        "description": "Trajectory-controlled video generation.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-ati",
        "tags": ["Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-05-21"
      },
      {
        "name": "video_wan2.1_fun_camera_v1.1_1.3B",
        "title": "Wan 2.1 Fun Camera 1.3B",
        "description": "Generate dynamic videos with cinematic camera movements using Wan 2.1 Fun Camera 1.3B model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-04-15"
      },
      {
        "name": "video_wan2.1_fun_camera_v1.1_14B",
        "title": "Wan 2.1 Fun Camera 14B",
        "description": "Generate high-quality videos with advanced camera control using the full 14B model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-04-15"
      },
      {
        "name": "text_to_video_wan",
        "title": "Wan 2.1 Text to Video",
        "description": "Generate videos from text prompts using Wan 2.1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-video",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-03-01"
      },
      {
        "name": "image_to_video_wan",
        "title": "Wan 2.1 Image to Video",
        "description": "Generate videos from images using Wan 2.1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-video",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-03-01"
      },
      {
        "name": "wan2.1_fun_inp",
        "title": "Wan 2.1 Inpainting",
        "description": "Generate videos from start and end frames using Wan 2.1 inpainting.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-inp",
        "tags": ["Inpainting", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-04-15"
      },
      {
        "name": "wan2.1_fun_control",
        "title": "Wan 2.1 ControlNet",
        "description": "Generate videos guided by pose, depth, and edge controls using Wan 2.1 ControlNet.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control",
        "tags": ["Vidéo vers Vidéo", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-04-15"
      },
      {
        "name": "wan2.1_flf2v_720_f16",
        "title": "Wan 2.1 FLF2V 720p F16",
        "description": "Generate videos by controlling first and last frames using Wan 2.1 FLF2V.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-flf",
        "tags": ["FLF2V", "Vidéo"],
        "models": ["Wan2.1"],
        "date": "2025-04-15"
      },
      {
        "name": "ltxv_text_to_video",
        "title": "LTXV Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text prompts.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/ltxv",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["LTXV"],
        "date": "2025-03-01"
      },
      {
        "name": "ltxv_image_to_video",
        "title": "LTXV Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from still images.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/ltxv",
        "tags": ["Image vers Vidéo", "Vidéo"],
        "models": ["LTXV"],
        "date": "2025-03-01"
      },
      {
        "name": "mochi_text_to_video_example",
        "title": "Mochi Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text prompts using Mochi model.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/mochi/",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Mochi"],
        "date": "2025-03-01"
      },
      {
        "name": "hunyuan_video_text_to_video",
        "title": "Hunyuan Video Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text prompts using Hunyuan model.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["Hunyuan Video"],
        "date": "2025-03-01"
      },
      {
        "name": "image_to_video",
        "title": "SVD Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from still images.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video",
        "tags": ["Image vers Vidéo", "Vidéo"],
        "models": ["SVD"],
        "date": "2025-03-01"
      },
      {
        "name": "txt_to_image_to_video",
        "title": "SVD Text to Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos by first creating images from text prompts.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video",
        "tags": ["Texte vers Vidéo", "Vidéo"],
        "models": ["SVD"],
        "date": "2025-03-01"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "USE CASES",
    "title": "Audio",
    "type": "audio",
    "templates": [
      {
        "name": "audio_stable_audio_example",
        "title": "Stable Audio",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Generate audio from text prompts using Stable Audio.",
        "tags": ["Texte vers Audio", "Audio"],
        "models": ["Stable Audio"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/audio/"
      },
      {
        "name": "audio_ace_step_1_t2a_instrumentals",
        "title": "ACE-Step v1 Text to Instrumentals Music",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Generate instrumental music from text prompts using ACE-Step v1.",
        "tags": ["Texte vers Audio", "Audio", "Instrumentals"],
        "models": ["ACE-Step v1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1"
      },
      {
        "name": "audio_ace_step_1_t2a_song",
        "title": "ACE Step v1 Text to Song",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Generate songs with vocals from text prompts using ACE-Step v1, supporting multilingual and style customization.",
        "tags": ["Texte vers Audio", "Audio", "Song"],
        "models": ["ACE-Step v1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1"
      },
      {
        "name": "audio_ace_step_1_m2m_editing",
        "title": "ACE Step v1 M2M Editing",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Edit existing songs to change style and lyrics using ACE-Step v1 M2M.",
        "tags": ["Édition Audio", "Audio"],
        "models": ["ACE-Step v1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/audio/ace-step/ace-step-v1"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "TOOLS & BUILDING",
    "title": "Image API",
    "type": "image",
    "templates": [
      {
        "name": "api_bfl_flux_1_kontext_multiple_images_input",
        "title": "BFL Flux.1 Kontext Multiple Image Input",
        "description": "Input multiple images and edit them with Flux.1 Kontext.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux"],
        "date": "2025-05-29"
      },
      {
        "name": "api_bfl_flux_1_kontext_pro_image",
        "title": "BFL Flux.1 Kontext Pro",
        "description": "Edit images with Flux.1 Kontext pro image.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux"],
        "date": "2025-05-29"
      },
      {
        "name": "api_bfl_flux_1_kontext_max_image",
        "title": "BFL Flux.1 Kontext Max",
        "description": "Edit images with Flux.1 Kontext max image.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-kontext",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux"],
        "date": "2025-05-29"
      },
      {
        "name": "api_bfl_flux_pro_t2i",
        "title": "BFL Flux[Pro]: Text to Image",
        "description": "Generate images with excellent prompt following and visual quality using FLUX.1 Pro.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/black-forest-labs/flux-1-1-pro-ultra-image",
        "tags": ["Édition d'Image", "Image"],
        "models": ["Flux"],
        "date": "2025-05-01"
      },
      {
        "name": "api_luma_photon_i2i",
        "title": "Luma Photon: Image to Image",
        "description": "Guider la génération d'images en utilisant une combinaison d'images et de prompt.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["Luma Photon"],
        "date": "2025-03-01"
      },
      {
        "name": "api_luma_photon_style_ref",
        "title": "Luma Photon: Style Reference",
        "description": "Générer des images en mélangeant des références de style avec un contrôle précis en utilisant Luma Photon.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Texte vers Image", "Image", "API", "Transfert de Style"],
        "models": ["Luma Photon"],
        "date": "2025-03-01"
      },
      {
        "name": "api_recraft_image_gen_with_color_control",
        "title": "Recraft: Color Control Image Generation",
        "description": "Générer des images avec des palettes de couleurs personnalisées et des visuels spécifiques à la marque en utilisant Recraft.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Contrôle de Couleur"],
        "models": ["Recraft"],
        "date": "2025-03-01"
      },
      {
        "name": "api_recraft_image_gen_with_style_control",
        "title": "Recraft: Style Control Image Generation",
        "description": "Contrôler le style avec des exemples visuels, aligner le positionnement et affiner les objets. Stocker et partager des styles pour une cohérence de marque parfaite.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Contrôle de Style"],
        "models": ["Recraft"],
        "date": "2025-03-01"
      },
      {
        "name": "api_recraft_vector_gen",
        "title": "Recraft: Vector Generation",
        "description": "Générer des images vectorielles de haute qualité à partir de prompts textuels en utilisant le générateur AI vectoriel de Recraft.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Vector"],
        "models": ["Recraft"],
        "date": "2025-03-01"
      },
      {
        "name": "api_runway_text_to_image",
        "title": "Runway: Text to Image",
        "description": "Generate high-quality images from text prompts using Runway's AI model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Runway"],
        "date": "2025-03-01"
      },
      {
        "name": "api_runway_reference_to_image",
        "title": "Runway: Reference to Image",
        "description": "Generate new images based on reference styles and compositions with Runway's AI.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Image", "Image", "API", "Transfert de Style"],
        "models": ["Runway"],
        "date": "2025-03-01"
      },
      {
        "name": "api_stability_ai_stable_image_ultra_t2i",
        "title": "Stability AI: Stable Image Ultra Text to Image",
        "description": "Generate high quality images with excellent prompt adherence. Perfect for professional use cases at 1 megapixel resolution.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Stable Image Ultra"],
        "date": "2025-03-01"
      },
      {
        "name": "api_stability_ai_i2i",
        "title": "Stability AI: Image to Image",
        "description": "Transform images with high-quality generation using Stability AI, perfect for professional editing and style transfer.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["Stability AI"],
        "date": "2025-03-01"
      },
      {
        "name": "api_stability_ai_sd3.5_t2i",
        "title": "Stability AI: SD3.5 Text to Image",
        "description": "Generate high quality images with excellent prompt adherence. Perfect for professional use cases at 1 megapixel resolution.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["SD3.5"],
        "date": "2025-03-01"
      },
      {
        "name": "api_stability_ai_sd3.5_i2i",
        "title": "Stability AI: SD3.5 Image to Image",
        "description": "Generate high quality images with excellent prompt adherence. Perfect for professional use cases at 1 megapixel resolution.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["SD3.5"],
        "date": "2025-03-01"
      },
      {
        "name": "api_ideogram_v3_t2i",
        "title": "Ideogram V3: Text to Image",
        "description": "Générer des images de qualité professionnelle avec un excellent alignement des prompts, du photoréalisme et un rendu de texte en utilisant Ideogram V3.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API", "Text Rendering"],
        "models": ["Ideogram V3"],
        "date": "2025-03-01"
      },
      {
        "name": "api_openai_image_1_t2i",
        "title": "OpenAI: GPT-Image-1 Text to Image",
        "description": "Générer des images à partir de prompts textuels en utilisant l'API OpenAI GPT Image 1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["GPT-Image-1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "api_openai_image_1_i2i",
        "title": "OpenAI: GPT-Image-1 Image to Image",
        "description": "Générer des images à partir d'images d'entrée en utilisant l'API OpenAI GPT Image 1.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Image vers Image", "Image", "API"],
        "models": ["GPT-Image-1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "api_openai_image_1_inpaint",
        "title": "OpenAI: GPT-Image-1 Inpaint",
        "description": "Edit images using inpainting with OpenAI GPT Image 1 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Inpainting", "Image", "API"],
        "models": ["GPT-Image-1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "api_openai_image_1_multi_inputs",
        "title": "OpenAI: GPT-Image-1 Multi Inputs",
        "description": "Generate images from multiple inputs using OpenAI GPT Image 1 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Texte vers Image", "Image", "API", "Multi Input"],
        "models": ["GPT-Image-1"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "api_openai_dall_e_2_t2i",
        "title": "OpenAI: Dall-E 2 Text to Image",
        "description": "Generate images from text prompts using OpenAI Dall-E 2 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Dall-E 2"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2"
      },
      {
        "name": "api_openai_dall_e_2_inpaint",
        "title": "OpenAI: Dall-E 2 Inpaint",
        "description": "Edit images using inpainting with OpenAI Dall-E 2 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tags": ["Inpainting", "Image", "API"],
        "models": ["Dall-E 2"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2"
      },
      {
        "name": "api_openai_dall_e_3_t2i",
        "title": "OpenAI: Dall-E 3 Text to Image",
        "description": "Générer des images à partir de prompts textuels en utilisant l'API OpenAI Dall-E 3.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Image", "Image", "API"],
        "models": ["Dall-E 3"],
        "date": "2025-03-01",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-3"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "TOOLS & BUILDING",
    "title": "Video API",
    "type": "video",
    "templates": [
      {
        "name": "api_kling_i2v",
        "title": "Kling: Image to Video",
        "description": "Générer des vidéos avec une excellente adhérence aux prompts pour les actions, expressions et mouvements de caméra en utilisant Kling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_kling_effects",
        "title": "Kling: Video Effects",
        "description": "Générer des vidéos dynamiques en appliquant des effets visuels aux images en utilisant Kling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Effets Vidéo", "Vidéo", "API"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_kling_flf",
        "title": "Kling: FLF2V",
        "description": "Générer des vidéos en contrôlant les première et dernière images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Génération de Vidéo", "Vidéo", "API", "Contrôle de Cadre"],
        "models": ["Kling"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_vidu_text_to_video",
        "title": "Vidu: Text to Video",
        "description": "Generate high-quality 1080p videos from text prompts with adjustable movement amplitude and duration control using Vidu's advanced AI model.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": ""
      },
      {
        "name": "api_vidu_image_to_video",
        "title": "Vidu: Image to Video",
        "description": "Transform static images into dynamic 1080p videos with precise motion control and customizable movement amplitude using Vidu.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": ""
      },
      {
        "name": "api_vidu_reference_to_video",
        "title": "Vidu: Reference to Video",
        "description": "Generate videos with consistent subjects using multiple reference images (up to 7) for character and style continuity across the video sequence.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Référence vers Vidéo", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": ""
      },
      {
        "name": "api_vidu_start_end_to_video",
        "title": "Vidu: Start End to Video",
        "description": "Create smooth video transitions between defined start and end frames with natural motion interpolation and consistent visual quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["FLF2V", "Vidéo", "API"],
        "models": ["Vidu"],
        "date": "2025-08-23",
        "tutorialUrl": ""
      },
      {
        "name": "api_luma_i2v",
        "title": "Luma: Image to Video",
        "description": "Take static images and instantly create magical high quality animations.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_luma_t2v",
        "title": "Luma: Text to Video",
        "description": "High-quality videos can be generated using simple prompts.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["Luma"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_moonvalley_text_to_video",
        "title": "Moonvalley: Text to Video",
        "description": "Generate cinematic, 1080p videos from text prompts through a model trained exclusively on licensed data.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_moonvalley_image_to_video",
        "title": "Moonvalley: Image to Video",
        "description": "Generate cinematic, 1080p videos with an image through a model trained exclusively on licensed data.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_moonvalley_video_to_video_motion_transfer",
        "title": "Moonvalley: Motion Transfer",
        "description": "Apply motion from one video to another.",
        "mediaType": "image",
        "thumbnailVariant": "hoverDissolve",
        "mediaSubtype": "webp",
        "tags": ["Vidéo vers Vidéo", "Vidéo", "API", "Transfert de Mouvement"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_moonvalley_video_to_video_pose_control",
        "title": "Moonvalley: Pose Control",
        "description": "Apply human pose and movement from one video to another.",
        "mediaType": "image",
        "thumbnailVariant": "hoverDissolve",
        "mediaSubtype": "webp",
        "tags": ["Vidéo vers Vidéo", "Vidéo", "API", "Contrôle de Pose"],
        "models": ["Moonvalley"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_hailuo_minimax_video",
        "title": "MiniMax: Video",
        "description": "Generate high-quality videos from text prompts with optional first-frame control using MiniMax Hailuo-02 model. Supports multiple resolutions (768P/1080P) and durations (6/10s) with intelligent prompt optimization.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_hailuo_minimax_t2v",
        "title": "MiniMax: Text to Video",
        "description": "Generate high-quality videos directly from text prompts. Explore MiniMax's advanced AI capabilities to create diverse visual narratives with professional CGI effects and stylistic elements to bring your descriptions to life.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_hailuo_minimax_i2v",
        "title": "MiniMax: Image to Video",
        "description": "Generate refined videos from images and text with CGI integration using MiniMax.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["MiniMax"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_pixverse_i2v",
        "title": "PixVerse: Image to Video",
        "description": "Generate dynamic videos from static images with motion and effects using PixVerse.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_pixverse_template_i2v",
        "title": "PixVerse Templates: Image to Video",
        "description": "Generate dynamic videos from static images with motion and effects using PixVerse.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API", "Modèles"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_pixverse_t2v",
        "title": "PixVerse: Text to Video",
        "description": "Generate videos with accurate prompt interpretation and stunning video dynamics.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Vidéo", "Vidéo", "API"],
        "models": ["PixVerse"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_runway_gen3a_turbo_image_to_video",
        "title": "Runway: Gen3a Turbo Image to Video",
        "description": "Generate cinematic videos from static images using Runway Gen3a Turbo.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Runway Gen3a Turbo"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_runway_gen4_turo_image_to_video",
        "title": "Runway: Gen4 Turbo Image to Video",
        "description": "Generate dynamic videos from images using Runway Gen4 Turbo.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Runway Gen4 Turbo"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_runway_first_last_frame",
        "title": "Runway: First Last Frame to Video",
        "description": "Generate smooth video transitions between two keyframes with Runway's precision.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Génération de Vidéo", "Vidéo", "API", "Contrôle de Cadre"],
        "models": ["Runway"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_pika_i2v",
        "title": "Pika: Image to Video",
        "description": "Generate smooth animated videos from single static images using Pika AI.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Pika"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_pika_scene",
        "title": "Pika Scenes: Images to Video",
        "description": "Generate videos that incorporate multiple input images using Pika Scenes.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API", "Multi-Image"],
        "models": ["Pika Scenes"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_veo2_i2v",
        "title": "Veo2: Image to Video",
        "description": "Generate videos from images using Google Veo2 API.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Vidéo", "API"],
        "models": ["Veo2"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_veo3",
        "title": "Veo3: Image to Video",
        "description": "Generate high-quality 8-second videos from text prompts or images using Google's advanced Veo 3 API. Features audio generation, prompt enhancement, and dual model options for speed or quality.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image vers Vidéo", "Texte vers Vidéo", "API"],
        "models": ["Veo3"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "TOOLS & BUILDING",
    "title": "3D API",
    "type": "image",
    "templates": [
      {
        "name": "api_rodin_image_to_model",
        "title": "Rodin: Image to Model",
        "description": "Generate detailed 3D models from single photos using Rodin AI.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Modèle", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_rodin_multiview_to_model",
        "title": "Rodin: Multiview to Model",
        "description": "Sculpt comprehensive 3D models using Rodin's multi-angle reconstruction.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Multivue vers Modèle", "3D", "API"],
        "models": ["Rodin"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_tripo_text_to_model",
        "title": "Tripo: Text to Model",
        "description": "Craft 3D objects from descriptions with Tripo's text-driven modeling.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Texte vers Modèle", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_tripo_image_to_model",
        "title": "Tripo: Image to Model",
        "description": "Generate professional 3D assets from 2D images using Tripo engine.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Image vers Modèle", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_tripo_multiview_to_model",
        "title": "Tripo: Multiview to Model",
        "description": "Build 3D models from multiple angles with Tripo's advanced scanner.",
        "mediaType": "image",
        "thumbnailVariant": "compareSlider",
        "mediaSubtype": "webp",
        "tags": ["Multivue vers Modèle", "3D", "API"],
        "models": ["Tripo"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "TOOLS & BUILDING",
    "title": "LLM API",
    "type": "image",
    "templates": [
      {
        "name": "api_openai_chat",
        "title": "OpenAI: Chat",
        "description": "Engage with OpenAI's advanced language models for intelligent conversations.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Chat", "LLM", "API"],
        "models": ["OpenAI"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "api_google_gemini",
        "title": "Google Gemini: Chat",
        "description": "Experience Google's multimodal AI with Gemini's reasoning capabilities.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Chat", "LLM", "API"],
        "models": ["Google Gemini"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "TOOLS & BUILDING",
    "title": "Upscaling",
    "type": "image",
    "templates": [
      {
        "name": "hiresfix_latent_workflow",
        "title": "Agrandissement",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images en améliorant la qualité dans l'espace latent.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/"
      },
      {
        "name": "esrgan_example",
        "title": "ESRGAN",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images en utilisant les modèles ESRGAN pour améliorer la qualité.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/"
      },
      {
        "name": "hiresfix_esrgan_workflow",
        "title": "HiresFix ESRGAN Workflow",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images en utilisant les modèles ESRGAN pendant les étapes de génération intermédiaires.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#non-latent-upscaling"
      },
      {
        "name": "latent_upscale_different_prompt_model",
        "title": "Latent Upscale Different Prompt Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Agrandir les images tout en changeant les prompts à travers les passes de génération.",
        "thumbnailVariant": "zoomHover",
        "tags": ["Agrandissement", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#more-examples"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "TOOLS & BUILDING",
    "title": "ControlNet",
    "type": "image",
    "templates": [
      {
        "name": "controlnet_example",
        "title": "Scribble ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par des images de référence griffonnées en utilisant ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/"
      },
      {
        "name": "2_pass_pose_worship",
        "title": "Pose ControlNet 2 Pass",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par des références de pose en utilisant ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#pose-controlnet"
      },
      {
        "name": "depth_controlnet",
        "title": "Depth ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets"
      },
      {
        "name": "depth_t2i_adapter",
        "title": "Depth T2I Adapter",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images guidées par les informations de profondeur en utilisant l'adaptateur T2I.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["Adaptateur T2I", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets"
      },
      {
        "name": "mixing_controlnets",
        "title": "Mixing ControlNets",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en combinant plusieurs modèles ControlNet.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#mixing-controlnets"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "TOOLS & BUILDING",
    "title": "Composition de Zone",
    "type": "image",
    "templates": [
      {
        "name": "area_composition",
        "title": "Composition de Zone",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images en contrôlant la composition avec des zones définies.",
        "tags": ["Composition de Zone", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/"
      },
      {
        "name": "area_composition_square_area_for_subject",
        "title": "Area Composition Square Area for Subject",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des images avec un placement cohérent du sujet en utilisant la composition de zone.",
        "tags": ["Composition de Zone", "Image"],
        "models": ["SD1.5"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/#increasing-consistency-of-images-with-area-composition"
      }
    ]
  },
  {
    "moduleName": "default",
    "category": "USE CASES",
    "title": "3D",
    "type": "3d",
    "templates": [
      {
        "name": "3d_hunyuan3d_image_to_model",
        "title": "Hunyuan3D 2.0",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des modèles 3D à partir d'images simples en utilisant Hunyuan3D 2.0.",
        "tags": ["Image vers Modèle", "3D"],
        "models": ["Hunyuan3D 2.0"],
        "date": "2025-03-01",
        "tutorialUrl": ""
      },
      {
        "name": "3d_hunyuan3d_multiview_to_model",
        "title": "Hunyuan3D 2.0 MV",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des modèles 3D à partir de vues multiples en utilisant Hunyuan3D 2.0 MV.",
        "tags": ["Multivue vers Modèle", "3D"],
        "models": ["Hunyuan3D 2.0 MV"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "thumbnailVariant": "hoverDissolve"
      },
      {
        "name": "3d_hunyuan3d_multiview_to_model_turbo",
        "title": "Hunyuan3D 2.0 MV Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des modèles 3D à partir de vues multiples en utilisant Hunyuan3D 2.0 MV Turbo.",
        "tags": ["Multivue vers Modèle", "3D"],
        "models": ["Hunyuan3D 2.0 MV Turbo"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "thumbnailVariant": "hoverDissolve"
      },
      {
        "name": "stable_zero123_example",
        "title": "Stable Zero123",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Générer des vues 3D à partir d'images simples en utilisant Stable Zero123.",
        "tags": ["Image vers 3D", "3D"],
        "models": ["Stable Zero123"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/3d/"
      }
    ]
  }
]
