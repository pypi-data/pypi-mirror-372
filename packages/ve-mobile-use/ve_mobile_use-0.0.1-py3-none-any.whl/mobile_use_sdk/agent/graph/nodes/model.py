# Copyright (c) 2025 Beijing Volcano Engine Technology Co., Ltd. and/or its affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import uuid

from langchain_core.messages import AIMessage
from langgraph.config import get_stream_writer

from mobile_use_sdk.agent.graph.sse_output import get_writer_think
from mobile_use_sdk.agent.graph.state import MobileUseAgentState
from mobile_use_sdk.agent.llm.llm import LLM
from mobile_use_sdk.agent.prompt.human_prompt import (
    build_messages_with_screenshots,
    get_human_message_without_screenshot,
)
from mobile_use_sdk.agent.tools.action_parser import ActionParser

logger = logging.getLogger(__name__)


def model_node(llm: LLM):
    """åˆ›å»ºæ¨¡å‹èŠ‚ç‚¹çš„é—­åŒ…å·¥å‚å‡½æ•°.

    Args:
        llm: è¯­è¨€æ¨¡å‹å®ä¾‹

    Returns:
        model_nodeå‡½æ•°
    """

    async def model_node_impl(state: MobileUseAgentState) -> MobileUseAgentState:
        """å¤§æ¨¡å‹èŠ‚ç‚¹ - æ ¹æ®å½“å‰çŠ¶æ€è®¡ç®—è¡ŒåŠ¨å’Œå·¥å…·è°ƒç”¨.

        Args:
            state: å½“å‰AgentçŠ¶æ€

        Returns:
            MobileUseAgentState: æ›´æ–°åçš„çŠ¶æ€ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
        """
        iteration_count = state.get("iteration_count", 0)
        is_stream = state.get("is_stream")
        messages = list(state.get("messages", []))

        # ğŸš€ åˆ›å»ºçº¯æ–‡æœ¬æ¶ˆæ¯
        text_human_message = get_human_message_without_screenshot(state)

        # ğŸš€ å¦‚æœæœ‰å½“å‰æˆªå›¾ï¼Œä»æˆªå›¾ä¸­è·å–IDå¹¶å…³è”åˆ°æ¶ˆæ¯
        current_screenshot = state.get("current_screenshot")
        if current_screenshot:
            screenshot_id = current_screenshot.get("id")

            # åœ¨æ¶ˆæ¯çš„ additional_kwargs ä¸­å­˜å‚¨æˆªå›¾ID
            text_human_message.additional_kwargs["screenshot_id"] = screenshot_id

        # ğŸš€ æ„å»ºå‘é€ç»™LLMçš„æ¶ˆæ¯åˆ—è¡¨ï¼šåˆ›å»ºæ–°æ•°ç»„å‰¯æœ¬ï¼Œä¸ä¿®æ”¹åŸæ•°ç»„
        temp_messages = [*messages, text_human_message]  # åˆ›å»ºæ–°æ•°ç»„

        # è·å–æˆªå›¾å­—å…¸
        screenshots_dict = state.get("screenshots", {})

        messages_for_llm = build_messages_with_screenshots(
            temp_messages, screenshots_dict, state.get("keep_last_n_screenshots")
        )

        # è°ƒç”¨æ¨¡å‹
        chunk_id, content, summary, tool_call = await llm.async_chat(messages_for_llm, is_stream)

        logger.info(f"content========: {content}")

        if not is_stream:
            # éæµå¼ä¼ è¾“ç›´æ¥è¾“å‡ºå¯¹åº”çš„summary
            sse_writer = get_stream_writer()
            sse_writer(get_writer_think(state, chunk_id, summary))

        # ğŸš€ åˆ›å»ºAIæ¶ˆæ¯
        ai_message = AIMessage(role="assistant", content=content)

        # ğŸš€ åˆ›å»ºæ–°çš„messagesæ•°ç»„ç”¨äºä¿å­˜åˆ°state
        updated_messages = [*messages, text_human_message, ai_message]

        # è§£æå·¥å…·è°ƒç”¨
        parsed_tool_call = ActionParser.parse_tool_call_string(tool_call)
        if parsed_tool_call is None:
            parsed_tool_call = {
                "name": "error_action",
                "arguments": {"content": content},
            }

        # åˆ›å»ºæ–°çš„å·¥å…·è°ƒç”¨è®°å½•
        tool_calls = state.get("tool_calls", [])
        tool_call_id = str(uuid.uuid4())
        tool_calls.append(
            {
                "tool_call": parsed_tool_call,
                "tool_output": None,
                "id": tool_call_id,
                "tool_name": parsed_tool_call.get("name", ""),
            }
        )

        # æ„å»ºè¿”å›çš„çŠ¶æ€
        return {
            "tool_calls": tool_calls,
            "current_tool_call_id": tool_call_id,
            "iteration_count": iteration_count + 1,
            "chunk_id": chunk_id,
            "messages": updated_messages,
            "last_tool_output": None,  # æ¸…é™¤ä¸Šæ¬¡çš„å·¥å…·è¾“å‡º
        }

    return model_node_impl
