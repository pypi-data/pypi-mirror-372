from transformers import pipeline, AutoTokenizer
import re
class RefusalClassifier:
    """
    Classifies whether a model's response constitutes a refusal.
    """
    def __init__(self, model_id="NousResearch/Minos-v1"):
        """
        Initializes the classifier pipeline.

        Args:
            model_id (str): The model to use for classification.
        """
        # Using text-classification pipeline for simplicity.
        # You might need a more specific setup depending on the model.
        self.classifier = pipeline("text-classification", model=model_id)

    def classify(self, response_text):
        """
        Classifies the given response text.

        Args:
            response_text (str): The text generated by the large language model.

        Returns:
            dict: The classification result (e.g., {'label': 'REFUSAL', 'score': 0.98}).
                  The exact labels depend on the classification model.
        """
        # This assumes the model has labels like 'REFUSAL' and 'NOT_REFUSAL'.
        # You may need to adapt this based on the actual model's output.
        return self.classifier(response_text)
# SpaimClassifier and SpaimDetector would be defined here as well,
# likely with different models and logic.


class SpaimDetector:
    """
    Detects if a prompt injection contains special control tokens from a model's
    chat template, which indicates a potential injection attack (Spaim).
    """
    def __init__(self, model_id):
        """
        Initializes the detector by extracting special tokens from the chat template.

        Args:
            model_id (str): The model identifier to load the correct tokenizer and template.
        """
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        if not self.tokenizer.chat_template:
            raise ValueError(f"The tokenizer for '{model_id}' does not have a chat_template.")

        # Find all unique special tokens like <|start|>, <|message|>, etc. from the template
        special_tokens_list = re.findall(r'(<\|.*?\|>)', self.tokenizer.chat_template)
        self.special_tokens = set(special_tokens_list)

        if not self.special_tokens:
            raise ValueError(f"Could not extract any special tokens in the format <|...|> from the chat template for '{model_id}'.")

    def detect(self, injection_text: str) -> bool:
        """
        Detects if any of the model's special tokens are present in the input text.

        Args:
            injection_text (str): The user-provided text to check for spaim.

        Returns:
            bool: True if a special token is found, False otherwise.
        """
        for token in self.special_tokens:
            if token in injection_text:
                return True
        return False


class SpaimClassifier:
    # This class can be developed further, perhaps using a more advanced model
    # to classify the *intent* of an injection, rather than just detecting tokens.
    pass