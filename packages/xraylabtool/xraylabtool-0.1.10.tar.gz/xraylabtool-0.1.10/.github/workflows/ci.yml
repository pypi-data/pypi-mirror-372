name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run weekly on Sundays at 6 AM UTC
    - cron: '0 6 * * 0'
  workflow_call:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHONUNBUFFERED: 1
  PYTHONDONTWRITEBYTECODE: 1
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_NO_PYTHON_VERSION_WARNING: 1

jobs:
  lint:
    name: Code Quality & Linting
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'

    - name: Cache pre-commit hooks
      uses: actions/cache@v4
      with:
        path: ~/.cache/pre-commit
        key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[lint]
        pip install pre-commit

    - name: Run pre-commit hooks
      run: |
        pre-commit run --all-files || echo "Pre-commit found issues - please run locally to fix"
      continue-on-error: true

    - name: Check code formatting with black
      run: |
        black --check --diff xraylabtool/ tests/

    - name: Lint with flake8
      run: |
        # Critical errors that should fail the build
        flake8 xraylabtool/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
        # Full linting check (allow to continue on non-critical errors)
        flake8 xraylabtool/ tests/ --count --max-complexity=10 --max-line-length=88 --statistics || echo "Non-critical linting issues found"
      continue-on-error: true

    - name: Type check with mypy
      run: |
        mypy xraylabtool/ || echo "Type checking completed with warnings"

    - name: Security check with bandit
      run: |
        pip install bandit
        bandit -r xraylabtool/ -f json -o bandit-report.json || true
        bandit -r xraylabtool/
      continue-on-error: true

    - name: Check dependencies with safety
      run: |
        pip install safety
        safety check --json --output safety-report.json || true
        safety check
      continue-on-error: true

  test:
    name: Test Suite
    needs: lint
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.12', '3.13']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[test]

    - name: Run tests with pytest
      shell: bash
      run: pytest tests/ -v --cov=xraylabtool --cov-report=xml --cov-report=html --cov-report=term-missing --junit-xml=pytest-results.xml --benchmark-skip

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: |
          pytest-results.xml
          htmlcov/
          .coverage

    - name: Upload coverage to Codecov
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12'
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
      continue-on-error: true

  benchmark:
    name: Performance Benchmarks
    needs: lint
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Run benchmarks
      run: |
        pytest tests/ -v --benchmark-only --benchmark-json=benchmark-results.json

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmark-results.json

  build:
    name: Build Distribution
    needs: [lint, test]
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'

    - name: Install build tools
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: Build package
      run: |
        python -m build

    - name: Check package integrity
      run: |
        python -m twine check dist/*

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: dist
        path: dist/

  integration:
    name: Integration Tests
    needs: build
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: dist
        path: dist/

    - name: Install from wheel
      run: |
        python -m pip install --upgrade pip
        pip install dist/*.whl

    - name: Test CLI functionality
      shell: bash
      run: |
        xraylabtool --version
        xraylabtool calc Si -e 10.0 -d 2.33 --fields energy_kev,wavelength_angstrom

    - name: Test package import
      shell: bash
      run: |
        python -c "
        import xraylabtool
        from xraylabtool import calculate_xray_properties
        print('Package import successful')
        "

  status-check:
    name: Status Check
    if: always()
    needs: [lint, test, benchmark, build, integration]
    runs-on: ubuntu-latest

    steps:
    - name: Check job statuses
      run: |
        echo "Lint: ${{ needs.lint.result }}"
        echo "Test: ${{ needs.test.result }}"
        echo "Benchmark: ${{ needs.benchmark.result }}"
        echo "Build: ${{ needs.build.result }}"
        echo "Integration: ${{ needs.integration.result }}"

        if [[ "${{ needs.lint.result }}" == "failure" || \
              "${{ needs.test.result }}" == "failure" || \
              "${{ needs.build.result }}" == "failure" || \
              "${{ needs.integration.result }}" == "failure" ]]; then
          echo "❌ Required checks failed"
          exit 1
        else
          echo "✅ All required checks passed"
        fi
