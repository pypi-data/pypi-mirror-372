{
  "accelerator_model_name": [
    "Intel Gaudi2",
    "N/A",
    "NVIDIA A100 - PCIe - 80 GB",
    "NVIDIA A100-PCIe-80GB",
    "NVIDIA A100-SXM-40GB",
    "NVIDIA A10G",
    "NVIDIA A30",
    "NVIDIA H100-PCIe-80GB",
    "NVIDIA H100-SXM-80GB",
    "NVIDIA H100-SXM5-80GB",
    "NVIDIA H100-SXM5-96GB",
    "NVIDIA L4",
    "NVIDIA L40",
    "NVIDIA L40S",
    "NVIDIA RTX A5000",
    "TPU-v5e"
  ],
  "accelerators_count": [
    0,
    2,
    4,
    6,
    8,
    10,
    16,
    32,
    64,
    72,
    128,
    256,
    384,
    512,
    768,
    1024,
    2048,
    3472,
    3584,
    4096,
    6144,
    8192,
    10240,
    10752
  ],
  "availability": [
    "Available Cloud",
    "Available in cloud",
    "Available on premise",
    "Available on-premise",
    "available",
    "available on premise",
    "cloud",
    "onprem"
  ],
  "benchmark_branch": [
    "main"
  ],
  "benchmark_name": [
    "mlperf-training"
  ],
  "benchmark_version": [
    "3.1"
  ],
  "benchmark_version_alias": [
    "3.1"
  ],
  "code_url": [
    "https://github.com/mlcommons/training_results_v3.1/blob/master/ASUSTeK/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Ailiverse/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Azure+NVIDIA/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Azure/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/CTuning/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Clemson University Research Computing and Data/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Dell/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Fujitsu/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/GigaComputing/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Google/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Intel-HabanaLabs/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Intel/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Krai/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Lenovo/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/NVIDIA+CoreWeave/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/NVIDIA/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Quanta_Cloud_Technology/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Supermicro-RedHat/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/Supermicro/benchmarks",
    "https://github.com/mlcommons/training_results_v3.1/blob/master/xFusion/benchmarks"
  ],
  "datetime_last_commit": [
    "2025/01/14_17:16:29"
  ],
  "debug_uid": [
    "003a8a48430c45f1",
    "006bcea6a2e144fb",
    "0166dacb72c640b7",
    "02b8e75b118d4ad5",
    "0430aeebd14d4efc",
    "0541f16f84494474",
    "0639aa7fb67d4e65",
    "09be7f0e9aca4e90",
    "0b9a4055d52247b6",
    "0fc32bdfe84049f3",
    "1098f017a9944365",
    "11c4d35f613147de",
    "167f7be34ee0421c",
    "18c962439c454880",
    "19a55e558cb64413",
    "1a1086d5bdd94fb0",
    "1d51e32c6ea54067",
    "1dc284231ad34139",
    "1e0a55552c35404a",
    "1f0f086b1e904b56",
    "1f2bb9d1b5ae4961",
    "1fb30cb296ae4374",
    "202bf57f63ab44ba",
    "217f68039b3b4990",
    "23a6430e61ed4af8",
    "2477be76ef514675",
    "2681ac538ba54fff",
    "27dcee698a364e92",
    "29404e4ffcd3410a",
    "2a88e00a84904691",
    "2afc16a5684a417d",
    "2dd972b129ae48b6",
    "2e994598044647d6",
    "2eded7ee2e9c4665",
    "3038b54421b14948",
    "30aa4a144cf64eb4",
    "31e0e906b591436c",
    "3380426359884264",
    "3498681f92cd4127",
    "34fe6bbb390b4cba",
    "36c7f13ad53f4403",
    "3732024601cb409d",
    "3b58a6a40d0c4f11",
    "3b8f8dfe65d54407",
    "3d4657a5f9d84073",
    "3ed94bcc0b8f4b18",
    "3fffd75fc6714016",
    "4392cd2958834f1c",
    "46a0009098844f8c",
    "4907b27b555f4095",
    "49695378e3f84a2e",
    "4b02f09bacff4b78",
    "4b56e00cde8b44bc",
    "4c0fc97ac540482f",
    "4d0074a2728c4e39",
    "4dcae18739c84490",
    "4e842c0e698341e6",
    "4f00b1d7a2bf4440",
    "4fb982d933be4a19",
    "4fe5bf6481034546",
    "50e7a1df57874f60",
    "513f6a1bfc384a61",
    "55dddc65bf224076",
    "56b7a334c34d4ed6",
    "5759600981724bef",
    "576f29a5c0d74515",
    "57bb5da0d52b4dd6",
    "58a18373da894d76",
    "58d787ab21614636",
    "599dd243b1054ef5",
    "5a51602113954807",
    "5ad5fddb22b043b1",
    "5ffe5b0a2d714d77",
    "60b0cb4a531148b1",
    "612a89f5731f4be6",
    "627a7677048f4a49",
    "631f0867ac0042df",
    "638363cf3e0a4235",
    "63a06caca2574a08",
    "654ad6565d704ad7",
    "6a40d73a7caa4e42",
    "6ac5a639613d4b85",
    "6b95390f74c54553",
    "6ba6cf00b1944eaf",
    "6d98115e7fb74be7",
    "6e0904ae23064b9f",
    "6f8b228d85b641a8",
    "6fab8dde4e0145d8",
    "7199e1a78e0a4b4c",
    "720da28387f74a58",
    "7307f09abeca43b0",
    "73611ab22802467e",
    "749f022d81e0412f",
    "758269d5d3d84c10",
    "773506977ae2464d",
    "773b6ff56f344c39",
    "78e918e08b2443d6",
    "7960489d29694d16",
    "7975fd43b4524cea",
    "7988c46e41794434",
    "7cf2177e7bac4d94",
    "7f07eb20fd8f4b4e",
    "815cfe8a268141f8",
    "81a11df672bf4ab1",
    "820d6b1ee2224ebe",
    "82af915dd7f846d1",
    "83f49ea4b1ef47f2",
    "87925804475743b9",
    "8bb00e3753404420",
    "8d8fe25cbff04f2f",
    "8e57be3ec5f44e08",
    "8f2a8473ffed4740",
    "9145cf777bbf473f",
    "9238a065ca8042dd",
    "94f01ad7fd1a4a25",
    "959faa41392148d9",
    "96414dbb21ed41dd",
    "97a8cef9db2c42c3",
    "9919168d6bd24850",
    "9a995bb4e78c47eb",
    "9af1e786b29642e5",
    "9be9859941f24306",
    "9f059866514946fb",
    "9fb5a860f297485d",
    "a12aa4ae9bbf4c8e",
    "a33f02641abe4b28",
    "a69132ef7b93404b",
    "a8d590bc489244f0",
    "a912510f247146bd",
    "a97d06c97ae84b71",
    "aa5ec80311144371",
    "aafeb1f7e3f74a38",
    "abff375641de4a38",
    "ac2f4841848a49c1",
    "ac832d85ad374af9",
    "ae4296ac91e34a87",
    "aeeaf22a2a784ef0",
    "af87114a96f54f03",
    "b0392563d91b4d5c",
    "b050eb1c8690475b",
    "b0ef94497ca34139",
    "b264488a8e904d21",
    "b30697d9fafc48d1",
    "b3a97f8eebc14db3",
    "b55b3472f5174c38",
    "b60594a8b4834249",
    "b7920919cb594f38",
    "b9018d846adc4df4",
    "bb0f521bd7504d2f",
    "bd25a3854aaf41de",
    "bd51cdd0396642ba",
    "bddf4c4bdce3426b",
    "c13f917632c641da",
    "c19dad23114f45e3",
    "c26780b6a5e24be1",
    "c39906bd6ae64f1e",
    "c422e9936cf84401",
    "c42b6c42e1cb4029",
    "c5ed803b2e29436a",
    "c6850659159e49a0",
    "c8e1f06713314643",
    "ca5256ff9957428a",
    "ca811addea7540f7",
    "cb52dc7c7ce8428e",
    "cc09284f09464de5",
    "cc197ab846614e83",
    "cdc7159151a043aa",
    "ceadfa599116468d",
    "ceb54132c07a4051",
    "d157ee28e3e444b9",
    "d1ac00710d334d3b",
    "d3154c1c3b21493c",
    "d35a393ebb084a67",
    "d46dfc509201480a",
    "d4fbedf83f9d485d",
    "d5432f8756c34578",
    "d60471a482b344ba",
    "d82365816d8d4b69",
    "d8a0131caaf941e1",
    "db3bdcb698674575",
    "db8a83d8cb5541a2",
    "dc2fde18156c45a8",
    "dc4ad20fd3a44f8b",
    "ddb76f5cc6714153",
    "ddff5635f9bf4d63",
    "e0963048f71b40d5",
    "e0cc1fadca714227",
    "e28c31b81de1415b",
    "e3d011cfe10047d6",
    "e632ef6bccb248e5",
    "e6aec5cb227d4cce",
    "e7b379193698401a",
    "e8138f1a6ee14ae2",
    "ea6b5402703a4847",
    "ebd4e14ed3e84717",
    "ec869731fc9747c9",
    "ee36ac0ab46240bc",
    "ee9016886727447e",
    "eeeb5175deb145e8",
    "f12a288a62054fb9",
    "f3b373fc124a4a9b",
    "f52576cf5bc24964",
    "f567e6205e674d01",
    "f67c55424ad54725",
    "f7a81bdcbd0549b0",
    "fa4b6d6de8b54d56",
    "fb0d5e88073b469a",
    "fc5b82542e1a4c14",
    "fdf3e0219e96441b"
  ],
  "details_url": [
    "https://github.com/mlcommons/training_results_v3.1/blob/main/ASUSTeK/systems/ESC-N8-E11.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/ASUSTeK/systems/ESC8000-E11-8xH100-PCIE-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Ailiverse/systems/8xA100_40GB_open.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Azure+NVIDIA/systems/ND_H100_v5_n1344_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Azure/systems/ND_H100_v5_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Azure/systems/ND_H100_v5_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/CTuning/systems/a10x2-mxnet_22.08.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Clemson University Research Computing and Data/systems/16xR750-2xA100-PCIe-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Clemson University Research Computing and Data/systems/8xR750-2xA100-PCIe-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Dell/systems/2xXE8640x4H100-SXM-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Dell/systems/2xXE9680x8H100-SXM-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Dell/systems/XE8640x4H100-SXM-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Dell/systems/XE9640x4H100-SXM-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Dell/systems/XE9680x8H100-SXM-80GB.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Fujitsu/systems/primergy-cdi-A100x10-mxnet-ngc23.09.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Fujitsu/systems/primergy-cdi-A100x10-pytorch-ngc23.09_gbs320.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Fujitsu/systems/primergy-cdi-A100x2-mxnet-ngc23.09.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Fujitsu/systems/primergy-cdi-A100x4-mxnet-ngc23.09.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Fujitsu/systems/primergy-cdi-A100x8-mxnet-ngc23.04.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Fujitsu/systems/primergy-cdi-A100x8-mxnet-ngc23.09.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Fujitsu/systems/primergy-cdi-A100x8-pytorch-ngc23.09_gbs320.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/GigaComputing/systems/G593-ZD2_hugectr.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/GigaComputing/systems/G593-ZD2_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/GigaComputing/systems/G593-ZD2_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Google/systems/cloud-tpu-v5e-4096-PAX.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel-HabanaLabs/systems/HLS-Gaudi2-N32-PT.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel-HabanaLabs/systems/HLS-Gaudi2-N48-PT.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel-HabanaLabs/systems/HLS-Gaudi2-N8-PT.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel-HabanaLabs/systems/HLS-Gaudi2-PT.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel-HabanaLabs/systems/HLS-Gaudi2-TF.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel/systems/16-nodes-SPR-pytorch-open.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel/systems/16-nodes-SPR-pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel/systems/4-nodes-SPR-pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Intel/systems/8-nodes-SPR-pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Krai/systems/7920T_2xA5000_hdd.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Krai/systems/7920T_2xA5000_mxnet22.04.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Krai/systems/7920T_2xA5000_mxnet22.08.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Krai/systems/7920T_2xA5000_mxnet23.08.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Krai/systems/7920T_2xA5000_ssd.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Lenovo/systems/SR675v3-4xH100_SXM5_96GB_700W.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Lenovo/systems/SR675v3-8xH100_PCIe_80GB_350W.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA+CoreWeave/systems/coreweave_hgxh100_n448_ngc23.04_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos-dfw_n1024_ngc23.09_nemo.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos-dfw_n1280_ngc23.09_nemo.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos-dfw_n1344_ngc23.09_nemo.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos-dfw_n512_ngc23.09_nemo.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos-dfw_n768_ngc23.09_nemo.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n128_ngc23.09_nemo_mm.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n16_ngc23.09_merlin_hugectr.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n256_ngc23.09_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n434_ngc23.09_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n48_ngc23.04_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n64_ngc23.04_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n64_ngc23.09_nemo.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n64_ngc23.09_nemo_mm.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n8_ngc23.04_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n8_ngc23.09_merlin_hugectr.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n8_ngc23.09_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n8_ngc23.09_nemo_mm.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n8_ngc23.09_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n96_ngc23.04_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n96_ngc23.09_nemo.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_n9_ngc23.04_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_ngc23.04_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_ngc23.04_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_ngc23.09_merlin_hugectr.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_ngc23.09_mxnet.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/NVIDIA/systems/eos_ngc23.09_pytorch.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Quanta_Cloud_Technology/systems/D54U-3U.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Quanta_Cloud_Technology/systems/D74H-7U.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Supermicro-RedHat/systems/AS-4125GS-TNRT-RedHat-OpenShift.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Supermicro/systems/AS-8125GS-TNHR.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Supermicro/systems/SYS-421GU-TNXR.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Supermicro/systems/SYS-681E-TR.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/Supermicro/systems/SYS-821GE-TNHR.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/2288H_V7x6xL4.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/G5500V7x10L40.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/G5500V7x10xA30.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/G5500V7x10xL40.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/G5500V7x8L40.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/G5500V7x8xA30.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/G5500V7x8xL40.json",
    "https://github.com/mlcommons/training_results_v3.1/blob/main/xFusion/systems/G5500V7x8xL40S.json"
  ],
  "division": [
    "closed",
    "open"
  ],
  "framework": [
    "",
    "CUDA 12.0",
    "MXNet NVIDIA Release 23.04",
    "MXNet NVIDIA Release 23.09, PyTorch NVIDIA Release 23.09, HugeCTR NVIDIA Release 23.09",
    "MxNet NVIDIA Release 22.04",
    "MxNet NVIDIA Release 22.08",
    "MxNet NVIDIA Release 23.04",
    "MxNet NVIDIA Release 23.08",
    "MxNet NVIDIA Release 23.09",
    "Mxnet",
    "NGC MLPerf Training v3.1",
    "NGC MXNet 23.04 ,  NGC PyTorch 23.04",
    "NGC MXNet 23.04 , NGC PyTorch 23.04",
    "NGC MXNet 23.04 , NGC PyTorch 23.09",
    "NGC MXNet 23.09 , NGC PyTorch 22.09",
    "NGC MXNet 23.09 , NGC PyTorch 23.09",
    "NGC MXNet 23.09 , NGC PyTorch 23.09 , NGC HugeCTR 23.09",
    "NGC MXNet 23.09, NGC PyTorch 23.09, NGC HugeCTR 23.09",
    "NGC MXNet 23.09, NGC Pytorch 23.09, NGC HugeCTR 23.09",
    "NVIDIA Merlin HugeCTR Release 23.09",
    "NVIDIA NeMo Framework Release 23.09",
    "NVIDIA NeMo Multimodal Release 23.09 (EA)",
    "NVIDIA PyTorch/MxNet",
    "NVIDIA Release 23.04 MxNet, 23.09 pytorch",
    "PAX",
    "PyTorch",
    "PyTorch 2.0.1a0",
    "PyTorch NVIDIA Release 22.08",
    "PyTorch NVIDIA Release 22.09",
    "PyTorch NVIDIA Release 23.04",
    "PyTorch NVIDIA Release 23.09",
    "PyTorch v1.11.0 + optimizations",
    "Pytorch",
    "TensorFlow 2.13.0",
    "hugectr",
    "mxnet NVIDIA Release 23.04",
    "mxnet NVIDIA Release 23.09",
    "pytorch NVIDIA Release 23.09"
  ],
  "host_processor_model_name": [
    "AMD EPYC 7B13",
    "AMD EPYC 7R32",
    "AMD EPYC 9554 64-Core Processor",
    "AMD EPYC 9654",
    "AMD EPYC 9654 96-Core Processor",
    "Intel(R) Xeon(R) CPU @ 2.20GHz",
    "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "Intel(R) Xeon(R) Gold 6430",
    "Intel(R) Xeon(R) Platinum 6458Q",
    "Intel(R) Xeon(R) Platinum 8358",
    "Intel(R) Xeon(R) Platinum 8380",
    "Intel(R) Xeon(R) Platinum 8458P",
    "Intel(R) Xeon(R) Platinum 8460Y+",
    "Intel(R) Xeon(R) Platinum 8462Y+",
    "Intel(R) Xeon(R) Platinum 8468",
    "Intel(R) Xeon(R) Platinum 8470",
    "Intel(R) Xeon(R) Platinum 8470Q",
    "Intel(R) Xeon(R) Platinum 8480+",
    "Intel(R) Xeon(R) Platinum 8480+ @ 2.00GHz",
    "Intel(R) Xeon(R) Platinum 8480C",
    "Intel(R) Xeon(R) Platinum 8490H 60-Core Processor",
    "Intel(R)Xeon(R)Platinum 8490H"
  ],
  "host_processors_count": [
    1,
    2,
    4,
    8,
    16,
    18,
    32,
    64,
    96,
    128,
    192,
    256,
    512,
    868,
    896,
    1024,
    1536,
    2048,
    2560,
    2688
  ],
  "mlperf_training_model": [
    "bert",
    "dlrm_dcnv2",
    "gpt3",
    "maskrcnn",
    "resnet",
    "rnnt",
    "ssd",
    "stable_diffusion",
    "unet3d"
  ],
  "notes": [
    "",
    "700W",
    "GPU TDP:700W;N/A",
    "GPUs are installed in an external PCI box.",
    "GPUs are installed in an external PCI box. This systems corresponds to preview system 3.0-2086.",
    "GPUs are installed in an external PCI box. This systems corresponds to preview system 3.0-2087.",
    "NVIDIA H100-PCIe-80GB",
    "PAXML 20230904 wheels. ",
    "TDP=350W per GPU",
    "TDP=350W per GPU, air cooling ",
    "TDP=700W per GPU, L2A cooling ",
    "This result was obtained in partnership between Azure AI Production and NVIDIA",
    "We perform LAMB over a fused parameter instead of individual parameters (one fused param for each datatype and weight_decay value). No change in model or any other computation compared to closed division"
  ],
  "number_of_nodes": [
    1,
    2,
    4,
    8,
    9,
    16,
    32,
    48,
    64,
    96,
    128,
    256,
    434,
    448,
    512,
    768,
    1024,
    1280,
    1344
  ],
  "result": [
    0.119275,
    0.18298333333333336,
    0.7726755208333334,
    0.89813125,
    0.919282663558,
    1.0266707408386189,
    1.3852501895256042,
    1.4656666666666667,
    1.6612163611422874,
    1.893353125,
    2.46645393939394,
    2.5047503117144294,
    2.9329800505050505,
    3.4424312500000003,
    3.9171666666666667,
    3.9274655753968246,
    3.9347661371527773,
    3.9521607142857142,
    4.0085,
    4.070316666666667,
    4.073520300729754,
    4.093894345238095,
    4.230547916666667,
    4.264355555555556,
    4.282410201446281,
    4.379996524835216,
    4.86575,
    5.364558333333333,
    5.375974972249749,
    5.378320935172327,
    5.398863949388485,
    5.4298618481028225,
    5.466285416666667,
    5.46880625,
    5.5088,
    5.785054166666667,
    5.95922791087963,
    6.027416666666667,
    6.141505555555557,
    7.547959361488186,
    7.858050948166877,
    8.574483333333333,
    9.112610416666666,
    10.024000000000001,
    10.063,
    11.010485416666667,
    11.190314583333333,
    11.486908333333332,
    11.700723897023638,
    11.749683861340676,
    11.849742283163264,
    13.124232819461456,
    13.174798834375002,
    13.194591666666668,
    13.195999360272316,
    13.20121914270833,
    13.212293559638542,
    13.219327276767185,
    13.221827893203125,
    13.270597916666668,
    13.301993533019797,
    13.397950194402547,
    13.410731724484666,
    13.417856130383777,
    13.446660599966481,
    13.554681545165073,
    13.554759651416123,
    13.579123222724988,
    13.818574672364674,
    13.930637814407815,
    14.11911875,
    15.919044279489572,
    16.231664767331434,
    16.25733979107312,
    16.42227971988796,
    16.663795833333335,
    16.686216666666667,
    16.824370833333333,
    16.832140472078294,
    17.077590008613264,
    17.98853958333333,
    18.51311666666667,
    19.179827777777774,
    19.257227777777775,
    19.30883888888889,
    19.32835,
    19.390222222222224,
    19.394116666666665,
    19.6394,
    19.835194444444443,
    19.899127777777778,
    20.026953203125,
    20.205054166666663,
    20.66628942931875,
    20.949703288084464,
    20.993052658905274,
    20.995994605391903,
    21.134843274428967,
    21.86535402714932,
    22.74248450231481,
    22.754632748449804,
    23.381451661918327,
    24.302171057655595,
    24.570686770571477,
    25.237708878968252,
    26.228162393619794,
    26.37116887513021,
    26.397814583333336,
    26.533464583333334,
    26.567755555555554,
    26.577495149146355,
    26.691777777777776,
    26.923871902128372,
    27.533691869085946,
    27.607797670168726,
    28.05226752136752,
    28.12641791907514,
    28.165666666666667,
    28.98447777777778,
    29.862256961622254,
    29.988138888888887,
    31.060012500000003,
    31.387112500000004,
    31.50324583333333,
    33.68078901287554,
    35.06298888888889,
    35.76064791666667,
    35.77560833333333,
    35.9591,
    35.968716666666666,
    36.16931111111111,
    36.20965555555555,
    36.29745555555555,
    36.30103888888889,
    36.309733333333334,
    36.319449999999996,
    37.768805773181064,
    38.42203888888889,
    38.662616666666665,
    38.83781111111111,
    38.96752777777778,
    39.101001808666666,
    39.958677895853654,
    40.33741666666667,
    40.62638333333333,
    41.39916458333333,
    42.72475567837392,
    42.79557291666667,
    44.68485,
    44.92458333333334,
    45.128638888888894,
    46.7802625,
    46.9195703792286,
    47.061735416666664,
    47.20586156862745,
    47.929222916666674,
    48.352677777777785,
    49.339247916666665,
    50.51321111111111,
    51.405264583333334,
    51.8248375,
    53.73291041666666,
    53.921850000000006,
    54.271812499999996,
    57.82265,
    58.30195,
    58.57912222222222,
    58.73116111111111,
    58.93611666666666,
    62.20019444444444,
    62.908141666666666,
    64.37337777777778,
    64.80329444444443,
    66.66386666666666,
    70.06141614583332,
    71.62287222222221,
    71.83005,
    72.17468333333333,
    73.3137111111111,
    74.47758125000001,
    77.66543888888889,
    79.7887,
    87.61505555555556,
    88.10295625,
    88.56049550671551,
    90.07806666666666,
    102.70098333333333,
    108.02093888888889,
    112.91945555555556,
    115.50712777777778,
    115.70072222222223,
    128.58215555555554,
    134.00750416666665,
    137.99796666666666,
    153.58133333333333,
    170.37841666666668,
    175.96930555555556,
    183.56744791666665,
    200.32544444444443,
    223.90986666666666,
    227.13806250000002,
    232.40458333333333,
    271.19305,
    284.03768888888885,
    319.09158333333335,
    343.08845625,
    366.18525,
    399.5917666666667,
    583.9959722222221
  ],
  "submitter": [
    "ASUSTeK",
    "Ailiverse",
    "Azure",
    "Azure+NVIDIA",
    "CTuning",
    "Clemson University Research Computing and Data",
    "Dell",
    "Fujitsu",
    "GigaComputing",
    "Google",
    "Intel",
    "Intel-HabanaLabs",
    "Krai",
    "Lenovo",
    "NVIDIA",
    "NVIDIA+CoreWeave",
    "Quanta_Cloud_Technology",
    "Supermicro",
    "Supermicro-RedHat",
    "xFusion"
  ],
  "system": [
    "16 xR750 - 2 xA100 - PCIe - 80 GB",
    "16-nodes-SPR-pytorch",
    "16-nodes-SPR-pytorch-open",
    "2xXE8640x4H100-SXM-80GB",
    "2xXE9680x8H100-SXM-80GB",
    "4-nodes-SPR-pytorch",
    "8 xR750 - 2 xA100 - PCIe - 80 GB",
    "8-nodes-SPR-pytorch",
    "AS-4125GS-TNRT-RedHat-OpenShift",
    "AS-8125GS-TNHR",
    "AWS Cloud instance g5.12xlarge",
    "Araucana",
    "D54U-3U",
    "D74H-7U",
    "Dell Precision 7920 Tower with 2x A5000 and 1TB SSD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 and 4TB HDD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 using MxNet 22.04 and 0.25TB SSD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 using MxNet 22.08 and 0.25TB SSD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 using MxNet 23.08 and 0.25TB SSD for the dataset",
    "ESC-N8-E11",
    "ESC8000-E11-8xH100-PCIE-80GB",
    "Eos-dfw_n1024",
    "Eos-dfw_n1280",
    "Eos-dfw_n1344",
    "Eos-dfw_n512",
    "Eos-dfw_n768",
    "Eos_n1",
    "Eos_n128",
    "Eos_n16",
    "Eos_n256",
    "Eos_n434",
    "Eos_n48",
    "Eos_n64",
    "Eos_n8",
    "Eos_n9",
    "Eos_n96",
    "GIGABYTE G593-ZD2",
    "HLS-Gaudi2-N32-PT",
    "HLS-Gaudi2-N48-PT",
    "HLS-Gaudi2-N8-PT",
    "HLS-Gaudi2-PT",
    "HLS-Gaudi2-TF",
    "Lenovo ThinkSystem SR675 V3 Server with 4x 96GB SXM5 H100",
    "Lenovo ThinkSystem SR675 V3 Server with 8x 80GB PCIe H100",
    "ND_H100_v5",
    "ND_H100_v5 x1344",
    "PRIMERGY-CDI-A100x10-mxnet",
    "PRIMERGY-CDI-A100x10-pytorch",
    "PRIMERGY-CDI-A100x2-mxnet",
    "PRIMERGY-CDI-A100x4-mxnet",
    "PRIMERGY-CDI-A100x8-mxnet",
    "PRIMERGY-CDI-A100x8-pytorch",
    "SYS-421GU-TNXR",
    "SYS-681E-TR",
    "SYS-821GE-TNHR",
    "XE8640x4H100-SXM-80GB",
    "XE9640x4H100-SXM-80GB",
    "XE9680x8H100-SXM-80GB",
    "coreweave_hgxh100_n448_ngc23.04_mxnet",
    "tpu-v5e-4096",
    "xFusion FusionServer 2288H V7(6x NVIDIA L4)",
    "xFusion FusionServer G5500 V7(10x NVIDIA A30)",
    "xFusion FusionServer G5500 V7(10x NVIDIA L40)",
    "xFusion FusionServer G5500 V7(8x NVIDIA A30)",
    "xFusion FusionServer G5500 V7(8x NVIDIA L40)",
    "xFusion FusionServer G5500 V7(8x NVIDIA L40S)"
  ],
  "system.accelerator_frequency": [
    "",
    "1.4 GHz",
    "1.4GHz",
    "1170 MHz (boost 1695 MHz)",
    "1410MHz",
    "1710.000000 MHz",
    "1755 MHz",
    "1800MHz",
    "1980 MHz",
    "1980MHz",
    "2040MHz",
    "2490MHz",
    "2520MHz"
  ],
  "system.accelerator_host_interconnect": [
    "",
    "2x PCIe Gen 4",
    "4x PCIe 4.0 x16",
    "PCIe 4.0x16",
    "PCIe 5.0 x16",
    "PCIe 5.0x16",
    "PCIe 5.0x8",
    "SXM5"
  ],
  "system.accelerator_interconnect": [
    "",
    "24x 100Gb/s Ethernet",
    "NVIDIA NVLink",
    "NVLINK 3.0",
    "NVLINK 4.0",
    "NVLINK 4.0, NVSWITCH 3.0 900GB/s",
    "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "NVLink",
    "NVLink Gen4 900GB/s",
    "PCIe 5.0",
    "PCIe Gen4: 64 GB / s",
    "PCIe Gen5",
    "PCIe gen4 x16",
    "PCIe, Gen5"
  ],
  "system.accelerator_interconnect_topology": [
    "",
    "10x L3 Fat Tree",
    "N/A"
  ],
  "system.accelerator_memory_capacity": [
    "",
    "16GB",
    "22.056640625 GB",
    "24 GB",
    "24 GiB",
    "2x 24 GB",
    "48 GB",
    "80 GB",
    "80G",
    "80GB",
    "96 GB",
    "N/A"
  ],
  "system.accelerator_memory_configuration": [
    "",
    "GDDR6",
    "HBM2",
    "HBM2E",
    "HBM2e",
    "HBM3"
  ],
  "system.accelerator_model_name": [
    "Intel Gaudi2",
    "N/A",
    "NVIDIA A100 - PCIe - 80 GB",
    "NVIDIA A100-PCIe-80GB",
    "NVIDIA A100-SXM-40GB",
    "NVIDIA A10G",
    "NVIDIA A30",
    "NVIDIA H100-PCIe-80GB",
    "NVIDIA H100-SXM-80GB",
    "NVIDIA H100-SXM5-80GB",
    "NVIDIA H100-SXM5-96GB",
    "NVIDIA L4",
    "NVIDIA L40",
    "NVIDIA L40S",
    "NVIDIA RTX A5000",
    "TPU-v5e"
  ],
  "system.accelerator_on-chip_memories": [
    "",
    "6",
    "N/A"
  ],
  "system.accelerators_per_node": [
    "0",
    "10",
    "2",
    "4",
    "6",
    "8"
  ],
  "system.cooling": [
    "",
    "Air",
    "Air-cooled",
    "L2A",
    "air"
  ],
  "system.division": [
    "closed",
    "open"
  ],
  "system.framework": [
    "",
    "CUDA 12.0",
    "MXNet NVIDIA Release 23.04",
    "MXNet NVIDIA Release 23.09, PyTorch NVIDIA Release 23.09, HugeCTR NVIDIA Release 23.09",
    "MxNet NVIDIA Release 22.04",
    "MxNet NVIDIA Release 22.08",
    "MxNet NVIDIA Release 23.04",
    "MxNet NVIDIA Release 23.08",
    "MxNet NVIDIA Release 23.09",
    "Mxnet",
    "NGC MLPerf Training v3.1",
    "NGC MXNet 23.04 ,  NGC PyTorch 23.04",
    "NGC MXNet 23.04 , NGC PyTorch 23.04",
    "NGC MXNet 23.04 , NGC PyTorch 23.09",
    "NGC MXNet 23.09 , NGC PyTorch 22.09",
    "NGC MXNet 23.09 , NGC PyTorch 23.09",
    "NGC MXNet 23.09 , NGC PyTorch 23.09 , NGC HugeCTR 23.09",
    "NGC MXNet 23.09, NGC PyTorch 23.09, NGC HugeCTR 23.09",
    "NGC MXNet 23.09, NGC Pytorch 23.09, NGC HugeCTR 23.09",
    "NVIDIA Merlin HugeCTR Release 23.09",
    "NVIDIA NeMo Framework Release 23.09",
    "NVIDIA NeMo Multimodal Release 23.09 (EA)",
    "NVIDIA PyTorch/MxNet",
    "NVIDIA Release 23.04 MxNet, 23.09 pytorch",
    "PAX",
    "PyTorch",
    "PyTorch 2.0.1a0",
    "PyTorch NVIDIA Release 22.08",
    "PyTorch NVIDIA Release 22.09",
    "PyTorch NVIDIA Release 23.04",
    "PyTorch NVIDIA Release 23.09",
    "PyTorch v1.11.0 + optimizations",
    "Pytorch",
    "TensorFlow 2.13.0",
    "hugectr",
    "mxnet NVIDIA Release 23.04",
    "mxnet NVIDIA Release 23.09",
    "pytorch NVIDIA Release 23.09"
  ],
  "system.hardware": [
    "8 GPUs"
  ],
  "system.host_memory_capacity": [
    "",
    "1 TB",
    "1.0 TB",
    "1.024 TB",
    "1.4 TB",
    "1.5 TB",
    "1.5TB",
    "1.8 TB",
    "1024 GB",
    "1024GB",
    "16 TB",
    "191 GB",
    "1TB",
    "2.0 TB",
    "2.048 TB",
    "256 GB",
    "256GB",
    "2TB",
    "384 GiB",
    "384GB",
    "512 GB",
    "768 GiB",
    "96 GB"
  ],
  "system.host_memory_configuration": [
    "",
    "128 x 128GB DDR5 4800GHz",
    "12x 32 GiB, DDR5 @ 4800 MHz",
    "16 slots / 64GB each / 4800 MT/s per socket",
    "16 x 32GB DDR5 4800 MHz",
    "16 x 32GB DDR5 4800 MT/s",
    "16 x 64GB DDR5 4800 MHz",
    "16x 64GB",
    "16x 64GB DDR5",
    "16x 64GB DDR5 4800MHz",
    "16x64GB",
    "24 x 64GB DDR5 4800 MT/s",
    "24x 32 GiB, DDR5 @ 4800 MHz",
    "24x 64GB DDR5 4800MHz",
    "32 x 32 GB 2Rx4 PC5-4400B-R",
    "32 x 64GB DDR5 4800 MT/s",
    "32x 32GB DDR5",
    "32x 64GB DDR5",
    "6x 16 GB DDR4 2933MHz RDIMM ECC",
    "DDR4-3200"
  ],
  "system.host_network_card_count": [
    "1x Intel X540 10GbE, 9x ConnectX-7 400Gb/s NDR IB",
    "1x Intel X550T 10GbE, 8x ConnectX-7 400Gb/s NDR IB",
    "2 100Gbe + 2 10Gbe"
  ],
  "system.host_networking": [
    "",
    " ConnectX-6 25Gb/s Ethernet",
    "1x Ethernet 100Gb/Sec, 8x NVIDIA Quantum-2 CX7 InfiniBand (400Gb/s)",
    "1x Ethernet 80Gb/Sec, 8x NVIDIA NDR (400Gb/s)",
    "2x Mellanox ConnectX-5 Ex 100Gb/s Ethernet",
    "4x ConnectX-7 IB NDR 400Gb/Sec",
    "8x ConnectX-7 IB NDR 400Gb/Sec",
    "Ethernet",
    "Ethernet, Infiniband",
    "Gig Ethernet",
    "Infiniband",
    "Intel XXV710 25Gb/s Ethernet",
    "Intel(R) Corporation Ethernet Controller E810-C for QSFP",
    "Management: 1 x 25 Gb / Sec Ethernet, Compute: 1 x ConnectX - 6 IB HDR100 100 Gb / Sec",
    "Management: 1x Bluefield-2 DPU Ethernet 100Gb/Sec, Compute: 8x ConnectX-7 InfiniBand NDR 400Gb/Sec",
    "Management: 1x Ethernet 10GB/Sec",
    "NetXtreme BCM5719 Gigabit Ethernet PCIe",
    "Storage+Management: 1x NVIDIA BlueField 2 DPU 100Gb/s, Compute: 8x NVIDIA ConnectX-7 IB NDR 400Gb/s",
    "Storage: 2x ConnectX-7 IB NDR 400Gb/s, Compute: 8x ConnectX-7 IB NDR 400Gb/s, Management: 100Gb/s Ethernet NIC"
  ],
  "system.host_networking_topology": [
    "",
    "Integrated",
    "L3 Fat Tree",
    "N/A"
  ],
  "system.host_processor_caches": [
    "",
    "2.1MB L2 per core, 33.6 MB L3",
    "L1: 6 MiB I + 6 MiB D perchip, L2: 192 MiB  per chip, L3: 768 MiB per chip",
    "L1d cache: 3.8 MiB, L1i cache: 2.5 MiB, L2 cache: 100 MiB, L3 cache: 120 MiB",
    "L1d cache: 768 KiB, L1i cache: 768 KiB, L2 cache: 12 MiB, L3 cache: 96 MiB",
    "N/A"
  ],
  "system.host_processor_core_count": [
    "112",
    "24",
    "32",
    "40",
    "44",
    "48",
    "52",
    "56",
    "60",
    "64",
    "96"
  ],
  "system.host_processor_frequency": [
    "",
    "1.90 GHz",
    "1.9GHz",
    "2.00GHz",
    "2.10GHz",
    "2.3 GHz",
    "2.40 GHz",
    "2.45GHz",
    "2.4GHz",
    "2.60 GHz",
    "2100 MHz",
    "3.0GHz",
    "3.1 GHz",
    "3.1GHz",
    "3.8GHz"
  ],
  "system.host_processor_interconnect": [
    "",
    "IF (Infinity Fabric)",
    "UPI",
    "xGMI3 32GT/s x16 x4 Link"
  ],
  "system.host_processor_model_name": [
    "AMD EPYC 7B13",
    "AMD EPYC 7R32",
    "AMD EPYC 9554 64-Core Processor",
    "AMD EPYC 9654",
    "AMD EPYC 9654 96-Core Processor",
    "Intel(R) Xeon(R) CPU @ 2.20GHz",
    "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "Intel(R) Xeon(R) Gold 6430",
    "Intel(R) Xeon(R) Platinum 6458Q",
    "Intel(R) Xeon(R) Platinum 8358",
    "Intel(R) Xeon(R) Platinum 8380",
    "Intel(R) Xeon(R) Platinum 8458P",
    "Intel(R) Xeon(R) Platinum 8460Y+",
    "Intel(R) Xeon(R) Platinum 8462Y+",
    "Intel(R) Xeon(R) Platinum 8468",
    "Intel(R) Xeon(R) Platinum 8470",
    "Intel(R) Xeon(R) Platinum 8470Q",
    "Intel(R) Xeon(R) Platinum 8480+",
    "Intel(R) Xeon(R) Platinum 8480+ @ 2.00GHz",
    "Intel(R) Xeon(R) Platinum 8480C",
    "Intel(R) Xeon(R) Platinum 8490H 60-Core Processor",
    "Intel(R)Xeon(R)Platinum 8490H"
  ],
  "system.host_processor_vcpu_count": [
    "",
    "0",
    "104",
    "112",
    "128",
    "192",
    "48",
    "80",
    "96"
  ],
  "system.host_processors_per_node": [
    "1",
    "2",
    "8"
  ],
  "system.host_storage_capacity": [
    "",
    "0.25 TB",
    "0.25 TB; 1 TB (hosting the dataset)",
    "0.25 TB; 4 TB (hosting the dataset)",
    "1 PB",
    "1 x 7.68T U.2 NVMe",
    "1.1 TB;",
    "1.8 TB NVMe + 5x 1.8 TB NVMe",
    "1.8 TB NVMe + 7x 1.8 TB NVMe",
    "1.8T",
    "1x 1.92TB NVMe SSD + 5x 7.68TB NVMe SSD",
    "1x 3.84TB NVMe SSD + 7.68 TB NVMe SSD",
    "1x 480GB, 8x 7.68TB",
    "1x 5.9TB NVMe",
    "1x 500GB M.2 NVMe SSD + 5x 7.68TB NVMe SSD",
    "1x 900GB NVMe SSD + 1x 15.36TB NVMe SSD",
    "2TB + 21TB",
    "2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2",
    "2x1.92TB NVMe + 2x 3.20TB NVMe + 1x 3.84TB NVMe + 1x 7.68TB NVMe",
    "3 TB",
    "480 GB SATA SSD + 4 x 3.2 TB NVMe",
    "4x 4TB + 1x 1TB",
    "4x 800GB NVMe SSD",
    "4x1.92TB NVMe",
    "4x1.92TB NVMe + 2x 1.00TB NVMe + 1x 7.68TB NVMe + 1x 6.40TB NVMe",
    "4x6.4TB NVMe",
    "7 TB",
    "7 TB (OS) + 15 TB (DATA)",
    "8x 4TB NVMe SSD",
    "960 GB",
    "97GB"
  ],
  "system.host_storage_type": [
    "",
    "NVMe",
    "NVMe SSD",
    "NVMe SSD PCIe Gen4",
    "NVMe, SSD",
    "NVMe1",
    "NVMe1; NVMe0",
    "SSD",
    "SSD;",
    "Weka"
  ],
  "system.hw_notes": [
    "",
    "700W",
    "GPU TDP:700W",
    "GPUs are installed in an external PCI box.",
    "GPUs are installed in an external PCI box. This systems corresponds to preview system 3.0-2086.",
    "GPUs are installed in an external PCI box. This systems corresponds to preview system 3.0-2087.",
    "NVIDIA H100-PCIe-80GB",
    "TDP=350W per GPU",
    "TDP=350W per GPU, air cooling ",
    "TDP=700W per GPU, L2A cooling "
  ],
  "system.number_of_nodes": [
    "1",
    "1.0",
    "1024",
    "128",
    "1280",
    "1344",
    "16",
    "2",
    "256",
    "32",
    "4",
    "434",
    "448",
    "48",
    "512",
    "64",
    "768",
    "8",
    "9",
    "96"
  ],
  "system.operating_system": [
    "Red Hat Enterprise Linux 8.7 (Ootpa)",
    "Red Hat Enterprise Linux 9.1",
    "Red Hat Rocky Linux 8.6(Green Obsidian)",
    "Rocky Linux release 9.2 (Blue Onyx)",
    "Ubuntu 20.04",
    "Ubuntu 20.04.1 LTS",
    "Ubuntu 20.04.2 LTS",
    "Ubuntu 20.04.3 LTS",
    "Ubuntu 20.04.4 LTS",
    "Ubuntu 20.04.5 LTS",
    "Ubuntu 22.04",
    "Ubuntu 22.04.1 LTS",
    "Ubuntu 22.04.2 LTS",
    "Ubuntu 22.04.3 LTS",
    "Ubuntu 22.04.3 LTS (Linux chai 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)"
  ],
  "system.other_software_stack": [
    "",
    "cuda 12.2",
    "synapseAI 1.12.0",
    "synapseAI 1.13.99"
  ],
  "system.other_software_stack.JAX": [
    "commit 6b5af15eeab3b08de4c05bac8999779d503fdb2a"
  ],
  "system.other_software_stack.PAXML": [
    "nightly+20230904"
  ],
  "system.other_software_stack.PRAXIS": [
    "nightly+20230904"
  ],
  "system.other_software_stack.composer_version": [
    "0.7.0"
  ],
  "system.other_software_stack.cublas_version": [
    "11.10.3.66",
    "11.9.3.115",
    "12.1.3.1",
    "12.2.5",
    "12.2.5.6"
  ],
  "system.other_software_stack.cuda_driver_version": [
    "510.47.03",
    "515.65.01",
    "525.105.17",
    "525.125 .06",
    "525.125.06",
    "530.30.02",
    "535.102.12",
    "535.104.05",
    "535.104.12",
    "535.86.10"
  ],
  "system.other_software_stack.cuda_version": [
    "11.3",
    "11.6.2",
    "11.7",
    "12.0",
    "12.1",
    "12.1.0.023",
    "12.2",
    "12.2.1",
    "12.2.1.020",
    "12.2.128",
    "12.2.2"
  ],
  "system.other_software_stack.cudnn_version": [
    "8.4.0.27",
    "8.5 .0",
    "8.5.0",
    "8.9.0.131",
    "8.9.4",
    "8.9.5",
    "8.9.5.27"
  ],
  "system.other_software_stack.dali_version": [
    "1.12.0",
    "1.16 .0",
    "1.16.0",
    "1.24.0",
    "1.28.0",
    "1.29.0"
  ],
  "system.other_software_stack.hpcx_version": [
    "2.10",
    "2.13",
    "2.15",
    "2.16rc4"
  ],
  "system.other_software_stack.kernel_version": [
    "5.14.0-284.30.1.el9_2.x86_64",
    "5.15.0-84-generic",
    "5.19.0-41-generic",
    "Linux 5.15.0-1030-nvidia",
    "Linux 5.15.0-1041-azure",
    "Linux 5.15.0-86-generic"
  ],
  "system.other_software_stack.libtpu": [
    ""
  ],
  "system.other_software_stack.mofed_version": [
    "",
    "5.4-rdmacore32.1",
    "5.4-rdmacore36.0",
    "5.4-rdmacore39.0",
    "5.8-3.0.7.0",
    "rdmacore39.0"
  ],
  "system.other_software_stack.mxnet_version": [
    "1.9.1"
  ],
  "system.other_software_stack.nccl_version": [
    "2.12 .12",
    "2.12.10",
    "2.12.12",
    "2.17.1",
    "2.18.3",
    "2.18.5",
    "2.18.5-fix-4365458757e4107ecbf629b2fd6e0e19a5d237c2"
  ],
  "system.other_software_stack.nvidia_kernel_driver": [
    "525.105.17",
    "535.104.05",
    "535.104.12",
    "535.86.10"
  ],
  "system.other_software_stack.ofed_version": [
    "23.07-0.5.1.2"
  ],
  "system.other_software_stack.openmpi_version": [
    "4.1",
    "4.1 .5",
    "4.1.1rc1",
    "4.1.2rc4",
    "4.1.4",
    "4.1.4+",
    "4.1.5a1",
    "4.1.5rc2"
  ],
  "system.other_software_stack.openucx_version": [
    "1.12.0",
    "1.14.0",
    "1.15.0"
  ],
  "system.other_software_stack.python_version": [
    "3.9.12 (main, Apr 18 2022, 22:40:46) \n[GCC 9.4.0]"
  ],
  "system.other_software_stack.pytorch_version": [
    "2.1.0a0+32f93b1"
  ],
  "system.other_software_stack.trt_version": [
    "8.2.4.2+cuda11.4",
    "8.4 .2 .4 - 1 + cuda11 .6",
    "8.4.2-1+cuda11.6",
    "8.6.1",
    "8.6.1.2",
    "8.6.1.2+cuda12.0.1.011",
    "8.6.1.6",
    "8.6.1.6+cuda12.0.1.011"
  ],
  "system.status": [
    "Available Cloud",
    "Available in cloud",
    "Available on premise",
    "Available on-premise",
    "available",
    "available on premise",
    "cloud",
    "onprem"
  ],
  "system.submitter": [
    "ASUSTeK",
    "Ailiverse",
    "Azure",
    "Azure+NVIDIA",
    "CTuning",
    "Clemson University Research Computing and Data",
    "Dell",
    "Fujitsu",
    "GigaComputing",
    "Google",
    "Intel",
    "Intel-HabanaLabs",
    "Krai",
    "Lenovo",
    "NVIDIA",
    "NVIDIA+CoreWeave",
    "Quanta_Cloud_Technology",
    "Supermicro",
    "Supermicro-RedHat",
    "xFusion"
  ],
  "system.sw_notes": [
    "",
    "N/A",
    "PAXML 20230904 wheels. ",
    "This result was obtained in partnership between Azure AI Production and NVIDIA",
    "We perform LAMB over a fused parameter instead of individual parameters (one fused param for each datatype and weight_decay value). No change in model or any other computation compared to closed division"
  ],
  "system.system_name": [
    "16 xR750 - 2 xA100 - PCIe - 80 GB",
    "16-nodes-SPR-pytorch",
    "16-nodes-SPR-pytorch-open",
    "2xXE8640x4H100-SXM-80GB",
    "2xXE9680x8H100-SXM-80GB",
    "4-nodes-SPR-pytorch",
    "8 xR750 - 2 xA100 - PCIe - 80 GB",
    "8-nodes-SPR-pytorch",
    "AS-4125GS-TNRT-RedHat-OpenShift",
    "AS-8125GS-TNHR",
    "AWS Cloud instance g5.12xlarge",
    "Araucana",
    "D54U-3U",
    "D74H-7U",
    "Dell Precision 7920 Tower with 2x A5000 and 1TB SSD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 and 4TB HDD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 using MxNet 22.04 and 0.25TB SSD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 using MxNet 22.08 and 0.25TB SSD for the dataset",
    "Dell Precision 7920 Tower with 2x A5000 using MxNet 23.08 and 0.25TB SSD for the dataset",
    "ESC-N8-E11",
    "ESC8000-E11-8xH100-PCIE-80GB",
    "Eos-dfw_n1024",
    "Eos-dfw_n1280",
    "Eos-dfw_n1344",
    "Eos-dfw_n512",
    "Eos-dfw_n768",
    "Eos_n1",
    "Eos_n128",
    "Eos_n16",
    "Eos_n256",
    "Eos_n434",
    "Eos_n48",
    "Eos_n64",
    "Eos_n8",
    "Eos_n9",
    "Eos_n96",
    "GIGABYTE G593-ZD2",
    "HLS-Gaudi2-N32-PT",
    "HLS-Gaudi2-N48-PT",
    "HLS-Gaudi2-N8-PT",
    "HLS-Gaudi2-PT",
    "HLS-Gaudi2-TF",
    "Lenovo ThinkSystem SR675 V3 Server with 4x 96GB SXM5 H100",
    "Lenovo ThinkSystem SR675 V3 Server with 8x 80GB PCIe H100",
    "ND_H100_v5",
    "ND_H100_v5 x1344",
    "PRIMERGY-CDI-A100x10-mxnet",
    "PRIMERGY-CDI-A100x10-pytorch",
    "PRIMERGY-CDI-A100x2-mxnet",
    "PRIMERGY-CDI-A100x4-mxnet",
    "PRIMERGY-CDI-A100x8-mxnet",
    "PRIMERGY-CDI-A100x8-pytorch",
    "SYS-421GU-TNXR",
    "SYS-681E-TR",
    "SYS-821GE-TNHR",
    "XE8640x4H100-SXM-80GB",
    "XE9640x4H100-SXM-80GB",
    "XE9680x8H100-SXM-80GB",
    "coreweave_hgxh100_n448_ngc23.04_mxnet",
    "tpu-v5e-4096",
    "xFusion FusionServer 2288H V7(6x NVIDIA L4)",
    "xFusion FusionServer G5500 V7(10x NVIDIA A30)",
    "xFusion FusionServer G5500 V7(10x NVIDIA L40)",
    "xFusion FusionServer G5500 V7(8x NVIDIA A30)",
    "xFusion FusionServer G5500 V7(8x NVIDIA L40)",
    "xFusion FusionServer G5500 V7(8x NVIDIA L40S)"
  ],
  "system.system_type": [
    "datacenter"
  ],
  "system_file_name": [
    "16-nodes-SPR-pytorch-open.json",
    "16-nodes-SPR-pytorch.json",
    "16xR750-2xA100-PCIe-80GB.json",
    "2288H_V7x6xL4.json",
    "2xXE8640x4H100-SXM-80GB.json",
    "2xXE9680x8H100-SXM-80GB.json",
    "4-nodes-SPR-pytorch.json",
    "7920T_2xA5000_hdd.json",
    "7920T_2xA5000_mxnet22.04.json",
    "7920T_2xA5000_mxnet22.08.json",
    "7920T_2xA5000_mxnet23.08.json",
    "7920T_2xA5000_ssd.json",
    "8-nodes-SPR-pytorch.json",
    "8xA100_40GB_open.json",
    "8xR750-2xA100-PCIe-80GB.json",
    "AS-4125GS-TNRT-RedHat-OpenShift.json",
    "AS-8125GS-TNHR.json",
    "D54U-3U.json",
    "D74H-7U.json",
    "ESC-N8-E11.json",
    "ESC8000-E11-8xH100-PCIE-80GB.json",
    "G5500V7x10L40.json",
    "G5500V7x10xA30.json",
    "G5500V7x10xL40.json",
    "G5500V7x8L40.json",
    "G5500V7x8xA30.json",
    "G5500V7x8xL40.json",
    "G5500V7x8xL40S.json",
    "G593-ZD2_hugectr.json",
    "G593-ZD2_mxnet.json",
    "G593-ZD2_pytorch.json",
    "HLS-Gaudi2-N32-PT.json",
    "HLS-Gaudi2-N48-PT.json",
    "HLS-Gaudi2-N8-PT.json",
    "HLS-Gaudi2-PT.json",
    "HLS-Gaudi2-TF.json",
    "ND_H100_v5_mxnet.json",
    "ND_H100_v5_n1344_pytorch.json",
    "ND_H100_v5_pytorch.json",
    "SR675v3-4xH100_SXM5_96GB_700W.json",
    "SR675v3-8xH100_PCIe_80GB_350W.json",
    "SYS-421GU-TNXR.json",
    "SYS-681E-TR.json",
    "SYS-821GE-TNHR.json",
    "XE8640x4H100-SXM-80GB.json",
    "XE9640x4H100-SXM-80GB.json",
    "XE9680x8H100-SXM-80GB.json",
    "a10x2-mxnet_22.08.json",
    "cloud-tpu-v5e-4096-PAX.json",
    "coreweave_hgxh100_n448_ngc23.04_mxnet.json",
    "eos-dfw_n1024_ngc23.09_nemo.json",
    "eos-dfw_n1280_ngc23.09_nemo.json",
    "eos-dfw_n1344_ngc23.09_nemo.json",
    "eos-dfw_n512_ngc23.09_nemo.json",
    "eos-dfw_n768_ngc23.09_nemo.json",
    "eos_n128_ngc23.09_nemo_mm.json",
    "eos_n16_ngc23.09_merlin_hugectr.json",
    "eos_n256_ngc23.09_pytorch.json",
    "eos_n434_ngc23.09_pytorch.json",
    "eos_n48_ngc23.04_pytorch.json",
    "eos_n64_ngc23.04_pytorch.json",
    "eos_n64_ngc23.09_nemo.json",
    "eos_n64_ngc23.09_nemo_mm.json",
    "eos_n8_ngc23.04_pytorch.json",
    "eos_n8_ngc23.09_merlin_hugectr.json",
    "eos_n8_ngc23.09_mxnet.json",
    "eos_n8_ngc23.09_nemo_mm.json",
    "eos_n8_ngc23.09_pytorch.json",
    "eos_n96_ngc23.04_mxnet.json",
    "eos_n96_ngc23.09_nemo.json",
    "eos_n9_ngc23.04_mxnet.json",
    "eos_ngc23.04_mxnet.json",
    "eos_ngc23.04_pytorch.json",
    "eos_ngc23.09_merlin_hugectr.json",
    "eos_ngc23.09_mxnet.json",
    "eos_ngc23.09_pytorch.json",
    "primergy-cdi-A100x10-mxnet-ngc23.09.json",
    "primergy-cdi-A100x10-pytorch-ngc23.09_gbs320.json",
    "primergy-cdi-A100x2-mxnet-ngc23.09.json",
    "primergy-cdi-A100x4-mxnet-ngc23.09.json",
    "primergy-cdi-A100x8-mxnet-ngc23.04.json",
    "primergy-cdi-A100x8-mxnet-ngc23.09.json",
    "primergy-cdi-A100x8-pytorch-ngc23.09_gbs320.json"
  ],
  "url_repo": [
    "https://github.com/mlcommons/training_results_v3.1/tree/main"
  ]
}
