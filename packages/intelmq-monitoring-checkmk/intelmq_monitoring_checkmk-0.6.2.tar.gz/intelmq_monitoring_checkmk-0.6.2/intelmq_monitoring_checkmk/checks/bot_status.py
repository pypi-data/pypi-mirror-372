"""
Make a check on every enabled bot.

For every bot, a couple of generic data is collected, checked and reported
(e.g. state, number of fails, number of produced messages, queue sizes etc.)

See description in the BotStatusCheck class.
"""

import logging
from datetime import datetime, timedelta

from ..base import BaseServiceCheck
from ..config import Config
from ..helpers import TOTAL_COUNTER_TEMPLATE, is_collector, sum_timeline
from ..writer import CheckStatus

logger = logging.getLogger(__name__)

TOTAL_MESSAGES_KEY = "total-processed-timeline"
SUCCEEDED_MESSAGES_KEY = "successes-timeline"
FAILED_MESSAGES_KEY = "failures-timeline"


STATS_CACHE_MAPPING = {
    TOTAL_MESSAGES_KEY: TOTAL_COUNTER_TEMPLATE,
    SUCCEEDED_MESSAGES_KEY: "{}.stats.success",
    FAILED_MESSAGES_KEY: "{}.stats.failure",
}


class BotStatusCheck(BaseServiceCheck, auto_register=False):
    DESCRIPTION = """Evaluate status of a single enabled bot

    Checks explained:

      * state: ensures the bot is running,
      * collector processing data: for collectors, it ensures the bot has produced some
        data to the system in the monitored period (set "monitoring-ignore-no-data"
        parameter in bot's config to disable alerts; it's content should describe the reason)

    Metrics explained:

    Due to the collecting limitations, values are just an approximation. It should
    be enough for operational monitoring, but do not use it for statistics. Restarting
    bot causes stats cache clear.

      * '-queue': the current state of the Redis queues, quickly changing
      * '-produced': number of messages generated by the bot
      * '-succeeded': number of successfully proceeded messages, and/or scheduled runs
        (e.g. when RT bots don't find any new report without any issue)
      * '-failures': number of failures during processing messages and/or scheduled runs
        (e.g. error on auth to the RT)
      * 'today-' uses UTC timezone, and are reset on UTC midnight
      * error rate it's counted as (fails / (fails+successes) * 100) in the whole monitored
        period

    A RT bot with non-empty success metric, but empty proceeded metric means, that the bot
    didn't find any new report in RT.

    For disabled bots, this check is not produced.
    """
    PREFIX = Config.PREFIX_BOT

    def __init__(self, config: Config, bot_id: str) -> None:
        self._bot_id = bot_id
        self.NAME = bot_id
        super().__init__(config)

    @property
    def bot_config(self):
        return self.intelmq_runtime.get(self._bot_id) or {}

    @property
    def bot_parameters(self):
        return self.bot_config.get("parameters") or {}

    def _get_time_window(self):
        cfg_value = self.get_custom_bot_monitoring_config(
            self._bot_id, "activity-window-days"
        )
        if not cfg_value:
            return self.config.TIME_WINDOW
        return timedelta(days=cfg_value)

    def _check_bot_state(self):
        """Verify that enabled bot is running"""
        status_code, status_description = self.intelmq_cli.bot_status(self._bot_id)
        logger.debug(
            "Bot %s status: %d, %s", self._bot_id, status_code, status_description
        )
        if status_code:
            self.writer.status = CheckStatus.CRITICAL
            self.writer.add_summary_line(f"FAIL: Bot in state {status_description}")
            self.writer.set_short_summary("Bot isn't running")
        else:
            self.writer.add_summary_line(f"OK: Bot in state {status_description}")

    def _update_stat_queues_cache(self):
        logger.debug("Updating stats from statistic database")
        period_start = datetime.utcnow() - self._get_time_window()
        for cache_key, redis_template in STATS_CACHE_MAPPING.items():
            current_value = 0
            for queue in self.stat_db.keys(redis_template.format(self._bot_id)):
                queue_value = int(self.stat_db.get(queue) or 0)
                current_value += queue_value
                logger.debug("Queue %s value %d", queue, queue_value)

            self.storage.add_timeline_entry(cache_key, current_value)
            self.storage.clean_timeline_key(cache_key, period_start)

    def _check_collector_processed_data(self):
        """For collectors, verify they had some data during last TIME_WINDOW"""
        if not is_collector(self.bot_config):
            logger.debug(
                "Bot not in the collector group (groupname: %s)",
                self.bot_config.get("groupname", self.bot_config.get("group")),
            )
            return

        if self.bot_parameters.get(self.config.INACTIVE_COLLECTOR_IGNORING_KEY):
            reason = self.bot_parameters.get(
                self.config.INACTIVE_COLLECTOR_IGNORING_KEY
            )
            logger.debug(
                "Bot is configured to ignore processing data check, reason: %s", reason
            )
            self.writer.add_summary_line(
                f'SKIPPED: Verifying producing data skipped because: "{reason}"'
            )
            return

        total_sum = sum_timeline(iter(self.storage[TOTAL_MESSAGES_KEY]))

        if not total_sum:
            self.writer.status = CheckStatus.CRITICAL
            self.writer.add_summary_line(
                f"FAIL: Collector processed no data in last {self._get_time_window()}"
            )
            self.writer.set_short_summary("Collector doesn't produce data")
        else:
            self.writer.add_summary_line(
                f"OK: Collector processed data in last {self._get_time_window()}"
            )

    @property
    def queues(self):
        return self.bots_queues.get(self._bot_id, {})

    def _report_queues_size(self):
        if "source_queue" in self.queues:
            self.writer.add_metric(
                "input-queue",
                self.queues["source_queue"][1],
                self.get_custom_bot_monitoring_config(
                    self._bot_id, "queue-warning", self.config.QUEUE_WARNING
                ),
                self.get_custom_bot_monitoring_config(
                    self._bot_id, "queue-critical", self.config.QUEUE_CRITICAL
                ),
            )

        if "internal_queue" in self.queues:
            self.writer.add_metric(
                "internal-queue",
                self.queues["internal_queue"],
                self.get_custom_bot_monitoring_config(
                    self._bot_id, "queue-warning", self.config.QUEUE_WARNING
                ),
                self.get_custom_bot_monitoring_config(
                    self._bot_id, "queue-critical", self.config.QUEUE_CRITICAL
                ),
            )

        for name, size in self.queues.get("destination_queues", []):
            self.writer.add_metric(f"destination-{name}", size)

    def _report_today_stats(self):
        today = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)

        stats_to_metric_mapping = (
            (TOTAL_MESSAGES_KEY, "today-produced", dict()),
            (SUCCEEDED_MESSAGES_KEY, "today-succeeded", dict()),
            (
                FAILED_MESSAGES_KEY,
                "today-failures",
                dict(
                    warn_level=self.config.FAILURES_WARNING,
                    critical_level=self.config.FAILURES_CRITICAL,
                ),
            ),
        )
        for stat_key, metric, metric_kwargs in stats_to_metric_mapping:
            today_checkpoints = filter(
                lambda v: datetime.fromisoformat(v["time"]) > today,
                self.storage[stat_key],
            )

            sum_value = sum_timeline(today_checkpoints)
            if sum_value is None:
                logger.warning("No data for metric %s", metric)
                sum_value = 0

            self.writer.add_metric(metric, sum_value, **metric_kwargs)

    def _report_error_rate(self):
        period_start = datetime.utcnow() - self.config.ERROR_RATE_WINDOW
        success_sum = sum_timeline(
            filter(
                lambda v: datetime.fromisoformat(v["time"]) > period_start,
                self.storage[SUCCEEDED_MESSAGES_KEY],
            )
        )
        failure_sum = sum_timeline(
            filter(
                lambda v: datetime.fromisoformat(v["time"]) > period_start,
                self.storage[FAILED_MESSAGES_KEY],
            )
        )

        if failure_sum + success_sum:
            rate = failure_sum / (failure_sum + success_sum) * 100
        else:
            rate = 0

        self.writer.add_summary_line(
            f"Error rate for last {self.config.ERROR_RATE_WINDOW} is {rate:.2f}%"
        )
        self.writer.add_metric(
            "period-error-percentage",
            rate,
            self.config.ERROR_RATE_WARNING,
            self.config.ERROR_RATE_CRITICAL,
        )

    def _is_bot_disabled(self):
        if self.bot_config.get("enabled", True):
            return False
        self.writer.status = CheckStatus.OK
        self.writer.set_short_summary("Bot is disabled")
        return True

    def proceed(self):
        if self._is_bot_disabled():
            logger.info("Bot is disabled, skipping")
            return

        self.writer.set_short_summary("Checking bot state")
        self._update_stat_queues_cache()

        self._check_bot_state()
        self._check_collector_processed_data()

        self._report_today_stats()
        self._report_queues_size()
        self._report_error_rate()


class BotSummaryStatusCheck(BaseServiceCheck):
    NAME = "Bots summary check"
    PREFIX = Config.PREFIX_SUMMARY
    DESCRIPTION = "Run checks for every bot and collect disabled state"

    def proceed(self):
        failed_checks = 0
        disabled_bots = 0
        total_bots = 0
        for bot in filter(lambda k: k != "global", self.intelmq_runtime.keys()):
            total_bots += 1
            if not self.intelmq_runtime[bot].get("enabled", True):
                disabled_bots += 1

            try:
                self.check_bot(bot)
            except Exception:
                failed_checks += 1
                logger.exception("Checking bot %s failed", bot)
                self.writer.add_summary_line(f"Checking bot {bot} failed")

        self.writer.add_metric("total-bots", total_bots)
        self.writer.add_metric("disabled-bots", disabled_bots, 10, 30)
        self.writer.add_metric("failed-bot-checks", failed_checks, critical_level=1)
        self.writer.set_short_summary(
            "All bot checks finished"
            if not failed_checks
            else f"{failed_checks} bot checks failed"
        )

    def check_bot(self, bot_id: str):
        check = BotStatusCheck(self.config, bot_id)
        check.check()
